{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('data/*txt')\n",
    "with open('data/all_lyrics.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        if 'all_lyrics' in fname: continue\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "\n",
    "with open('data/all_lyrics.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with open('data/all_lyrics.txt', 'w') as f:\n",
    "    list_of_chars = \"[^\\n\\\"$&\\'(),-./0123456789:?ABCDEFGHIJKLMNOPQRSTUVWY\\[\\]abcdefghijklmnopqrstuvwxyz ]\"\n",
    "    regex = re.compile(list_of_chars)\n",
    "    f.write(regex.sub('', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308423\n"
     ]
    }
   ],
   "source": [
    "with open('data/all_lyrics.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \"$&'(),-./012345789:?ABCDEFGHIJKLMNOPQRSTUVWY[]abcdefghijklmnopqrstuvwxyz\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 57, 1, 68, 56, 53, 66, 53]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode('hi there'))\n",
    "print(decode(encode('hi there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([308423]) torch.int64\n",
      "tensor([ 2, 41, 61, 63, 59, 53,  1, 41, 57, 55])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 41, 61, 63, 59, 53,  1, 41, 57])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[57, 67,  1,  0, 37, 66,  1, 62],\n",
      "        [63, 67, 68,  1, 63, 54,  1, 73],\n",
      "        [68, 69, 52, 53,  2,  0,  0, 23],\n",
      "        [ 1, 31,  5, 60, 60,  1, 66, 53]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[67,  1,  0, 37, 66,  1, 62, 63],\n",
      "        [67, 68,  1, 63, 54,  1, 73, 63],\n",
      "        [69, 52, 53,  2,  0,  0, 23, 60],\n",
      "        [31,  5, 60, 60,  1, 66, 53, 49]])\n",
      "------\n",
      "when input is [57] target is 67\n",
      "when input is [57, 67] target is 1\n",
      "when input is [57, 67, 1] target is 0\n",
      "when input is [57, 67, 1, 0] target is 37\n",
      "when input is [57, 67, 1, 0, 37] target is 66\n",
      "when input is [57, 67, 1, 0, 37, 66] target is 1\n",
      "when input is [57, 67, 1, 0, 37, 66, 1] target is 62\n",
      "when input is [57, 67, 1, 0, 37, 66, 1, 62] target is 63\n",
      "when input is [63] target is 67\n",
      "when input is [63, 67] target is 68\n",
      "when input is [63, 67, 68] target is 1\n",
      "when input is [63, 67, 68, 1] target is 63\n",
      "when input is [63, 67, 68, 1, 63] target is 54\n",
      "when input is [63, 67, 68, 1, 63, 54] target is 1\n",
      "when input is [63, 67, 68, 1, 63, 54, 1] target is 73\n",
      "when input is [63, 67, 68, 1, 63, 54, 1, 73] target is 63\n",
      "when input is [68] target is 69\n",
      "when input is [68, 69] target is 52\n",
      "when input is [68, 69, 52] target is 53\n",
      "when input is [68, 69, 52, 53] target is 2\n",
      "when input is [68, 69, 52, 53, 2] target is 0\n",
      "when input is [68, 69, 52, 53, 2, 0] target is 0\n",
      "when input is [68, 69, 52, 53, 2, 0, 0] target is 23\n",
      "when input is [68, 69, 52, 53, 2, 0, 0, 23] target is 60\n",
      "when input is [1] target is 31\n",
      "when input is [1, 31] target is 5\n",
      "when input is [1, 31, 5] target is 60\n",
      "when input is [1, 31, 5, 60] target is 60\n",
      "when input is [1, 31, 5, 60, 60] target is 1\n",
      "when input is [1, 31, 5, 60, 60, 1] target is 66\n",
      "when input is [1, 31, 5, 60, 60, 1, 66] target is 53\n",
      "when input is [1, 31, 5, 60, 60, 1, 66, 53] target is 49\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print('------')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'when input is {context.tolist()} target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57, 67,  1,  0, 37, 66,  1, 62],\n",
      "        [63, 67, 68,  1, 63, 54,  1, 73],\n",
      "        [68, 69, 52, 53,  2,  0,  0, 23],\n",
      "        [ 1, 31,  5, 60, 60,  1, 66, 53]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[67,  1,  0, 37, 66,  1, 62, 63],\n",
      "        [67, 68,  1, 63, 54,  1, 73, 63],\n",
      "        [69, 52, 53,  2,  0,  0, 23, 60],\n",
      "        [31,  5, 60, 60,  1, 66, 53, 49]])\n"
     ]
    }
   ],
   "source": [
    "print(yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 75])\n",
      "tensor(5.0185, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "RjEBMArY0T.i?B2'2Tn&KnLhA[UBR[YD&AW$0LTMpup3Bj2UsenM4P2'1A)Ki:3vFjHd$Ir9Oim&iz?3-QVgJre4w92B'Y[iC,[)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next torkne from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx: (B, T) \n",
    "        logits = self.token_embedding_table(idx) # (B, T = 8, C = channels == vocab size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T = 8 for the 8 context) indices of current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # now (B, C)\n",
    "            # apply softmax to get probs\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "    \n",
    "m  = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3260750770568848\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): \n",
    "    # sample new batch of data \n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We an frtheeldoutoun sdeyo I as \n",
      "Yo f cu gestht waberan'th e Wh taitr on ju fr s m as s f ur oms ane yold\n",
      "Whasouman besethtove oucth ainea lomigile f be t waby'me\n",
      "Sore \n",
      "Se \"\n",
      "Angitourongid pll w ieth cispl he twhunkngandou, oucal y?\n",
      "Oht o achery y the\n",
      "Goditr s siletoulg, tre a teeskild\n",
      "\"\n",
      "I we\n",
      "Whorasoup s don bou me\n",
      "\"Re \n",
      "I plous f al het\n",
      "Laknd les nd atoll u'\n",
      "'t wan fayoforou, y, w fout\n",
      "Anke I'tod dito..\n",
      "\"\n",
      "Th-at manndinsoverve.. g I wevethevean, olstow\n",
      "'rekendos y y Landlat'low\n",
      "Hend ndonond\n",
      "\n",
      "y y\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b, t] = mean_i<=t{}\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei@x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a/torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a@b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention \n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x) # (B, T, head_size)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5713e-01,  8.8009e-01,  1.6152e-01, -7.8239e-01, -1.4289e-01,\n",
       "           7.4676e-01,  1.0068e-01, -5.2395e-01, -8.8726e-01,  1.9067e-01,\n",
       "           1.7616e-01, -5.9426e-01, -4.8124e-01, -4.8599e-01,  2.8623e-01,\n",
       "           5.7099e-01],\n",
       "         [ 4.3974e-01, -1.4227e-01, -1.3157e-01,  2.8895e-03, -1.3222e-01,\n",
       "           6.6093e-04, -2.7904e-01, -2.2676e-01, -2.8723e-01,  5.7456e-01,\n",
       "           5.6053e-01, -2.5208e-01,  9.7243e-02,  1.0771e-01,  3.0455e-02,\n",
       "           1.0727e+00],\n",
       "         [ 4.3615e-01, -6.6358e-02, -2.9296e-01,  7.4315e-02,  5.4381e-02,\n",
       "          -7.0388e-02, -6.8984e-02, -8.2153e-02, -2.9377e-01, -5.8952e-02,\n",
       "           3.5887e-01, -2.3088e-03, -1.8212e-01, -3.6143e-02, -6.7189e-02,\n",
       "           1.1412e+00],\n",
       "         [ 4.2068e-01, -1.0619e-01, -2.9984e-01,  5.2820e-02,  2.0077e-01,\n",
       "          -1.6048e-01, -3.5710e-02, -8.3110e-02, -1.7919e-01,  7.7992e-02,\n",
       "           1.2719e-01,  2.2611e-02, -5.1810e-02,  7.4466e-02,  1.8131e-01,\n",
       "           8.4463e-01],\n",
       "         [ 3.9499e-01,  1.7130e-01,  5.1664e-02,  2.0128e-01,  2.4059e-01,\n",
       "           1.6471e-01,  1.9638e-01,  1.3151e-01, -3.0257e-01, -3.9997e-01,\n",
       "          -4.7060e-02, -6.8541e-02, -3.7259e-01,  1.4653e-01,  3.3643e-02,\n",
       "           7.8407e-01],\n",
       "         [ 3.2160e-01,  1.3167e-01,  3.4681e-02,  2.6722e-01,  2.1268e-01,\n",
       "           1.6392e-01,  1.1234e-01,  7.3362e-02, -2.4218e-01, -2.6597e-01,\n",
       "           2.2720e-02, -1.5014e-02, -2.8530e-01,  1.6292e-01,  7.6938e-02,\n",
       "           7.5743e-01],\n",
       "         [ 1.0560e-01,  4.5449e-02, -1.3713e-01,  2.3461e-01,  1.8927e-01,\n",
       "          -2.0829e-02, -4.4675e-02, -6.8756e-02, -1.2469e-01,  4.6523e-02,\n",
       "           1.0449e-01,  9.9329e-02, -1.0045e-02,  7.7849e-02,  1.9440e-01,\n",
       "           6.4730e-01],\n",
       "         [ 1.2431e-01,  4.5290e-02, -3.4119e-01,  2.7087e-01,  2.3352e-01,\n",
       "          -9.4792e-02, -4.2095e-02,  2.1426e-01, -3.2988e-02, -3.1300e-02,\n",
       "           5.1987e-02,  2.3780e-01,  1.0845e-01, -9.5935e-02,  2.9991e-02,\n",
       "           4.7065e-01]],\n",
       "\n",
       "        [[-1.3254e+00,  1.1236e+00,  2.2927e-01, -2.9970e-01, -7.6266e-03,\n",
       "           7.9364e-01,  8.9581e-01,  3.9650e-01, -6.6613e-01, -2.1844e-01,\n",
       "          -1.3539e+00,  4.1245e-01,  9.6011e-01, -1.0805e+00, -3.9751e-01,\n",
       "          -4.4439e-01],\n",
       "         [-6.4733e-01,  1.7331e-01,  1.2791e-01,  4.9624e-02, -6.4768e-02,\n",
       "           3.1767e-01,  4.7299e-01, -6.4176e-02, -3.2625e-01, -7.3898e-02,\n",
       "          -3.0686e-02,  5.0577e-01,  2.5432e-01, -6.0843e-01, -2.8027e-01,\n",
       "          -4.5897e-01],\n",
       "         [-9.7019e-01,  3.1546e-01,  3.4645e-01, -3.8788e-02,  1.3692e-01,\n",
       "           2.3987e-01,  3.5699e-01,  1.6309e-01,  3.3288e-02, -3.7268e-02,\n",
       "          -9.9912e-02,  4.8613e-01,  5.9562e-01, -3.7783e-01,  5.7185e-02,\n",
       "          -2.2591e-01],\n",
       "         [-6.5972e-01,  2.1138e-01,  4.7277e-01,  1.7125e-01,  1.5721e-01,\n",
       "           4.1509e-01,  2.8069e-01,  1.4712e-01, -6.7355e-03,  1.2274e-01,\n",
       "          -1.7468e-01,  4.1368e-01,  5.1277e-01, -2.8585e-01,  3.6729e-02,\n",
       "          -1.8050e-01],\n",
       "         [-1.6183e-01,  2.0007e-01,  6.0713e-01,  3.2955e-01, -2.2336e-03,\n",
       "           5.3621e-01,  1.5889e-01,  3.6173e-01,  5.5019e-02,  3.6051e-01,\n",
       "           1.1735e-01,  2.3092e-01,  3.8389e-01, -1.0008e-01,  6.8729e-02,\n",
       "          -2.2749e-01],\n",
       "         [-2.1140e-01,  2.6617e-01,  5.4040e-01,  2.1307e-01, -1.0847e-01,\n",
       "           4.2144e-01,  1.4276e-01,  3.0351e-01, -1.9928e-02,  3.3220e-01,\n",
       "           7.4130e-02,  1.1718e-01,  4.1187e-01, -2.6235e-01,  5.9857e-02,\n",
       "          -3.1490e-01],\n",
       "         [-1.4507e-01,  2.2608e-01,  3.7810e-01,  1.2306e-01, -1.0936e-01,\n",
       "           2.5589e-01, -9.1279e-03,  2.4098e-01,  1.0412e-02,  3.9374e-01,\n",
       "           2.0256e-01,  2.7298e-02,  4.4937e-01, -4.0433e-01, -1.9074e-02,\n",
       "          -4.1265e-01],\n",
       "         [-3.3100e-01,  3.6802e-01,  3.2995e-01, -3.1286e-02, -1.5699e-01,\n",
       "           2.3272e-01,  9.0961e-02,  3.1875e-01,  1.2987e-02,  2.7334e-01,\n",
       "           2.1083e-02, -1.0045e-02,  4.8835e-01, -5.4052e-01,  1.2389e-02,\n",
       "          -4.2366e-01]],\n",
       "\n",
       "        [[ 6.8925e-02,  1.2248e+00, -4.1194e-01, -1.7046e-01, -6.9224e-01,\n",
       "          -2.9201e-01,  1.2704e+00, -6.8596e-01,  4.3798e-01, -2.6366e-01,\n",
       "           1.1528e-01,  1.1676e+00, -7.2138e-01, -1.2308e+00,  8.3821e-01,\n",
       "          -5.5987e-01],\n",
       "         [-4.4986e-01,  6.5337e-01, -1.6503e-01, -1.3407e-01, -5.9658e-01,\n",
       "          -4.9822e-01,  2.5994e-01, -3.3077e-01,  4.5729e-01, -1.8793e-01,\n",
       "           1.9015e-01,  3.9631e-01, -3.6849e-01, -7.8456e-01,  3.6308e-01,\n",
       "           5.3282e-02],\n",
       "         [-5.3164e-01,  2.7952e-01, -1.1372e-01, -1.1942e-01, -4.7999e-01,\n",
       "          -5.7604e-01,  4.5758e-02, -3.2054e-01,  4.9968e-01, -1.1678e-01,\n",
       "           4.4885e-01,  2.5802e-01, -3.6796e-01, -4.7685e-01,  4.7980e-01,\n",
       "           2.7696e-01],\n",
       "         [-3.8550e-01,  2.1642e-01, -3.1985e-03, -1.5432e-01, -3.7116e-02,\n",
       "          -4.6262e-01, -3.5652e-01, -6.7150e-02,  2.7857e-01,  1.5567e-01,\n",
       "           5.5354e-02,  5.1935e-02, -2.1987e-01, -1.7150e-01,  1.9222e-01,\n",
       "           2.1647e-01],\n",
       "         [-3.9807e-01,  3.4530e-01, -2.2231e-01, -1.1241e-01, -2.4619e-01,\n",
       "          -4.7757e-01,  2.8160e-01, -1.8940e-01,  2.9325e-01, -2.0639e-03,\n",
       "           2.2461e-01,  5.3476e-01, -4.2434e-01, -5.4877e-01,  4.1010e-01,\n",
       "          -7.6745e-02],\n",
       "         [-5.7634e-01, -2.2560e-03, -3.1488e-01,  9.1620e-02, -7.9742e-02,\n",
       "          -3.9549e-01,  9.9511e-02,  8.7891e-02,  3.3044e-01, -6.5358e-03,\n",
       "           2.4987e-01,  4.7826e-01, -2.6942e-01, -3.2518e-01,  3.5659e-01,\n",
       "          -1.2704e-01],\n",
       "         [-3.4582e-01,  5.4327e-03, -1.3520e-01,  1.5899e-01, -4.9529e-02,\n",
       "          -3.4307e-01, -1.3751e-01,  1.5925e-01,  1.4549e-01,  1.5565e-01,\n",
       "           1.7662e-01,  3.6624e-01, -1.4030e-01, -8.6785e-02,  1.3837e-01,\n",
       "          -6.5239e-02],\n",
       "         [-2.8486e-01,  1.1321e-01, -2.6014e-01,  1.5865e-01,  1.8084e-02,\n",
       "          -2.8388e-01,  3.6844e-02,  6.6312e-02,  2.0107e-01,  1.9944e-01,\n",
       "           1.5811e-01,  4.1358e-01, -2.0102e-01, -1.7096e-01,  3.2047e-01,\n",
       "           4.5389e-02]],\n",
       "\n",
       "        [[ 9.7183e-02,  5.7301e-02, -1.0468e-01, -4.6654e-02, -1.4006e-01,\n",
       "          -8.4126e-01, -1.3625e-01, -6.7465e-01, -2.1541e-01,  1.0993e+00,\n",
       "           2.3427e-01,  3.2605e-02, -1.8521e-01,  1.4780e-01, -6.1045e-01,\n",
       "           1.5391e+00],\n",
       "         [ 2.1995e-01, -2.8537e-01, -4.1443e-01,  2.7645e-01, -1.8862e-01,\n",
       "          -7.1933e-01, -7.8676e-01, -6.9664e-01, -2.0282e-01,  5.9328e-01,\n",
       "           2.3689e-01, -7.8802e-03, -1.6593e-01,  1.0200e-01, -7.3875e-01,\n",
       "           1.1601e+00],\n",
       "         [ 1.9948e-01, -2.0571e-01, -3.1089e-01,  2.5569e-01, -2.3325e-01,\n",
       "          -6.0104e-01, -6.3257e-01, -7.1145e-01, -2.5651e-01,  4.3021e-01,\n",
       "           1.7736e-01,  9.4623e-03, -1.6793e-01,  1.6852e-01, -6.5629e-01,\n",
       "           1.0664e+00],\n",
       "         [ 1.6538e-01,  2.1744e-01, -4.7123e-02, -2.9291e-01, -2.3346e-01,\n",
       "          -3.2531e-01,  3.8453e-02, -4.8501e-01, -4.2646e-01,  1.5670e-01,\n",
       "           4.6872e-02,  3.4695e-02, -9.7698e-02,  2.1606e-01, -5.5178e-01,\n",
       "           8.3573e-01],\n",
       "         [ 6.3022e-02,  1.1298e-02, -1.2262e-02, -3.2201e-01, -1.0722e-01,\n",
       "          -2.4687e-01, -1.2856e-01, -3.1578e-01, -3.3589e-01,  4.8637e-02,\n",
       "           1.3729e-01,  1.2083e-01, -6.6386e-02,  4.0389e-02, -5.1174e-01,\n",
       "           4.8917e-01],\n",
       "         [-6.5359e-03, -4.4882e-02, -8.4419e-03, -2.6507e-01, -7.7091e-02,\n",
       "          -3.1662e-01, -3.3695e-01, -2.1727e-01, -1.8777e-01,  9.0550e-02,\n",
       "           1.5949e-01, -7.7079e-02,  2.7144e-02,  6.7659e-02, -5.8646e-01,\n",
       "           4.9703e-01],\n",
       "         [-1.0728e-01,  1.4994e-01,  1.9941e-01, -4.0987e-01, -9.0358e-02,\n",
       "          -2.1748e-01, -5.7419e-02, -2.3498e-01, -2.3638e-01,  1.4216e-02,\n",
       "           1.2161e-01, -7.2387e-02,  1.4871e-01,  1.7265e-01, -5.0408e-01,\n",
       "           4.6045e-01],\n",
       "         [-2.7463e-01,  1.4564e-01,  9.7663e-02, -3.0300e-01, -4.3131e-02,\n",
       "          -1.0051e-01, -1.5073e-01, -1.3631e-01, -4.9155e-01, -1.7198e-01,\n",
       "           1.2484e-01, -4.4472e-02,  1.0056e-01,  4.8221e-02, -5.6625e-01,\n",
       "           3.7031e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./out/more.txt', 'w+') as f:\n",
    "    f.write('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "323baaede7499c3add454d1af5add592c6ed0fd69b14735d6fe682854c9d6878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
