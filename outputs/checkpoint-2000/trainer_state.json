{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.369426751592357,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 5.6759,
      "step": 1
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.000000000000001e-06,
      "loss": 9.2278,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 6e-06,
      "loss": 9.4527,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 8.000000000000001e-06,
      "loss": 8.6189,
      "step": 4
    },
    {
      "epoch": 0.02,
      "learning_rate": 1e-05,
      "loss": 9.4267,
      "step": 5
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.2e-05,
      "loss": 8.9336,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 8.5892,
      "step": 7
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 9.3676,
      "step": 8
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.8e-05,
      "loss": 9.5714,
      "step": 9
    },
    {
      "epoch": 0.03,
      "learning_rate": 2e-05,
      "loss": 9.7373,
      "step": 10
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 4.81,
      "step": 11
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.4e-05,
      "loss": 8.827,
      "step": 12
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 9.4198,
      "step": 13
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 8.4715,
      "step": 14
    },
    {
      "epoch": 0.05,
      "learning_rate": 3e-05,
      "loss": 8.1328,
      "step": 15
    },
    {
      "epoch": 0.05,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 9.1683,
      "step": 16
    },
    {
      "epoch": 0.05,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 8.1505,
      "step": 17
    },
    {
      "epoch": 0.06,
      "learning_rate": 3.6e-05,
      "loss": 8.612,
      "step": 18
    },
    {
      "epoch": 0.06,
      "learning_rate": 3.8e-05,
      "loss": 9.6851,
      "step": 19
    },
    {
      "epoch": 0.06,
      "learning_rate": 4e-05,
      "loss": 9.1717,
      "step": 20
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.2e-05,
      "loss": 9.816,
      "step": 21
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 8.4455,
      "step": 22
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.600000000000001e-05,
      "loss": 9.7776,
      "step": 23
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.8e-05,
      "loss": 9.2504,
      "step": 24
    },
    {
      "epoch": 0.08,
      "learning_rate": 5e-05,
      "loss": 8.4986,
      "step": 25
    },
    {
      "epoch": 0.08,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 7.5105,
      "step": 26
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 9.7485,
      "step": 27
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 8.8211,
      "step": 28
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.8e-05,
      "loss": 7.476,
      "step": 29
    },
    {
      "epoch": 0.1,
      "learning_rate": 6e-05,
      "loss": 6.8175,
      "step": 30
    },
    {
      "epoch": 0.1,
      "learning_rate": 6.2e-05,
      "loss": 7.5066,
      "step": 31
    },
    {
      "epoch": 0.1,
      "learning_rate": 6.400000000000001e-05,
      "loss": 9.8417,
      "step": 32
    },
    {
      "epoch": 0.11,
      "learning_rate": 6.6e-05,
      "loss": 4.3675,
      "step": 33
    },
    {
      "epoch": 0.11,
      "learning_rate": 6.800000000000001e-05,
      "loss": 9.0861,
      "step": 34
    },
    {
      "epoch": 0.11,
      "learning_rate": 7e-05,
      "loss": 9.5019,
      "step": 35
    },
    {
      "epoch": 0.11,
      "learning_rate": 7.2e-05,
      "loss": 6.9603,
      "step": 36
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.4e-05,
      "loss": 7.9824,
      "step": 37
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.6e-05,
      "loss": 8.6069,
      "step": 38
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.800000000000001e-05,
      "loss": 9.3592,
      "step": 39
    },
    {
      "epoch": 0.13,
      "learning_rate": 8e-05,
      "loss": 8.4133,
      "step": 40
    },
    {
      "epoch": 0.13,
      "learning_rate": 8.2e-05,
      "loss": 8.4301,
      "step": 41
    },
    {
      "epoch": 0.13,
      "learning_rate": 8.4e-05,
      "loss": 8.6983,
      "step": 42
    },
    {
      "epoch": 0.14,
      "learning_rate": 8.6e-05,
      "loss": 7.871,
      "step": 43
    },
    {
      "epoch": 0.14,
      "learning_rate": 8.800000000000001e-05,
      "loss": 6.625,
      "step": 44
    },
    {
      "epoch": 0.14,
      "learning_rate": 9e-05,
      "loss": 9.6215,
      "step": 45
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.200000000000001e-05,
      "loss": 6.1227,
      "step": 46
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.4e-05,
      "loss": 6.2597,
      "step": 47
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.6e-05,
      "loss": 7.4782,
      "step": 48
    },
    {
      "epoch": 0.16,
      "learning_rate": 9.8e-05,
      "loss": 7.3345,
      "step": 49
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0001,
      "loss": 7.3749,
      "step": 50
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00010200000000000001,
      "loss": 7.5089,
      "step": 51
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010400000000000001,
      "loss": 8.4622,
      "step": 52
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010600000000000002,
      "loss": 7.596,
      "step": 53
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010800000000000001,
      "loss": 7.5764,
      "step": 54
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011000000000000002,
      "loss": 7.4765,
      "step": 55
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011200000000000001,
      "loss": 6.9692,
      "step": 56
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011399999999999999,
      "loss": 4.5377,
      "step": 57
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.000116,
      "loss": 6.4749,
      "step": 58
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.000118,
      "loss": 6.0114,
      "step": 59
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00012,
      "loss": 6.0493,
      "step": 60
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.000122,
      "loss": 7.3822,
      "step": 61
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000124,
      "loss": 7.3809,
      "step": 62
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000126,
      "loss": 6.5897,
      "step": 63
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00012800000000000002,
      "loss": 7.1372,
      "step": 64
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00013000000000000002,
      "loss": 6.3058,
      "step": 65
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000132,
      "loss": 8.5667,
      "step": 66
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000134,
      "loss": 7.3077,
      "step": 67
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00013600000000000003,
      "loss": 4.1507,
      "step": 68
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000138,
      "loss": 4.304,
      "step": 69
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00014,
      "loss": 7.6085,
      "step": 70
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000142,
      "loss": 7.8729,
      "step": 71
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000144,
      "loss": 5.9862,
      "step": 72
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000146,
      "loss": 4.8585,
      "step": 73
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000148,
      "loss": 5.9539,
      "step": 74
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00015000000000000001,
      "loss": 7.5589,
      "step": 75
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000152,
      "loss": 4.2443,
      "step": 76
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.000154,
      "loss": 6.1773,
      "step": 77
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00015600000000000002,
      "loss": 7.4156,
      "step": 78
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00015800000000000002,
      "loss": 7.0191,
      "step": 79
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00016,
      "loss": 6.8154,
      "step": 80
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000162,
      "loss": 6.8502,
      "step": 81
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000164,
      "loss": 3.7133,
      "step": 82
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000166,
      "loss": 4.3581,
      "step": 83
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000168,
      "loss": 7.735,
      "step": 84
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00017,
      "loss": 6.7878,
      "step": 85
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000172,
      "loss": 7.9771,
      "step": 86
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000174,
      "loss": 8.8283,
      "step": 87
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00017600000000000002,
      "loss": 7.6323,
      "step": 88
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00017800000000000002,
      "loss": 9.2068,
      "step": 89
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00018,
      "loss": 10.2254,
      "step": 90
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000182,
      "loss": 10.2572,
      "step": 91
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00018400000000000003,
      "loss": 12.3211,
      "step": 92
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00018600000000000002,
      "loss": 15.0841,
      "step": 93
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000188,
      "loss": 15.8401,
      "step": 94
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019,
      "loss": 11.6177,
      "step": 95
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000192,
      "loss": 14.7587,
      "step": 96
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000194,
      "loss": 14.2408,
      "step": 97
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000196,
      "loss": 16.1382,
      "step": 98
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019800000000000002,
      "loss": 13.3746,
      "step": 99
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0002,
      "loss": 12.5751,
      "step": 100
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001999342105263158,
      "loss": 15.0125,
      "step": 101
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019986842105263158,
      "loss": 14.2702,
      "step": 102
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019980263157894738,
      "loss": 17.4569,
      "step": 103
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019973684210526318,
      "loss": 18.9482,
      "step": 104
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019967105263157895,
      "loss": 17.2836,
      "step": 105
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019960526315789475,
      "loss": 18.7006,
      "step": 106
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019953947368421052,
      "loss": 14.9285,
      "step": 107
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019947368421052632,
      "loss": 21.1089,
      "step": 108
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019940789473684212,
      "loss": 23.3173,
      "step": 109
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019934210526315792,
      "loss": 21.0636,
      "step": 110
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001992763157894737,
      "loss": 21.6619,
      "step": 111
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001992105263157895,
      "loss": 19.745,
      "step": 112
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019914473684210526,
      "loss": 20.1038,
      "step": 113
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019907894736842106,
      "loss": 19.316,
      "step": 114
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019901315789473684,
      "loss": 14.8836,
      "step": 115
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019894736842105264,
      "loss": 16.9176,
      "step": 116
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019888157894736843,
      "loss": 17.8174,
      "step": 117
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019881578947368423,
      "loss": 17.3609,
      "step": 118
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019875,
      "loss": 26.439,
      "step": 119
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0001986842105263158,
      "loss": 25.0461,
      "step": 120
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001986184210526316,
      "loss": 25.2197,
      "step": 121
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019855263157894738,
      "loss": 24.4505,
      "step": 122
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019848684210526315,
      "loss": 23.6123,
      "step": 123
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019842105263157895,
      "loss": 22.9074,
      "step": 124
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019835526315789475,
      "loss": 22.7362,
      "step": 125
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019828947368421055,
      "loss": 21.6091,
      "step": 126
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019822368421052632,
      "loss": 19.4497,
      "step": 127
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019815789473684212,
      "loss": 19.4096,
      "step": 128
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019809210526315792,
      "loss": 18.7741,
      "step": 129
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019802631578947372,
      "loss": 20.7739,
      "step": 130
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019796052631578946,
      "loss": 20.3023,
      "step": 131
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019789473684210526,
      "loss": 21.2262,
      "step": 132
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019782894736842106,
      "loss": 20.9764,
      "step": 133
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019776315789473686,
      "loss": 22.2753,
      "step": 134
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019769736842105263,
      "loss": 22.8083,
      "step": 135
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019763157894736843,
      "loss": 20.9484,
      "step": 136
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019756578947368423,
      "loss": 20.5682,
      "step": 137
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019750000000000003,
      "loss": 20.5759,
      "step": 138
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019743421052631578,
      "loss": 20.1925,
      "step": 139
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019736842105263157,
      "loss": 20.512,
      "step": 140
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019730263157894737,
      "loss": 21.4372,
      "step": 141
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019723684210526317,
      "loss": 22.2215,
      "step": 142
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019717105263157895,
      "loss": 21.6497,
      "step": 143
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019710526315789474,
      "loss": 26.202,
      "step": 144
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019703947368421054,
      "loss": 21.6811,
      "step": 145
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019697368421052634,
      "loss": 26.7222,
      "step": 146
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019690789473684212,
      "loss": 25.9274,
      "step": 147
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001968421052631579,
      "loss": 26.9116,
      "step": 148
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001967763157894737,
      "loss": 24.3339,
      "step": 149
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019671052631578949,
      "loss": 21.4098,
      "step": 150
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019664473684210526,
      "loss": 20.1031,
      "step": 151
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019657894736842106,
      "loss": 19.152,
      "step": 152
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019651315789473686,
      "loss": 16.4297,
      "step": 153
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019644736842105266,
      "loss": 15.4417,
      "step": 154
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019638157894736843,
      "loss": 14.7011,
      "step": 155
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019631578947368423,
      "loss": 14.088,
      "step": 156
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019625,
      "loss": 12.7674,
      "step": 157
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001961842105263158,
      "loss": 12.9194,
      "step": 158
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019611842105263157,
      "loss": 13.8197,
      "step": 159
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019605263157894737,
      "loss": 14.4543,
      "step": 160
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019598684210526317,
      "loss": 13.4982,
      "step": 161
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019592105263157897,
      "loss": 14.1973,
      "step": 162
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019585526315789474,
      "loss": 14.267,
      "step": 163
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019578947368421054,
      "loss": 14.1564,
      "step": 164
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001957236842105263,
      "loss": 15.358,
      "step": 165
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001956578947368421,
      "loss": 16.713,
      "step": 166
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001955921052631579,
      "loss": 13.721,
      "step": 167
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019552631578947368,
      "loss": 15.4837,
      "step": 168
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019546052631578948,
      "loss": 14.3886,
      "step": 169
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019539473684210528,
      "loss": 15.0899,
      "step": 170
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019532894736842105,
      "loss": 13.3579,
      "step": 171
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019526315789473685,
      "loss": 10.1595,
      "step": 172
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019519736842105265,
      "loss": 15.9625,
      "step": 173
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019513157894736843,
      "loss": 15.9005,
      "step": 174
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019506578947368422,
      "loss": 16.9157,
      "step": 175
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000195,
      "loss": 12.9977,
      "step": 176
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0001949342105263158,
      "loss": 15.3704,
      "step": 177
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0001948684210526316,
      "loss": 14.6059,
      "step": 178
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0001948026315789474,
      "loss": 14.3655,
      "step": 179
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019473684210526317,
      "loss": 13.2713,
      "step": 180
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019467105263157897,
      "loss": 11.8176,
      "step": 181
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019460526315789477,
      "loss": 8.8979,
      "step": 182
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019453947368421054,
      "loss": 9.9099,
      "step": 183
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001944736842105263,
      "loss": 9.3891,
      "step": 184
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001944078947368421,
      "loss": 11.6557,
      "step": 185
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001943421052631579,
      "loss": 12.4879,
      "step": 186
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0001942763157894737,
      "loss": 11.0896,
      "step": 187
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019421052631578948,
      "loss": 11.038,
      "step": 188
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019414473684210528,
      "loss": 12.7242,
      "step": 189
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019407894736842108,
      "loss": 12.0118,
      "step": 190
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019401315789473685,
      "loss": 10.5594,
      "step": 191
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019394736842105262,
      "loss": 10.2826,
      "step": 192
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019388157894736842,
      "loss": 12.2551,
      "step": 193
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019381578947368422,
      "loss": 10.3004,
      "step": 194
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019375000000000002,
      "loss": 10.8729,
      "step": 195
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001936842105263158,
      "loss": 11.7561,
      "step": 196
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001936184210526316,
      "loss": 9.4648,
      "step": 197
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001935526315789474,
      "loss": 10.7901,
      "step": 198
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001934868421052632,
      "loss": 10.9619,
      "step": 199
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019342105263157894,
      "loss": 11.6921,
      "step": 200
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019335526315789473,
      "loss": 9.3315,
      "step": 201
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019328947368421053,
      "loss": 8.2806,
      "step": 202
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00019322368421052633,
      "loss": 6.7133,
      "step": 203
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001931578947368421,
      "loss": 8.271,
      "step": 204
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001930921052631579,
      "loss": 8.1684,
      "step": 205
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001930263157894737,
      "loss": 6.7519,
      "step": 206
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001929605263157895,
      "loss": 8.0853,
      "step": 207
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00019289473684210525,
      "loss": 7.4471,
      "step": 208
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019282894736842105,
      "loss": 7.2211,
      "step": 209
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019276315789473685,
      "loss": 8.7592,
      "step": 210
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019269736842105265,
      "loss": 8.8813,
      "step": 211
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019263157894736842,
      "loss": 9.274,
      "step": 212
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019256578947368422,
      "loss": 7.5105,
      "step": 213
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019250000000000002,
      "loss": 7.1429,
      "step": 214
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019243421052631582,
      "loss": 9.2634,
      "step": 215
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001923684210526316,
      "loss": 6.715,
      "step": 216
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019230263157894736,
      "loss": 10.9345,
      "step": 217
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019223684210526316,
      "loss": 7.6129,
      "step": 218
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019217105263157896,
      "loss": 12.159,
      "step": 219
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019210526315789473,
      "loss": 9.8723,
      "step": 220
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019203947368421053,
      "loss": 8.8281,
      "step": 221
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019197368421052633,
      "loss": 8.7621,
      "step": 222
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019190789473684213,
      "loss": 10.7565,
      "step": 223
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0001918421052631579,
      "loss": 9.7459,
      "step": 224
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0001917763157894737,
      "loss": 9.4441,
      "step": 225
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019171052631578947,
      "loss": 8.9404,
      "step": 226
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019164473684210527,
      "loss": 8.0429,
      "step": 227
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019157894736842104,
      "loss": 7.2789,
      "step": 228
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019151315789473684,
      "loss": 8.0291,
      "step": 229
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019144736842105264,
      "loss": 8.3912,
      "step": 230
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019138157894736844,
      "loss": 8.727,
      "step": 231
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019131578947368421,
      "loss": 7.2409,
      "step": 232
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019125000000000001,
      "loss": 9.7089,
      "step": 233
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019118421052631579,
      "loss": 10.3189,
      "step": 234
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019111842105263159,
      "loss": 8.1965,
      "step": 235
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019105263157894738,
      "loss": 8.7254,
      "step": 236
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019098684210526316,
      "loss": 9.6717,
      "step": 237
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019092105263157896,
      "loss": 5.7683,
      "step": 238
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019085526315789476,
      "loss": 6.8171,
      "step": 239
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019078947368421053,
      "loss": 7.7083,
      "step": 240
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00019072368421052633,
      "loss": 7.6909,
      "step": 241
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00019065789473684213,
      "loss": 7.2135,
      "step": 242
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0001905921052631579,
      "loss": 8.3113,
      "step": 243
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0001905263157894737,
      "loss": 8.024,
      "step": 244
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019046052631578947,
      "loss": 8.7761,
      "step": 245
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019039473684210527,
      "loss": 7.7232,
      "step": 246
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019032894736842107,
      "loss": 10.4809,
      "step": 247
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019026315789473687,
      "loss": 9.9043,
      "step": 248
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019019736842105264,
      "loss": 6.0337,
      "step": 249
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019013157894736844,
      "loss": 11.841,
      "step": 250
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019006578947368424,
      "loss": 11.4816,
      "step": 251
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019,
      "loss": 11.2749,
      "step": 252
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018993421052631578,
      "loss": 8.9063,
      "step": 253
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018986842105263158,
      "loss": 10.5343,
      "step": 254
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018980263157894738,
      "loss": 10.3194,
      "step": 255
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018973684210526318,
      "loss": 9.7584,
      "step": 256
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018967105263157895,
      "loss": 14.4965,
      "step": 257
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018960526315789475,
      "loss": 16.4215,
      "step": 258
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018953947368421055,
      "loss": 19.8624,
      "step": 259
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00018947368421052632,
      "loss": 17.3915,
      "step": 260
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0001894078947368421,
      "loss": 16.7317,
      "step": 261
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0001893421052631579,
      "loss": 18.0015,
      "step": 262
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0001892763157894737,
      "loss": 16.0877,
      "step": 263
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0001892105263157895,
      "loss": 13.1755,
      "step": 264
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00018914473684210527,
      "loss": 14.4097,
      "step": 265
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018907894736842106,
      "loss": 13.2824,
      "step": 266
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018901315789473686,
      "loss": 13.7581,
      "step": 267
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018894736842105266,
      "loss": 16.5712,
      "step": 268
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001888815789473684,
      "loss": 13.5035,
      "step": 269
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001888157894736842,
      "loss": 11.8915,
      "step": 270
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00018875,
      "loss": 14.5707,
      "step": 271
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001886842105263158,
      "loss": 15.5897,
      "step": 272
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00018861842105263158,
      "loss": 14.7081,
      "step": 273
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00018855263157894738,
      "loss": 15.2912,
      "step": 274
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018848684210526318,
      "loss": 18.1013,
      "step": 275
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018842105263157898,
      "loss": 20.8701,
      "step": 276
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018835526315789475,
      "loss": 21.7741,
      "step": 277
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018828947368421052,
      "loss": 21.4064,
      "step": 278
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018822368421052632,
      "loss": 18.6123,
      "step": 279
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018815789473684212,
      "loss": 15.0317,
      "step": 280
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001880921052631579,
      "loss": 15.7044,
      "step": 281
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001880263157894737,
      "loss": 14.9149,
      "step": 282
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001879605263157895,
      "loss": 13.1727,
      "step": 283
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001878947368421053,
      "loss": 14.759,
      "step": 284
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018782894736842106,
      "loss": 15.3887,
      "step": 285
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018776315789473683,
      "loss": 13.0587,
      "step": 286
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018769736842105263,
      "loss": 12.1497,
      "step": 287
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00018763157894736843,
      "loss": 11.5455,
      "step": 288
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0001875657894736842,
      "loss": 14.0392,
      "step": 289
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0001875,
      "loss": 14.5723,
      "step": 290
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001874342105263158,
      "loss": 11.7874,
      "step": 291
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001873684210526316,
      "loss": 12.3434,
      "step": 292
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00018730263157894737,
      "loss": 12.4035,
      "step": 293
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018723684210526317,
      "loss": 11.6886,
      "step": 294
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018717105263157895,
      "loss": 9.0142,
      "step": 295
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018710526315789475,
      "loss": 11.394,
      "step": 296
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018703947368421052,
      "loss": 9.7303,
      "step": 297
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018697368421052632,
      "loss": 8.1218,
      "step": 298
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018690789473684212,
      "loss": 7.3644,
      "step": 299
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018684210526315792,
      "loss": 8.3423,
      "step": 300
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001867763157894737,
      "loss": 5.6038,
      "step": 301
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001867105263157895,
      "loss": 7.4735,
      "step": 302
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018664473684210526,
      "loss": 6.4936,
      "step": 303
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018657894736842106,
      "loss": 11.1872,
      "step": 304
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018651315789473686,
      "loss": 7.7247,
      "step": 305
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018644736842105263,
      "loss": 7.2046,
      "step": 306
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018638157894736843,
      "loss": 8.2687,
      "step": 307
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018631578947368423,
      "loss": 7.922,
      "step": 308
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018625,
      "loss": 7.9956,
      "step": 309
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001861842105263158,
      "loss": 6.3759,
      "step": 310
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001861184210526316,
      "loss": 7.5518,
      "step": 311
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00018605263157894737,
      "loss": 8.8418,
      "step": 312
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018598684210526317,
      "loss": 7.6948,
      "step": 313
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018592105263157894,
      "loss": 6.7944,
      "step": 314
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018585526315789474,
      "loss": 6.6822,
      "step": 315
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00018578947368421054,
      "loss": 5.7927,
      "step": 316
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00018572368421052634,
      "loss": 7.7049,
      "step": 317
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0001856578947368421,
      "loss": 9.1632,
      "step": 318
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001855921052631579,
      "loss": 7.6945,
      "step": 319
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001855263157894737,
      "loss": 6.2945,
      "step": 320
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00018546052631578948,
      "loss": 5.1819,
      "step": 321
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018539473684210526,
      "loss": 6.5901,
      "step": 322
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018532894736842106,
      "loss": 7.983,
      "step": 323
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018526315789473685,
      "loss": 9.2046,
      "step": 324
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018519736842105265,
      "loss": 6.5659,
      "step": 325
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018513157894736843,
      "loss": 6.6954,
      "step": 326
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018506578947368423,
      "loss": 6.4781,
      "step": 327
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018500000000000002,
      "loss": 6.9963,
      "step": 328
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001849342105263158,
      "loss": 6.6482,
      "step": 329
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00018486842105263157,
      "loss": 6.9935,
      "step": 330
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00018480263157894737,
      "loss": 7.8637,
      "step": 331
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018473684210526317,
      "loss": 7.0802,
      "step": 332
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018467105263157897,
      "loss": 7.8831,
      "step": 333
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018460526315789474,
      "loss": 6.8677,
      "step": 334
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018453947368421054,
      "loss": 9.8019,
      "step": 335
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018447368421052634,
      "loss": 6.0277,
      "step": 336
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018440789473684214,
      "loss": 10.1787,
      "step": 337
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018434210526315788,
      "loss": 8.1094,
      "step": 338
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018427631578947368,
      "loss": 9.9001,
      "step": 339
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018421052631578948,
      "loss": 9.9737,
      "step": 340
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018414473684210528,
      "loss": 7.9358,
      "step": 341
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018407894736842105,
      "loss": 9.7837,
      "step": 342
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018401315789473685,
      "loss": 8.2897,
      "step": 343
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018394736842105265,
      "loss": 9.2263,
      "step": 344
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018388157894736845,
      "loss": 9.9906,
      "step": 345
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018381578947368422,
      "loss": 8.6699,
      "step": 346
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00018375,
      "loss": 8.8681,
      "step": 347
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0001836842105263158,
      "loss": 9.8318,
      "step": 348
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0001836184210526316,
      "loss": 8.1051,
      "step": 349
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00018355263157894736,
      "loss": 11.4609,
      "step": 350
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018348684210526316,
      "loss": 11.2862,
      "step": 351
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018342105263157896,
      "loss": 12.2515,
      "step": 352
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018335526315789476,
      "loss": 11.3103,
      "step": 353
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00018328947368421053,
      "loss": 8.2848,
      "step": 354
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001832236842105263,
      "loss": 9.6668,
      "step": 355
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001831578947368421,
      "loss": 11.3855,
      "step": 356
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0001830921052631579,
      "loss": 10.8505,
      "step": 357
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00018302631578947368,
      "loss": 11.7766,
      "step": 358
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00018296052631578948,
      "loss": 10.8459,
      "step": 359
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018289473684210528,
      "loss": 11.4489,
      "step": 360
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018282894736842108,
      "loss": 11.3321,
      "step": 361
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018276315789473685,
      "loss": 12.6805,
      "step": 362
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018269736842105265,
      "loss": 11.6585,
      "step": 363
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018263157894736842,
      "loss": 9.2467,
      "step": 364
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018256578947368422,
      "loss": 10.3239,
      "step": 365
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001825,
      "loss": 9.0767,
      "step": 366
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001824342105263158,
      "loss": 8.9068,
      "step": 367
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001823684210526316,
      "loss": 9.4668,
      "step": 368
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0001823026315789474,
      "loss": 9.7107,
      "step": 369
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018223684210526316,
      "loss": 5.056,
      "step": 370
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018217105263157896,
      "loss": 9.0235,
      "step": 371
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018210526315789476,
      "loss": 7.2697,
      "step": 372
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00018203947368421053,
      "loss": 8.1155,
      "step": 373
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00018197368421052633,
      "loss": 9.6886,
      "step": 374
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0001819078947368421,
      "loss": 8.714,
      "step": 375
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0001818421052631579,
      "loss": 7.6017,
      "step": 376
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0001817763157894737,
      "loss": 8.3032,
      "step": 377
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00018171052631578947,
      "loss": 9.767,
      "step": 378
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018164473684210527,
      "loss": 6.8952,
      "step": 379
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018157894736842107,
      "loss": 7.7691,
      "step": 380
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018151315789473684,
      "loss": 7.4938,
      "step": 381
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018144736842105264,
      "loss": 7.8102,
      "step": 382
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018138157894736842,
      "loss": 8.4985,
      "step": 383
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018131578947368422,
      "loss": 7.6459,
      "step": 384
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018125000000000001,
      "loss": 8.5635,
      "step": 385
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018118421052631581,
      "loss": 5.0362,
      "step": 386
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018111842105263159,
      "loss": 5.7943,
      "step": 387
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018105263157894739,
      "loss": 6.2967,
      "step": 388
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018098684210526318,
      "loss": 9.3257,
      "step": 389
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018092105263157896,
      "loss": 6.6711,
      "step": 390
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018085526315789473,
      "loss": 7.1532,
      "step": 391
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018078947368421053,
      "loss": 7.2052,
      "step": 392
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018072368421052633,
      "loss": 8.6348,
      "step": 393
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018065789473684213,
      "loss": 7.0797,
      "step": 394
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001805921052631579,
      "loss": 6.7545,
      "step": 395
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001805263157894737,
      "loss": 5.9885,
      "step": 396
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001804605263157895,
      "loss": 6.6452,
      "step": 397
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018039473684210527,
      "loss": 7.8825,
      "step": 398
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018032894736842104,
      "loss": 6.7477,
      "step": 399
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018026315789473684,
      "loss": 7.6022,
      "step": 400
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00018019736842105264,
      "loss": 5.2887,
      "step": 401
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00018013157894736844,
      "loss": 7.0855,
      "step": 402
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0001800657894736842,
      "loss": 7.6928,
      "step": 403
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00018,
      "loss": 7.0171,
      "step": 404
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0001799342105263158,
      "loss": 9.5572,
      "step": 405
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0001798684210526316,
      "loss": 8.4234,
      "step": 406
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017980263157894735,
      "loss": 9.627,
      "step": 407
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017973684210526315,
      "loss": 8.5001,
      "step": 408
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017967105263157895,
      "loss": 8.0787,
      "step": 409
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017960526315789475,
      "loss": 6.5977,
      "step": 410
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017953947368421053,
      "loss": 5.0208,
      "step": 411
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017947368421052632,
      "loss": 6.9425,
      "step": 412
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017940789473684212,
      "loss": 7.6974,
      "step": 413
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017934210526315792,
      "loss": 5.2986,
      "step": 414
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0001792763157894737,
      "loss": 8.2266,
      "step": 415
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017921052631578947,
      "loss": 8.156,
      "step": 416
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017914473684210527,
      "loss": 7.4764,
      "step": 417
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017907894736842107,
      "loss": 8.3185,
      "step": 418
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017901315789473684,
      "loss": 7.6152,
      "step": 419
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017894736842105264,
      "loss": 6.6326,
      "step": 420
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017888157894736844,
      "loss": 8.4163,
      "step": 421
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017881578947368424,
      "loss": 6.695,
      "step": 422
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017875,
      "loss": 8.7324,
      "step": 423
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017868421052631578,
      "loss": 6.9342,
      "step": 424
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017861842105263158,
      "loss": 11.035,
      "step": 425
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017855263157894738,
      "loss": 11.0419,
      "step": 426
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017848684210526315,
      "loss": 9.4253,
      "step": 427
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017842105263157895,
      "loss": 12.7597,
      "step": 428
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017835526315789475,
      "loss": 6.5763,
      "step": 429
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017828947368421055,
      "loss": 10.4711,
      "step": 430
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017822368421052632,
      "loss": 9.7972,
      "step": 431
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00017815789473684212,
      "loss": 6.1812,
      "step": 432
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001780921052631579,
      "loss": 11.0408,
      "step": 433
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001780263157894737,
      "loss": 11.1766,
      "step": 434
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0001779605263157895,
      "loss": 10.0879,
      "step": 435
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017789473684210526,
      "loss": 9.0864,
      "step": 436
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017782894736842106,
      "loss": 7.6043,
      "step": 437
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017776315789473686,
      "loss": 9.8173,
      "step": 438
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017769736842105263,
      "loss": 9.3867,
      "step": 439
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017763157894736843,
      "loss": 8.2974,
      "step": 440
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017756578947368423,
      "loss": 9.8381,
      "step": 441
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001775,
      "loss": 7.1877,
      "step": 442
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001774342105263158,
      "loss": 7.7126,
      "step": 443
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00017736842105263158,
      "loss": 6.5377,
      "step": 444
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017730263157894738,
      "loss": 9.8501,
      "step": 445
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017723684210526317,
      "loss": 8.0838,
      "step": 446
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017717105263157895,
      "loss": 4.8709,
      "step": 447
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017710526315789475,
      "loss": 7.4893,
      "step": 448
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017703947368421055,
      "loss": 8.3785,
      "step": 449
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017697368421052632,
      "loss": 8.3244,
      "step": 450
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00017690789473684212,
      "loss": 9.8595,
      "step": 451
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001768421052631579,
      "loss": 9.4643,
      "step": 452
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001767763157894737,
      "loss": 4.4912,
      "step": 453
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0001767105263157895,
      "loss": 8.6767,
      "step": 454
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0001766447368421053,
      "loss": 8.941,
      "step": 455
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00017657894736842106,
      "loss": 6.4551,
      "step": 456
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017651315789473686,
      "loss": 10.098,
      "step": 457
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017644736842105266,
      "loss": 7.2525,
      "step": 458
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017638157894736843,
      "loss": 9.5392,
      "step": 459
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0001763157894736842,
      "loss": 7.7694,
      "step": 460
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00017625,
      "loss": 10.5878,
      "step": 461
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001761842105263158,
      "loss": 8.6952,
      "step": 462
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001761184210526316,
      "loss": 8.1309,
      "step": 463
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017605263157894737,
      "loss": 8.6866,
      "step": 464
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017598684210526317,
      "loss": 9.2521,
      "step": 465
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017592105263157897,
      "loss": 6.3651,
      "step": 466
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017585526315789474,
      "loss": 6.9983,
      "step": 467
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017578947368421052,
      "loss": 8.9906,
      "step": 468
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017572368421052631,
      "loss": 7.0841,
      "step": 469
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017565789473684211,
      "loss": 7.6972,
      "step": 470
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0001755921052631579,
      "loss": 7.7349,
      "step": 471
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017552631578947369,
      "loss": 6.2193,
      "step": 472
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017546052631578948,
      "loss": 6.4108,
      "step": 473
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017539473684210528,
      "loss": 8.5691,
      "step": 474
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017532894736842108,
      "loss": 8.0335,
      "step": 475
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017526315789473683,
      "loss": 7.9568,
      "step": 476
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017519736842105263,
      "loss": 7.407,
      "step": 477
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017513157894736843,
      "loss": 6.7954,
      "step": 478
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00017506578947368423,
      "loss": 7.835,
      "step": 479
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000175,
      "loss": 6.0811,
      "step": 480
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0001749342105263158,
      "loss": 9.3357,
      "step": 481
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001748684210526316,
      "loss": 7.903,
      "step": 482
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001748026315789474,
      "loss": 7.2982,
      "step": 483
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00017473684210526317,
      "loss": 9.1905,
      "step": 484
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00017467105263157894,
      "loss": 8.2641,
      "step": 485
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00017460526315789474,
      "loss": 8.5395,
      "step": 486
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00017453947368421054,
      "loss": 8.9992,
      "step": 487
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0001744736842105263,
      "loss": 7.5806,
      "step": 488
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001744078947368421,
      "loss": 6.2173,
      "step": 489
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001743421052631579,
      "loss": 6.139,
      "step": 490
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001742763157894737,
      "loss": 8.873,
      "step": 491
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017421052631578948,
      "loss": 6.3816,
      "step": 492
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017414473684210525,
      "loss": 8.0174,
      "step": 493
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017407894736842105,
      "loss": 7.3974,
      "step": 494
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017401315789473685,
      "loss": 7.5018,
      "step": 495
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017394736842105262,
      "loss": 8.9115,
      "step": 496
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017388157894736842,
      "loss": 5.7531,
      "step": 497
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00017381578947368422,
      "loss": 8.8558,
      "step": 498
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00017375000000000002,
      "loss": 5.3447,
      "step": 499
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001736842105263158,
      "loss": 5.8546,
      "step": 500
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001736184210526316,
      "loss": 5.2057,
      "step": 501
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00017355263157894737,
      "loss": 7.0328,
      "step": 502
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00017348684210526316,
      "loss": 7.5172,
      "step": 503
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017342105263157896,
      "loss": 9.4729,
      "step": 504
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017335526315789474,
      "loss": 6.3143,
      "step": 505
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017328947368421054,
      "loss": 6.094,
      "step": 506
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017322368421052634,
      "loss": 6.535,
      "step": 507
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001731578947368421,
      "loss": 6.1028,
      "step": 508
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001730921052631579,
      "loss": 7.2121,
      "step": 509
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001730263157894737,
      "loss": 5.3467,
      "step": 510
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017296052631578948,
      "loss": 7.8162,
      "step": 511
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017289473684210528,
      "loss": 5.9826,
      "step": 512
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017282894736842105,
      "loss": 4.9153,
      "step": 513
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017276315789473685,
      "loss": 5.1952,
      "step": 514
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017269736842105265,
      "loss": 9.6705,
      "step": 515
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017263157894736842,
      "loss": 4.0367,
      "step": 516
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00017256578947368422,
      "loss": 7.9563,
      "step": 517
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00017250000000000002,
      "loss": 7.6047,
      "step": 518
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001724342105263158,
      "loss": 7.3881,
      "step": 519
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001723684210526316,
      "loss": 5.9305,
      "step": 520
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00017230263157894736,
      "loss": 7.739,
      "step": 521
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00017223684210526316,
      "loss": 6.4404,
      "step": 522
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017217105263157896,
      "loss": 6.6856,
      "step": 523
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017210526315789476,
      "loss": 6.4346,
      "step": 524
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017203947368421053,
      "loss": 7.4347,
      "step": 525
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017197368421052633,
      "loss": 7.0139,
      "step": 526
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017190789473684213,
      "loss": 6.917,
      "step": 527
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001718421052631579,
      "loss": 8.8123,
      "step": 528
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017177631578947368,
      "loss": 8.1804,
      "step": 529
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017171052631578947,
      "loss": 8.0765,
      "step": 530
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017164473684210527,
      "loss": 7.6481,
      "step": 531
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017157894736842107,
      "loss": 7.5002,
      "step": 532
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017151315789473685,
      "loss": 5.4967,
      "step": 533
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017144736842105264,
      "loss": 5.7779,
      "step": 534
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017138157894736844,
      "loss": 7.4914,
      "step": 535
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00017131578947368422,
      "loss": 6.8433,
      "step": 536
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00017125,
      "loss": 7.821,
      "step": 537
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001711842105263158,
      "loss": 7.6259,
      "step": 538
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001711184210526316,
      "loss": 5.8863,
      "step": 539
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00017105263157894739,
      "loss": 4.9646,
      "step": 540
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00017098684210526316,
      "loss": 9.1112,
      "step": 541
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017092105263157896,
      "loss": 8.009,
      "step": 542
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017085526315789476,
      "loss": 6.8101,
      "step": 543
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017078947368421056,
      "loss": 7.6545,
      "step": 544
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001707236842105263,
      "loss": 6.2157,
      "step": 545
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001706578947368421,
      "loss": 7.5117,
      "step": 546
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001705921052631579,
      "loss": 6.2438,
      "step": 547
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0001705263157894737,
      "loss": 6.6676,
      "step": 548
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017046052631578947,
      "loss": 6.6791,
      "step": 549
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017039473684210527,
      "loss": 6.9335,
      "step": 550
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017032894736842107,
      "loss": 9.5455,
      "step": 551
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017026315789473687,
      "loss": 6.1273,
      "step": 552
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017019736842105264,
      "loss": 7.6874,
      "step": 553
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017013157894736841,
      "loss": 6.0116,
      "step": 554
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0001700657894736842,
      "loss": 7.4642,
      "step": 555
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00017,
      "loss": 8.0394,
      "step": 556
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00016993421052631578,
      "loss": 8.3467,
      "step": 557
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016986842105263158,
      "loss": 7.148,
      "step": 558
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016980263157894738,
      "loss": 7.0483,
      "step": 559
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016973684210526318,
      "loss": 9.3816,
      "step": 560
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016967105263157895,
      "loss": 4.5338,
      "step": 561
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016960526315789475,
      "loss": 8.1417,
      "step": 562
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016953947368421053,
      "loss": 6.4424,
      "step": 563
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.00016947368421052633,
      "loss": 5.439,
      "step": 564
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001694078947368421,
      "loss": 7.7598,
      "step": 565
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001693421052631579,
      "loss": 6.0347,
      "step": 566
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001692763157894737,
      "loss": 8.3304,
      "step": 567
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001692105263157895,
      "loss": 4.7275,
      "step": 568
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00016914473684210527,
      "loss": 6.6496,
      "step": 569
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016907894736842107,
      "loss": 5.6252,
      "step": 570
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016901315789473684,
      "loss": 7.7278,
      "step": 571
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016894736842105264,
      "loss": 5.3837,
      "step": 572
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016888157894736844,
      "loss": 7.6139,
      "step": 573
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0001688157894736842,
      "loss": 7.3205,
      "step": 574
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00016875,
      "loss": 5.8176,
      "step": 575
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0001686842105263158,
      "loss": 6.082,
      "step": 576
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016861842105263158,
      "loss": 7.3743,
      "step": 577
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016855263157894738,
      "loss": 5.2722,
      "step": 578
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016848684210526318,
      "loss": 8.1518,
      "step": 579
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016842105263157895,
      "loss": 7.4338,
      "step": 580
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016835526315789475,
      "loss": 5.2382,
      "step": 581
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016828947368421052,
      "loss": 6.7977,
      "step": 582
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016822368421052632,
      "loss": 6.5813,
      "step": 583
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016815789473684212,
      "loss": 5.9156,
      "step": 584
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0001680921052631579,
      "loss": 6.4112,
      "step": 585
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0001680263157894737,
      "loss": 5.3477,
      "step": 586
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0001679605263157895,
      "loss": 3.4396,
      "step": 587
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00016789473684210526,
      "loss": 6.8688,
      "step": 588
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016782894736842106,
      "loss": 6.5531,
      "step": 589
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016776315789473684,
      "loss": 8.3735,
      "step": 590
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016769736842105263,
      "loss": 7.5751,
      "step": 591
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016763157894736843,
      "loss": 8.2157,
      "step": 592
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016756578947368423,
      "loss": 6.4087,
      "step": 593
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0001675,
      "loss": 6.1903,
      "step": 594
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0001674342105263158,
      "loss": 5.2205,
      "step": 595
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0001673684210526316,
      "loss": 7.0044,
      "step": 596
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016730263157894738,
      "loss": 4.5823,
      "step": 597
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016723684210526315,
      "loss": 5.9253,
      "step": 598
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016717105263157895,
      "loss": 4.3104,
      "step": 599
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016710526315789475,
      "loss": 4.5051,
      "step": 600
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016703947368421055,
      "loss": 4.3634,
      "step": 601
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016697368421052632,
      "loss": 6.381,
      "step": 602
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016690789473684212,
      "loss": 6.5078,
      "step": 603
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016684210526315792,
      "loss": 6.8479,
      "step": 604
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0001667763157894737,
      "loss": 6.9782,
      "step": 605
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016671052631578946,
      "loss": 7.0489,
      "step": 606
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016664473684210526,
      "loss": 7.218,
      "step": 607
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016657894736842106,
      "loss": 6.8946,
      "step": 608
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016651315789473686,
      "loss": 5.0504,
      "step": 609
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016644736842105263,
      "loss": 6.9306,
      "step": 610
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016638157894736843,
      "loss": 5.0708,
      "step": 611
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016631578947368423,
      "loss": 8.3567,
      "step": 612
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016625000000000003,
      "loss": 5.7654,
      "step": 613
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016618421052631577,
      "loss": 7.5326,
      "step": 614
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016611842105263157,
      "loss": 7.3344,
      "step": 615
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016605263157894737,
      "loss": 7.5294,
      "step": 616
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016598684210526317,
      "loss": 6.3524,
      "step": 617
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016592105263157894,
      "loss": 7.1576,
      "step": 618
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016585526315789474,
      "loss": 6.4871,
      "step": 619
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016578947368421054,
      "loss": 6.1212,
      "step": 620
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016572368421052634,
      "loss": 6.6827,
      "step": 621
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016565789473684211,
      "loss": 7.6906,
      "step": 622
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0001655921052631579,
      "loss": 7.9251,
      "step": 623
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016552631578947369,
      "loss": 7.0462,
      "step": 624
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016546052631578949,
      "loss": 5.8511,
      "step": 625
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016539473684210526,
      "loss": 8.9401,
      "step": 626
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016532894736842106,
      "loss": 6.6981,
      "step": 627
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016526315789473686,
      "loss": 5.2718,
      "step": 628
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016519736842105266,
      "loss": 5.9845,
      "step": 629
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00016513157894736843,
      "loss": 6.7545,
      "step": 630
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00016506578947368423,
      "loss": 3.6693,
      "step": 631
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.000165,
      "loss": 7.8874,
      "step": 632
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0001649342105263158,
      "loss": 3.6892,
      "step": 633
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00016486842105263157,
      "loss": 4.8252,
      "step": 634
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00016480263157894737,
      "loss": 5.7972,
      "step": 635
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016473684210526317,
      "loss": 6.2797,
      "step": 636
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016467105263157897,
      "loss": 8.9891,
      "step": 637
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016460526315789474,
      "loss": 7.0017,
      "step": 638
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00016453947368421054,
      "loss": 8.5476,
      "step": 639
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001644736842105263,
      "loss": 5.6032,
      "step": 640
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001644078947368421,
      "loss": 4.7811,
      "step": 641
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001643421052631579,
      "loss": 6.067,
      "step": 642
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016427631578947368,
      "loss": 5.8464,
      "step": 643
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016421052631578948,
      "loss": 6.6472,
      "step": 644
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016414473684210528,
      "loss": 6.6265,
      "step": 645
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016407894736842105,
      "loss": 4.6543,
      "step": 646
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016401315789473685,
      "loss": 6.0185,
      "step": 647
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016394736842105265,
      "loss": 6.3654,
      "step": 648
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016388157894736842,
      "loss": 4.041,
      "step": 649
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016381578947368422,
      "loss": 6.3336,
      "step": 650
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016375,
      "loss": 8.414,
      "step": 651
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0001636842105263158,
      "loss": 7.434,
      "step": 652
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0001636184210526316,
      "loss": 3.7716,
      "step": 653
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00016355263157894737,
      "loss": 8.3403,
      "step": 654
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016348684210526317,
      "loss": 6.2682,
      "step": 655
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016342105263157897,
      "loss": 6.2844,
      "step": 656
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016335526315789476,
      "loss": 7.4151,
      "step": 657
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00016328947368421054,
      "loss": 6.6818,
      "step": 658
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001632236842105263,
      "loss": 8.6314,
      "step": 659
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001631578947368421,
      "loss": 6.9084,
      "step": 660
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0001630921052631579,
      "loss": 6.694,
      "step": 661
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0001630263157894737,
      "loss": 6.9694,
      "step": 662
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00016296052631578948,
      "loss": 6.711,
      "step": 663
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00016289473684210528,
      "loss": 8.012,
      "step": 664
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016282894736842108,
      "loss": 5.7472,
      "step": 665
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016276315789473685,
      "loss": 5.6348,
      "step": 666
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016269736842105262,
      "loss": 6.6843,
      "step": 667
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016263157894736842,
      "loss": 9.1781,
      "step": 668
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016256578947368422,
      "loss": 6.2448,
      "step": 669
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016250000000000002,
      "loss": 7.1374,
      "step": 670
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001624342105263158,
      "loss": 8.9919,
      "step": 671
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001623684210526316,
      "loss": 5.0703,
      "step": 672
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001623026315789474,
      "loss": 6.9487,
      "step": 673
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016223684210526316,
      "loss": 6.9791,
      "step": 674
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016217105263157893,
      "loss": 6.9609,
      "step": 675
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016210526315789473,
      "loss": 6.511,
      "step": 676
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00016203947368421053,
      "loss": 5.0456,
      "step": 677
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00016197368421052633,
      "loss": 4.7139,
      "step": 678
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0001619078947368421,
      "loss": 7.2923,
      "step": 679
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001618421052631579,
      "loss": 4.6535,
      "step": 680
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001617763157894737,
      "loss": 6.5314,
      "step": 681
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001617105263157895,
      "loss": 8.8248,
      "step": 682
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016164473684210525,
      "loss": 5.6368,
      "step": 683
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016157894736842105,
      "loss": 5.3128,
      "step": 684
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016151315789473685,
      "loss": 6.858,
      "step": 685
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016144736842105265,
      "loss": 8.1294,
      "step": 686
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016138157894736842,
      "loss": 3.6248,
      "step": 687
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016131578947368422,
      "loss": 5.5736,
      "step": 688
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016125000000000002,
      "loss": 7.8241,
      "step": 689
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00016118421052631582,
      "loss": 5.7889,
      "step": 690
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0001611184210526316,
      "loss": 7.7371,
      "step": 691
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00016105263157894736,
      "loss": 5.0423,
      "step": 692
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016098684210526316,
      "loss": 8.0954,
      "step": 693
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016092105263157896,
      "loss": 8.5545,
      "step": 694
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016085526315789473,
      "loss": 6.9751,
      "step": 695
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016078947368421053,
      "loss": 5.7838,
      "step": 696
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016072368421052633,
      "loss": 7.0672,
      "step": 697
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016065789473684213,
      "loss": 7.3838,
      "step": 698
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0001605921052631579,
      "loss": 5.1222,
      "step": 699
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0001605263157894737,
      "loss": 7.9851,
      "step": 700
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00016046052631578947,
      "loss": 6.7359,
      "step": 701
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016039473684210527,
      "loss": 6.4469,
      "step": 702
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016032894736842104,
      "loss": 9.1707,
      "step": 703
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016026315789473684,
      "loss": 7.643,
      "step": 704
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016019736842105264,
      "loss": 5.6455,
      "step": 705
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016013157894736844,
      "loss": 6.7616,
      "step": 706
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016006578947368421,
      "loss": 7.8844,
      "step": 707
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016,
      "loss": 7.1474,
      "step": 708
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015993421052631579,
      "loss": 6.6469,
      "step": 709
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015986842105263158,
      "loss": 7.9354,
      "step": 710
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015980263157894738,
      "loss": 5.6746,
      "step": 711
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015973684210526316,
      "loss": 7.4044,
      "step": 712
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015967105263157896,
      "loss": 5.5899,
      "step": 713
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015960526315789475,
      "loss": 6.221,
      "step": 714
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015953947368421053,
      "loss": 6.7536,
      "step": 715
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015947368421052633,
      "loss": 6.4945,
      "step": 716
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015940789473684213,
      "loss": 6.7731,
      "step": 717
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001593421052631579,
      "loss": 7.3555,
      "step": 718
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001592763157894737,
      "loss": 6.4165,
      "step": 719
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00015921052631578947,
      "loss": 7.2108,
      "step": 720
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015914473684210527,
      "loss": 5.5116,
      "step": 721
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015907894736842107,
      "loss": 5.2434,
      "step": 722
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015901315789473684,
      "loss": 6.2195,
      "step": 723
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015894736842105264,
      "loss": 6.9556,
      "step": 724
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015888157894736844,
      "loss": 6.5432,
      "step": 725
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015881578947368424,
      "loss": 5.8987,
      "step": 726
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015875,
      "loss": 6.538,
      "step": 727
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015868421052631578,
      "loss": 8.3281,
      "step": 728
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015861842105263158,
      "loss": 5.519,
      "step": 729
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015855263157894738,
      "loss": 7.948,
      "step": 730
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015848684210526318,
      "loss": 7.2478,
      "step": 731
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015842105263157895,
      "loss": 6.8984,
      "step": 732
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015835526315789475,
      "loss": 4.3433,
      "step": 733
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00015828947368421055,
      "loss": 7.5655,
      "step": 734
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00015822368421052632,
      "loss": 6.3821,
      "step": 735
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0001581578947368421,
      "loss": 6.0639,
      "step": 736
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001580921052631579,
      "loss": 7.3338,
      "step": 737
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001580263157894737,
      "loss": 7.3776,
      "step": 738
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001579605263157895,
      "loss": 6.675,
      "step": 739
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015789473684210527,
      "loss": 7.3202,
      "step": 740
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015782894736842106,
      "loss": 5.4583,
      "step": 741
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015776315789473686,
      "loss": 5.0976,
      "step": 742
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00015769736842105264,
      "loss": 5.0371,
      "step": 743
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0001576315789473684,
      "loss": 5.8948,
      "step": 744
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0001575657894736842,
      "loss": 6.8185,
      "step": 745
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0001575,
      "loss": 7.741,
      "step": 746
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0001574342105263158,
      "loss": 6.6126,
      "step": 747
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00015736842105263158,
      "loss": 5.6508,
      "step": 748
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015730263157894738,
      "loss": 5.7831,
      "step": 749
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015723684210526318,
      "loss": 7.2376,
      "step": 750
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015717105263157898,
      "loss": 7.1645,
      "step": 751
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015710526315789475,
      "loss": 7.2393,
      "step": 752
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015703947368421052,
      "loss": 8.1738,
      "step": 753
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015697368421052632,
      "loss": 6.4703,
      "step": 754
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015690789473684212,
      "loss": 7.816,
      "step": 755
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001568421052631579,
      "loss": 7.2473,
      "step": 756
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001567763157894737,
      "loss": 4.9348,
      "step": 757
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001567105263157895,
      "loss": 7.0899,
      "step": 758
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0001566447368421053,
      "loss": 7.0002,
      "step": 759
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00015657894736842106,
      "loss": 6.6266,
      "step": 760
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00015651315789473683,
      "loss": 4.9791,
      "step": 761
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00015644736842105263,
      "loss": 6.0215,
      "step": 762
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00015638157894736843,
      "loss": 6.4615,
      "step": 763
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0001563157894736842,
      "loss": 7.1153,
      "step": 764
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00015625,
      "loss": 7.9944,
      "step": 765
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0001561842105263158,
      "loss": 6.3988,
      "step": 766
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0001561184210526316,
      "loss": 5.3613,
      "step": 767
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015605263157894737,
      "loss": 5.2903,
      "step": 768
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015598684210526317,
      "loss": 4.8942,
      "step": 769
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015592105263157895,
      "loss": 3.4212,
      "step": 770
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015585526315789474,
      "loss": 5.8533,
      "step": 771
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015578947368421052,
      "loss": 7.2413,
      "step": 772
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015572368421052632,
      "loss": 6.6859,
      "step": 773
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015565789473684212,
      "loss": 6.0702,
      "step": 774
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00015559210526315791,
      "loss": 6.2573,
      "step": 775
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0001555263157894737,
      "loss": 7.8818,
      "step": 776
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00015546052631578949,
      "loss": 5.7124,
      "step": 777
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015539473684210526,
      "loss": 6.9013,
      "step": 778
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015532894736842106,
      "loss": 7.0208,
      "step": 779
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015526315789473686,
      "loss": 6.6827,
      "step": 780
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015519736842105263,
      "loss": 5.9441,
      "step": 781
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015513157894736843,
      "loss": 7.1122,
      "step": 782
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015506578947368423,
      "loss": 6.728,
      "step": 783
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.000155,
      "loss": 5.0752,
      "step": 784
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001549342105263158,
      "loss": 5.9231,
      "step": 785
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001548684210526316,
      "loss": 6.5907,
      "step": 786
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015480263157894737,
      "loss": 8.2295,
      "step": 787
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015473684210526317,
      "loss": 7.4967,
      "step": 788
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015467105263157894,
      "loss": 6.9904,
      "step": 789
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00015460526315789474,
      "loss": 4.3657,
      "step": 790
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00015453947368421054,
      "loss": 7.6279,
      "step": 791
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0001544736842105263,
      "loss": 5.5869,
      "step": 792
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001544078947368421,
      "loss": 5.9186,
      "step": 793
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001543421052631579,
      "loss": 7.4644,
      "step": 794
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001542763157894737,
      "loss": 6.3364,
      "step": 795
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015421052631578948,
      "loss": 6.8816,
      "step": 796
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015414473684210526,
      "loss": 8.3012,
      "step": 797
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015407894736842105,
      "loss": 5.454,
      "step": 798
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015401315789473685,
      "loss": 6.4431,
      "step": 799
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015394736842105265,
      "loss": 7.0492,
      "step": 800
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015388157894736843,
      "loss": 5.8384,
      "step": 801
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015381578947368422,
      "loss": 5.6661,
      "step": 802
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00015375000000000002,
      "loss": 5.2635,
      "step": 803
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0001536842105263158,
      "loss": 3.7131,
      "step": 804
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00015361842105263157,
      "loss": 6.6371,
      "step": 805
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015355263157894737,
      "loss": 6.4124,
      "step": 806
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015348684210526317,
      "loss": 5.9355,
      "step": 807
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015342105263157897,
      "loss": 5.1462,
      "step": 808
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015335526315789474,
      "loss": 5.3767,
      "step": 809
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015328947368421054,
      "loss": 6.8195,
      "step": 810
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015322368421052634,
      "loss": 4.4444,
      "step": 811
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0001531578947368421,
      "loss": 3.6598,
      "step": 812
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00015309210526315788,
      "loss": 4.9692,
      "step": 813
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00015302631578947368,
      "loss": 6.9108,
      "step": 814
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015296052631578948,
      "loss": 8.1998,
      "step": 815
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015289473684210528,
      "loss": 6.8161,
      "step": 816
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015282894736842105,
      "loss": 5.8481,
      "step": 817
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015276315789473685,
      "loss": 5.9156,
      "step": 818
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015269736842105265,
      "loss": 5.5674,
      "step": 819
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015263157894736845,
      "loss": 5.3137,
      "step": 820
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015256578947368422,
      "loss": 6.1893,
      "step": 821
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001525,
      "loss": 6.4184,
      "step": 822
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001524342105263158,
      "loss": 5.6095,
      "step": 823
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001523684210526316,
      "loss": 7.8894,
      "step": 824
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015230263157894736,
      "loss": 6.6889,
      "step": 825
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015223684210526316,
      "loss": 6.5747,
      "step": 826
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015217105263157896,
      "loss": 6.1156,
      "step": 827
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00015210526315789476,
      "loss": 5.8202,
      "step": 828
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00015203947368421053,
      "loss": 5.5123,
      "step": 829
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0001519736842105263,
      "loss": 5.2674,
      "step": 830
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0001519078947368421,
      "loss": 5.4908,
      "step": 831
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0001518421052631579,
      "loss": 6.4388,
      "step": 832
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00015177631578947368,
      "loss": 5.0561,
      "step": 833
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015171052631578948,
      "loss": 8.7734,
      "step": 834
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015164473684210528,
      "loss": 5.1529,
      "step": 835
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015157894736842108,
      "loss": 5.5235,
      "step": 836
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015151315789473685,
      "loss": 6.8769,
      "step": 837
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015144736842105265,
      "loss": 5.435,
      "step": 838
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015138157894736842,
      "loss": 3.8633,
      "step": 839
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00015131578947368422,
      "loss": 6.4536,
      "step": 840
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00015125,
      "loss": 6.767,
      "step": 841
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001511842105263158,
      "loss": 5.6768,
      "step": 842
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001511184210526316,
      "loss": 7.9853,
      "step": 843
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0001510526315789474,
      "loss": 6.7176,
      "step": 844
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00015098684210526316,
      "loss": 6.1393,
      "step": 845
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00015092105263157896,
      "loss": 3.9655,
      "step": 846
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015085526315789476,
      "loss": 6.1113,
      "step": 847
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015078947368421053,
      "loss": 5.4648,
      "step": 848
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015072368421052633,
      "loss": 5.6201,
      "step": 849
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001506578947368421,
      "loss": 5.8592,
      "step": 850
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001505921052631579,
      "loss": 4.605,
      "step": 851
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001505263157894737,
      "loss": 6.5752,
      "step": 852
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015046052631578947,
      "loss": 5.8605,
      "step": 853
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015039473684210527,
      "loss": 4.6916,
      "step": 854
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015032894736842107,
      "loss": 4.5582,
      "step": 855
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015026315789473684,
      "loss": 7.8363,
      "step": 856
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015019736842105264,
      "loss": 5.9937,
      "step": 857
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015013157894736842,
      "loss": 5.5856,
      "step": 858
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00015006578947368421,
      "loss": 6.2379,
      "step": 859
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00015000000000000001,
      "loss": 8.5126,
      "step": 860
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00014993421052631579,
      "loss": 6.6379,
      "step": 861
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014986842105263159,
      "loss": 5.2698,
      "step": 862
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014980263157894738,
      "loss": 6.1544,
      "step": 863
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014973684210526318,
      "loss": 5.5434,
      "step": 864
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014967105263157896,
      "loss": 6.7835,
      "step": 865
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014960526315789473,
      "loss": 5.8804,
      "step": 866
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014953947368421053,
      "loss": 6.6801,
      "step": 867
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014947368421052633,
      "loss": 6.0688,
      "step": 868
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.00014940789473684213,
      "loss": 5.6664,
      "step": 869
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001493421052631579,
      "loss": 7.1206,
      "step": 870
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001492763157894737,
      "loss": 5.9399,
      "step": 871
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0001492105263157895,
      "loss": 7.3804,
      "step": 872
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014914473684210527,
      "loss": 6.2835,
      "step": 873
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014907894736842104,
      "loss": 4.9061,
      "step": 874
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014901315789473684,
      "loss": 8.5323,
      "step": 875
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014894736842105264,
      "loss": 5.9518,
      "step": 876
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014888157894736844,
      "loss": 6.9103,
      "step": 877
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0001488157894736842,
      "loss": 6.898,
      "step": 878
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00014875,
      "loss": 7.8909,
      "step": 879
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0001486842105263158,
      "loss": 5.5964,
      "step": 880
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014861842105263158,
      "loss": 5.9566,
      "step": 881
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014855263157894735,
      "loss": 5.163,
      "step": 882
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014848684210526315,
      "loss": 6.4404,
      "step": 883
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014842105263157895,
      "loss": 7.5725,
      "step": 884
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014835526315789475,
      "loss": 7.9372,
      "step": 885
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014828947368421052,
      "loss": 5.1593,
      "step": 886
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014822368421052632,
      "loss": 8.9093,
      "step": 887
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00014815789473684212,
      "loss": 5.4914,
      "step": 888
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00014809210526315792,
      "loss": 7.5177,
      "step": 889
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0001480263157894737,
      "loss": 7.0449,
      "step": 890
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014796052631578947,
      "loss": 5.1561,
      "step": 891
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014789473684210527,
      "loss": 7.4049,
      "step": 892
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014782894736842107,
      "loss": 4.1205,
      "step": 893
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014776315789473684,
      "loss": 7.1785,
      "step": 894
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014769736842105264,
      "loss": 6.9466,
      "step": 895
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014763157894736844,
      "loss": 6.9065,
      "step": 896
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014756578947368424,
      "loss": 5.4256,
      "step": 897
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0001475,
      "loss": 8.3424,
      "step": 898
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014743421052631578,
      "loss": 6.2506,
      "step": 899
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014736842105263158,
      "loss": 7.4237,
      "step": 900
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014730263157894738,
      "loss": 7.4323,
      "step": 901
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014723684210526315,
      "loss": 9.0303,
      "step": 902
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014717105263157895,
      "loss": 6.5592,
      "step": 903
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014710526315789475,
      "loss": 6.274,
      "step": 904
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014703947368421055,
      "loss": 6.0262,
      "step": 905
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014697368421052632,
      "loss": 7.488,
      "step": 906
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014690789473684212,
      "loss": 8.8619,
      "step": 907
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0001468421052631579,
      "loss": 8.5165,
      "step": 908
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0001467763157894737,
      "loss": 9.5897,
      "step": 909
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014671052631578946,
      "loss": 8.614,
      "step": 910
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014664473684210526,
      "loss": 9.4893,
      "step": 911
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014657894736842106,
      "loss": 6.4858,
      "step": 912
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014651315789473686,
      "loss": 7.7731,
      "step": 913
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014644736842105263,
      "loss": 7.5183,
      "step": 914
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014638157894736843,
      "loss": 8.8299,
      "step": 915
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014631578947368423,
      "loss": 5.7484,
      "step": 916
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014625,
      "loss": 8.0063,
      "step": 917
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0001461842105263158,
      "loss": 6.3484,
      "step": 918
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014611842105263158,
      "loss": 6.3667,
      "step": 919
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014605263157894737,
      "loss": 6.832,
      "step": 920
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014598684210526317,
      "loss": 8.278,
      "step": 921
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014592105263157895,
      "loss": 5.4919,
      "step": 922
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014585526315789475,
      "loss": 5.1994,
      "step": 923
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014578947368421054,
      "loss": 5.5534,
      "step": 924
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014572368421052632,
      "loss": 8.0369,
      "step": 925
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014565789473684212,
      "loss": 5.998,
      "step": 926
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0001455921052631579,
      "loss": 5.6849,
      "step": 927
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0001455263157894737,
      "loss": 7.4017,
      "step": 928
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0001454605263157895,
      "loss": 3.7376,
      "step": 929
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00014539473684210526,
      "loss": 5.4368,
      "step": 930
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00014532894736842106,
      "loss": 8.5874,
      "step": 931
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014526315789473686,
      "loss": 7.3056,
      "step": 932
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014519736842105266,
      "loss": 3.6664,
      "step": 933
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014513157894736843,
      "loss": 6.5079,
      "step": 934
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0001450657894736842,
      "loss": 7.4123,
      "step": 935
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.000145,
      "loss": 6.8467,
      "step": 936
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0001449342105263158,
      "loss": 6.1826,
      "step": 937
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0001448684210526316,
      "loss": 6.8444,
      "step": 938
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00014480263157894737,
      "loss": 7.093,
      "step": 939
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00014473684210526317,
      "loss": 6.429,
      "step": 940
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014467105263157897,
      "loss": 6.985,
      "step": 941
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014460526315789474,
      "loss": 5.307,
      "step": 942
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014453947368421051,
      "loss": 5.1588,
      "step": 943
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00014447368421052631,
      "loss": 6.9922,
      "step": 944
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001444078947368421,
      "loss": 6.3198,
      "step": 945
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001443421052631579,
      "loss": 6.8799,
      "step": 946
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014427631578947368,
      "loss": 7.0528,
      "step": 947
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014421052631578948,
      "loss": 5.9014,
      "step": 948
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014414473684210528,
      "loss": 4.0878,
      "step": 949
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014407894736842106,
      "loss": 6.7893,
      "step": 950
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014401315789473683,
      "loss": 7.6755,
      "step": 951
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014394736842105263,
      "loss": 7.5226,
      "step": 952
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014388157894736843,
      "loss": 4.6329,
      "step": 953
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014381578947368423,
      "loss": 5.133,
      "step": 954
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014375,
      "loss": 5.2047,
      "step": 955
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0001436842105263158,
      "loss": 5.8394,
      "step": 956
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0001436184210526316,
      "loss": 8.3843,
      "step": 957
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0001435526315789474,
      "loss": 5.5916,
      "step": 958
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00014348684210526317,
      "loss": 3.6753,
      "step": 959
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014342105263157894,
      "loss": 6.4266,
      "step": 960
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014335526315789474,
      "loss": 7.1392,
      "step": 961
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014328947368421054,
      "loss": 3.6707,
      "step": 962
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001432236842105263,
      "loss": 6.0328,
      "step": 963
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001431578947368421,
      "loss": 4.4438,
      "step": 964
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001430921052631579,
      "loss": 4.3366,
      "step": 965
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0001430263157894737,
      "loss": 4.903,
      "step": 966
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00014296052631578948,
      "loss": 5.3537,
      "step": 967
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00014289473684210525,
      "loss": 5.2791,
      "step": 968
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014282894736842105,
      "loss": 5.9134,
      "step": 969
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014276315789473685,
      "loss": 7.1794,
      "step": 970
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014269736842105262,
      "loss": 6.5826,
      "step": 971
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014263157894736842,
      "loss": 4.7426,
      "step": 972
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014256578947368422,
      "loss": 6.8157,
      "step": 973
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014250000000000002,
      "loss": 7.2243,
      "step": 974
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0001424342105263158,
      "loss": 6.571,
      "step": 975
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0001423684210526316,
      "loss": 5.9073,
      "step": 976
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00014230263157894737,
      "loss": 5.8397,
      "step": 977
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00014223684210526316,
      "loss": 5.1685,
      "step": 978
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014217105263157894,
      "loss": 6.3394,
      "step": 979
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014210526315789474,
      "loss": 6.8359,
      "step": 980
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014203947368421054,
      "loss": 5.6035,
      "step": 981
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00014197368421052633,
      "loss": 7.2915,
      "step": 982
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0001419078947368421,
      "loss": 8.1051,
      "step": 983
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0001418421052631579,
      "loss": 5.1753,
      "step": 984
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0001417763157894737,
      "loss": 4.3142,
      "step": 985
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00014171052631578948,
      "loss": 7.9292,
      "step": 986
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00014164473684210528,
      "loss": 6.2082,
      "step": 987
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014157894736842105,
      "loss": 7.9789,
      "step": 988
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014151315789473685,
      "loss": 4.3829,
      "step": 989
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014144736842105265,
      "loss": 6.9979,
      "step": 990
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014138157894736842,
      "loss": 6.68,
      "step": 991
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014131578947368422,
      "loss": 6.6833,
      "step": 992
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014125000000000002,
      "loss": 5.6486,
      "step": 993
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0001411842105263158,
      "loss": 5.5527,
      "step": 994
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0001411184210526316,
      "loss": 5.5147,
      "step": 995
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00014105263157894736,
      "loss": 5.9635,
      "step": 996
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014098684210526316,
      "loss": 7.7153,
      "step": 997
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014092105263157896,
      "loss": 7.5182,
      "step": 998
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014085526315789473,
      "loss": 5.5395,
      "step": 999
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014078947368421053,
      "loss": 6.89,
      "step": 1000
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00014072368421052633,
      "loss": 4.5395,
      "step": 1001
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00014065789473684213,
      "loss": 7.0122,
      "step": 1002
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0001405921052631579,
      "loss": 5.7543,
      "step": 1003
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00014052631578947367,
      "loss": 4.1855,
      "step": 1004
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00014046052631578947,
      "loss": 7.4802,
      "step": 1005
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00014039473684210527,
      "loss": 7.0325,
      "step": 1006
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00014032894736842107,
      "loss": 8.2172,
      "step": 1007
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00014026315789473684,
      "loss": 6.2997,
      "step": 1008
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00014019736842105264,
      "loss": 5.3679,
      "step": 1009
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00014013157894736844,
      "loss": 6.2227,
      "step": 1010
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00014006578947368422,
      "loss": 5.7804,
      "step": 1011
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00014,
      "loss": 5.8018,
      "step": 1012
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0001399342105263158,
      "loss": 6.9042,
      "step": 1013
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00013986842105263159,
      "loss": 5.377,
      "step": 1014
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00013980263157894739,
      "loss": 7.5729,
      "step": 1015
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013973684210526316,
      "loss": 7.7567,
      "step": 1016
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013967105263157896,
      "loss": 4.9526,
      "step": 1017
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013960526315789476,
      "loss": 7.7651,
      "step": 1018
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00013953947368421056,
      "loss": 5.5885,
      "step": 1019
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0001394736842105263,
      "loss": 4.3167,
      "step": 1020
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0001394078947368421,
      "loss": 7.0991,
      "step": 1021
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0001393421052631579,
      "loss": 8.2953,
      "step": 1022
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0001392763157894737,
      "loss": 7.6564,
      "step": 1023
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00013921052631578947,
      "loss": 5.4878,
      "step": 1024
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00013914473684210527,
      "loss": 5.4025,
      "step": 1025
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00013907894736842107,
      "loss": 6.0625,
      "step": 1026
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00013901315789473687,
      "loss": 5.6337,
      "step": 1027
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00013894736842105264,
      "loss": 6.4105,
      "step": 1028
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0001388815789473684,
      "loss": 4.2685,
      "step": 1029
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0001388157894736842,
      "loss": 6.4664,
      "step": 1030
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00013875,
      "loss": 3.795,
      "step": 1031
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00013868421052631578,
      "loss": 6.0953,
      "step": 1032
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00013861842105263158,
      "loss": 5.333,
      "step": 1033
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00013855263157894738,
      "loss": 5.728,
      "step": 1034
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00013848684210526318,
      "loss": 4.2269,
      "step": 1035
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00013842105263157895,
      "loss": 5.0489,
      "step": 1036
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00013835526315789475,
      "loss": 5.8338,
      "step": 1037
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00013828947368421053,
      "loss": 6.079,
      "step": 1038
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00013822368421052632,
      "loss": 5.2205,
      "step": 1039
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0001381578947368421,
      "loss": 4.5413,
      "step": 1040
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0001380921052631579,
      "loss": 7.2906,
      "step": 1041
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0001380263157894737,
      "loss": 8.9297,
      "step": 1042
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0001379605263157895,
      "loss": 5.3346,
      "step": 1043
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00013789473684210527,
      "loss": 6.4965,
      "step": 1044
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00013782894736842107,
      "loss": 6.8825,
      "step": 1045
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00013776315789473684,
      "loss": 6.1873,
      "step": 1046
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00013769736842105264,
      "loss": 8.5544,
      "step": 1047
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0001376315789473684,
      "loss": 6.9302,
      "step": 1048
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0001375657894736842,
      "loss": 6.7404,
      "step": 1049
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0001375,
      "loss": 6.9389,
      "step": 1050
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0001374342105263158,
      "loss": 6.6332,
      "step": 1051
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00013736842105263158,
      "loss": 5.9424,
      "step": 1052
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00013730263157894738,
      "loss": 3.8153,
      "step": 1053
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00013723684210526318,
      "loss": 7.3954,
      "step": 1054
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00013717105263157895,
      "loss": 5.0744,
      "step": 1055
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00013710526315789475,
      "loss": 6.6166,
      "step": 1056
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00013703947368421052,
      "loss": 7.3988,
      "step": 1057
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00013697368421052632,
      "loss": 7.527,
      "step": 1058
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00013690789473684212,
      "loss": 7.3977,
      "step": 1059
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001368421052631579,
      "loss": 6.1964,
      "step": 1060
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001367763157894737,
      "loss": 5.911,
      "step": 1061
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001367105263157895,
      "loss": 5.1556,
      "step": 1062
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013664473684210526,
      "loss": 6.0215,
      "step": 1063
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013657894736842106,
      "loss": 6.7177,
      "step": 1064
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013651315789473683,
      "loss": 5.7545,
      "step": 1065
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013644736842105263,
      "loss": 6.539,
      "step": 1066
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00013638157894736843,
      "loss": 8.38,
      "step": 1067
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0001363157894736842,
      "loss": 7.1821,
      "step": 1068
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00013625,
      "loss": 6.9543,
      "step": 1069
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0001361842105263158,
      "loss": 5.3237,
      "step": 1070
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0001361184210526316,
      "loss": 7.3383,
      "step": 1071
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00013605263157894738,
      "loss": 5.8958,
      "step": 1072
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00013598684210526315,
      "loss": 7.2132,
      "step": 1073
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00013592105263157895,
      "loss": 7.4933,
      "step": 1074
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00013585526315789475,
      "loss": 3.4926,
      "step": 1075
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00013578947368421055,
      "loss": 6.0003,
      "step": 1076
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00013572368421052632,
      "loss": 7.9934,
      "step": 1077
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00013565789473684212,
      "loss": 6.5503,
      "step": 1078
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00013559210526315792,
      "loss": 5.7584,
      "step": 1079
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0001355263157894737,
      "loss": 5.1875,
      "step": 1080
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00013546052631578946,
      "loss": 5.898,
      "step": 1081
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00013539473684210526,
      "loss": 5.1785,
      "step": 1082
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00013532894736842106,
      "loss": 4.4673,
      "step": 1083
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00013526315789473686,
      "loss": 5.908,
      "step": 1084
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013519736842105263,
      "loss": 6.3476,
      "step": 1085
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013513157894736843,
      "loss": 7.8723,
      "step": 1086
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013506578947368423,
      "loss": 4.0418,
      "step": 1087
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013500000000000003,
      "loss": 6.8717,
      "step": 1088
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00013493421052631577,
      "loss": 5.9895,
      "step": 1089
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00013486842105263157,
      "loss": 5.8443,
      "step": 1090
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00013480263157894737,
      "loss": 5.6941,
      "step": 1091
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00013473684210526317,
      "loss": 3.9152,
      "step": 1092
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00013467105263157894,
      "loss": 6.7926,
      "step": 1093
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00013460526315789474,
      "loss": 6.01,
      "step": 1094
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00013453947368421054,
      "loss": 7.1282,
      "step": 1095
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00013447368421052634,
      "loss": 5.5819,
      "step": 1096
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00013440789473684211,
      "loss": 8.0182,
      "step": 1097
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00013434210526315789,
      "loss": 4.5518,
      "step": 1098
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00013427631578947369,
      "loss": 6.8526,
      "step": 1099
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00013421052631578948,
      "loss": 5.9775,
      "step": 1100
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00013414473684210526,
      "loss": 8.3186,
      "step": 1101
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00013407894736842106,
      "loss": 7.6408,
      "step": 1102
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00013401315789473686,
      "loss": 5.3529,
      "step": 1103
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00013394736842105265,
      "loss": 7.8094,
      "step": 1104
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00013388157894736843,
      "loss": 8.022,
      "step": 1105
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00013381578947368423,
      "loss": 7.5183,
      "step": 1106
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00013375,
      "loss": 7.4142,
      "step": 1107
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0001336842105263158,
      "loss": 4.9297,
      "step": 1108
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00013361842105263157,
      "loss": 8.5367,
      "step": 1109
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00013355263157894737,
      "loss": 6.2031,
      "step": 1110
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00013348684210526317,
      "loss": 8.6083,
      "step": 1111
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00013342105263157897,
      "loss": 9.2048,
      "step": 1112
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00013335526315789474,
      "loss": 9.1013,
      "step": 1113
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00013328947368421054,
      "loss": 5.2224,
      "step": 1114
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0001332236842105263,
      "loss": 5.9183,
      "step": 1115
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0001331578947368421,
      "loss": 7.2125,
      "step": 1116
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00013309210526315788,
      "loss": 3.6204,
      "step": 1117
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00013302631578947368,
      "loss": 6.5095,
      "step": 1118
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00013296052631578948,
      "loss": 7.1022,
      "step": 1119
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00013289473684210528,
      "loss": 6.4762,
      "step": 1120
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00013282894736842105,
      "loss": 5.2395,
      "step": 1121
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00013276315789473685,
      "loss": 6.1878,
      "step": 1122
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00013269736842105265,
      "loss": 8.9453,
      "step": 1123
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00013263157894736842,
      "loss": 4.5607,
      "step": 1124
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00013256578947368422,
      "loss": 7.0114,
      "step": 1125
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0001325,
      "loss": 5.8496,
      "step": 1126
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0001324342105263158,
      "loss": 6.5437,
      "step": 1127
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0001323684210526316,
      "loss": 6.6388,
      "step": 1128
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00013230263157894737,
      "loss": 8.0513,
      "step": 1129
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00013223684210526317,
      "loss": 6.6475,
      "step": 1130
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00013217105263157896,
      "loss": 6.1609,
      "step": 1131
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00013210526315789476,
      "loss": 5.9621,
      "step": 1132
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00013203947368421054,
      "loss": 6.8726,
      "step": 1133
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0001319736842105263,
      "loss": 8.0358,
      "step": 1134
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0001319078947368421,
      "loss": 6.9985,
      "step": 1135
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0001318421052631579,
      "loss": 6.9505,
      "step": 1136
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00013177631578947368,
      "loss": 8.0659,
      "step": 1137
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00013171052631578948,
      "loss": 5.25,
      "step": 1138
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00013164473684210528,
      "loss": 4.5511,
      "step": 1139
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00013157894736842108,
      "loss": 6.3247,
      "step": 1140
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00013151315789473685,
      "loss": 5.1575,
      "step": 1141
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00013144736842105262,
      "loss": 6.675,
      "step": 1142
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00013138157894736842,
      "loss": 4.9223,
      "step": 1143
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00013131578947368422,
      "loss": 5.4013,
      "step": 1144
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00013125000000000002,
      "loss": 5.7853,
      "step": 1145
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0001311842105263158,
      "loss": 4.1445,
      "step": 1146
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0001311184210526316,
      "loss": 6.9617,
      "step": 1147
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0001310526315789474,
      "loss": 6.7553,
      "step": 1148
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00013098684210526316,
      "loss": 6.4622,
      "step": 1149
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00013092105263157893,
      "loss": 6.6719,
      "step": 1150
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00013085526315789473,
      "loss": 6.0211,
      "step": 1151
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00013078947368421053,
      "loss": 5.9951,
      "step": 1152
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00013072368421052633,
      "loss": 3.4459,
      "step": 1153
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001306578947368421,
      "loss": 5.8672,
      "step": 1154
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001305921052631579,
      "loss": 4.8049,
      "step": 1155
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001305263157894737,
      "loss": 5.4136,
      "step": 1156
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001304605263157895,
      "loss": 6.3636,
      "step": 1157
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00013039473684210525,
      "loss": 5.6834,
      "step": 1158
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00013032894736842105,
      "loss": 6.086,
      "step": 1159
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00013026315789473685,
      "loss": 5.797,
      "step": 1160
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00013019736842105264,
      "loss": 5.798,
      "step": 1161
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00013013157894736842,
      "loss": 6.9284,
      "step": 1162
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00013006578947368422,
      "loss": 6.3442,
      "step": 1163
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00013000000000000002,
      "loss": 5.969,
      "step": 1164
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00012993421052631582,
      "loss": 6.3359,
      "step": 1165
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.0001298684210526316,
      "loss": 8.2816,
      "step": 1166
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00012980263157894736,
      "loss": 4.7292,
      "step": 1167
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00012973684210526316,
      "loss": 6.2013,
      "step": 1168
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00012967105263157896,
      "loss": 4.7467,
      "step": 1169
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00012960526315789473,
      "loss": 7.2917,
      "step": 1170
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00012953947368421053,
      "loss": 6.0287,
      "step": 1171
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00012947368421052633,
      "loss": 4.9467,
      "step": 1172
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00012940789473684213,
      "loss": 5.987,
      "step": 1173
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0001293421052631579,
      "loss": 5.0736,
      "step": 1174
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0001292763157894737,
      "loss": 6.9923,
      "step": 1175
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012921052631578947,
      "loss": 5.3225,
      "step": 1176
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012914473684210527,
      "loss": 6.7813,
      "step": 1177
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012907894736842104,
      "loss": 5.3644,
      "step": 1178
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012901315789473684,
      "loss": 7.6114,
      "step": 1179
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00012894736842105264,
      "loss": 5.5272,
      "step": 1180
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00012888157894736844,
      "loss": 8.4764,
      "step": 1181
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0001288157894736842,
      "loss": 9.8246,
      "step": 1182
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00012875,
      "loss": 6.8204,
      "step": 1183
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00012868421052631578,
      "loss": 8.5961,
      "step": 1184
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00012861842105263158,
      "loss": 7.971,
      "step": 1185
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00012855263157894736,
      "loss": 8.8435,
      "step": 1186
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00012848684210526316,
      "loss": 7.4146,
      "step": 1187
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00012842105263157895,
      "loss": 9.8588,
      "step": 1188
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00012835526315789475,
      "loss": 10.2022,
      "step": 1189
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00012828947368421053,
      "loss": 10.3293,
      "step": 1190
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00012822368421052633,
      "loss": 10.731,
      "step": 1191
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00012815789473684212,
      "loss": 11.7786,
      "step": 1192
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0001280921052631579,
      "loss": 11.4698,
      "step": 1193
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0001280263157894737,
      "loss": 11.9143,
      "step": 1194
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00012796052631578947,
      "loss": 12.4146,
      "step": 1195
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00012789473684210527,
      "loss": 12.5034,
      "step": 1196
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00012782894736842107,
      "loss": 13.491,
      "step": 1197
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012776315789473684,
      "loss": 15.5368,
      "step": 1198
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012769736842105264,
      "loss": 16.5032,
      "step": 1199
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012763157894736844,
      "loss": 17.2321,
      "step": 1200
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012756578947368424,
      "loss": 16.3306,
      "step": 1201
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.0001275,
      "loss": 19.1613,
      "step": 1202
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00012743421052631578,
      "loss": 20.1532,
      "step": 1203
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00012736842105263158,
      "loss": 17.9095,
      "step": 1204
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00012730263157894738,
      "loss": 18.5525,
      "step": 1205
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00012723684210526315,
      "loss": 19.0916,
      "step": 1206
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00012717105263157895,
      "loss": 19.8356,
      "step": 1207
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00012710526315789475,
      "loss": 17.7375,
      "step": 1208
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00012703947368421055,
      "loss": 18.2596,
      "step": 1209
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00012697368421052632,
      "loss": 16.688,
      "step": 1210
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0001269078947368421,
      "loss": 14.2965,
      "step": 1211
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0001268421052631579,
      "loss": 16.5785,
      "step": 1212
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0001267763157894737,
      "loss": 16.3472,
      "step": 1213
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.0001267105263157895,
      "loss": 17.0938,
      "step": 1214
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00012664473684210526,
      "loss": 15.4707,
      "step": 1215
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00012657894736842106,
      "loss": 13.1473,
      "step": 1216
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00012651315789473686,
      "loss": 13.6952,
      "step": 1217
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00012644736842105264,
      "loss": 13.2341,
      "step": 1218
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0001263815789473684,
      "loss": 12.4235,
      "step": 1219
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0001263157894736842,
      "loss": 13.5202,
      "step": 1220
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00012625,
      "loss": 12.5991,
      "step": 1221
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0001261842105263158,
      "loss": 8.2185,
      "step": 1222
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00012611842105263158,
      "loss": 11.9072,
      "step": 1223
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012605263157894738,
      "loss": 14.8127,
      "step": 1224
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012598684210526318,
      "loss": 14.0339,
      "step": 1225
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012592105263157898,
      "loss": 16.9167,
      "step": 1226
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00012585526315789475,
      "loss": 15.1518,
      "step": 1227
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00012578947368421052,
      "loss": 15.1441,
      "step": 1228
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00012572368421052632,
      "loss": 15.0974,
      "step": 1229
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00012565789473684212,
      "loss": 16.5809,
      "step": 1230
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0001255921052631579,
      "loss": 15.6455,
      "step": 1231
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0001255263157894737,
      "loss": 15.7744,
      "step": 1232
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0001254605263157895,
      "loss": 15.6843,
      "step": 1233
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0001253947368421053,
      "loss": 13.8317,
      "step": 1234
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00012532894736842106,
      "loss": 17.7687,
      "step": 1235
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00012526315789473683,
      "loss": 16.6902,
      "step": 1236
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00012519736842105263,
      "loss": 18.1837,
      "step": 1237
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00012513157894736843,
      "loss": 17.4163,
      "step": 1238
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0001250657894736842,
      "loss": 17.4623,
      "step": 1239
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.000125,
      "loss": 16.2442,
      "step": 1240
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0001249342105263158,
      "loss": 17.408,
      "step": 1241
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0001248684210526316,
      "loss": 17.2921,
      "step": 1242
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00012480263157894737,
      "loss": 16.6223,
      "step": 1243
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00012473684210526317,
      "loss": 15.1366,
      "step": 1244
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00012467105263157894,
      "loss": 16.0328,
      "step": 1245
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00012460526315789474,
      "loss": 17.1925,
      "step": 1246
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00012453947368421052,
      "loss": 14.4667,
      "step": 1247
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00012447368421052632,
      "loss": 14.4512,
      "step": 1248
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00012440789473684211,
      "loss": 14.3002,
      "step": 1249
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00012434210526315791,
      "loss": 17.27,
      "step": 1250
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00012427631578947369,
      "loss": 13.2031,
      "step": 1251
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00012421052631578949,
      "loss": 13.5705,
      "step": 1252
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00012414473684210526,
      "loss": 14.6664,
      "step": 1253
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00012407894736842106,
      "loss": 13.8306,
      "step": 1254
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012401315789473683,
      "loss": 13.7978,
      "step": 1255
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012394736842105263,
      "loss": 11.715,
      "step": 1256
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012388157894736843,
      "loss": 12.217,
      "step": 1257
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00012381578947368423,
      "loss": 10.4844,
      "step": 1258
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00012375,
      "loss": 9.4715,
      "step": 1259
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.0001236842105263158,
      "loss": 11.6519,
      "step": 1260
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.0001236184210526316,
      "loss": 10.7946,
      "step": 1261
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00012355263157894737,
      "loss": 11.293,
      "step": 1262
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00012348684210526317,
      "loss": 8.9483,
      "step": 1263
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00012342105263157894,
      "loss": 9.8588,
      "step": 1264
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00012335526315789474,
      "loss": 10.2646,
      "step": 1265
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00012328947368421054,
      "loss": 9.2131,
      "step": 1266
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0001232236842105263,
      "loss": 8.3955,
      "step": 1267
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0001231578947368421,
      "loss": 8.3826,
      "step": 1268
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0001230921052631579,
      "loss": 12.3891,
      "step": 1269
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.0001230263157894737,
      "loss": 14.4187,
      "step": 1270
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00012296052631578948,
      "loss": 10.3563,
      "step": 1271
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00012289473684210525,
      "loss": 10.2311,
      "step": 1272
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00012282894736842105,
      "loss": 11.405,
      "step": 1273
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00012276315789473685,
      "loss": 11.7353,
      "step": 1274
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00012269736842105263,
      "loss": 9.7874,
      "step": 1275
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00012263157894736842,
      "loss": 10.3458,
      "step": 1276
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00012256578947368422,
      "loss": 12.227,
      "step": 1277
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00012250000000000002,
      "loss": 8.3685,
      "step": 1278
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.0001224342105263158,
      "loss": 11.3328,
      "step": 1279
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00012236842105263157,
      "loss": 9.7565,
      "step": 1280
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00012230263157894737,
      "loss": 9.4804,
      "step": 1281
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00012223684210526317,
      "loss": 12.3719,
      "step": 1282
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00012217105263157897,
      "loss": 11.0178,
      "step": 1283
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00012210526315789474,
      "loss": 11.5696,
      "step": 1284
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00012203947368421054,
      "loss": 12.0826,
      "step": 1285
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00012197368421052632,
      "loss": 11.1969,
      "step": 1286
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00012190789473684212,
      "loss": 7.4716,
      "step": 1287
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.0001218421052631579,
      "loss": 11.9662,
      "step": 1288
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00012177631578947368,
      "loss": 12.0236,
      "step": 1289
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00012171052631578948,
      "loss": 13.4465,
      "step": 1290
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00012164473684210526,
      "loss": 14.2197,
      "step": 1291
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00012157894736842106,
      "loss": 14.8126,
      "step": 1292
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00012151315789473685,
      "loss": 14.3471,
      "step": 1293
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00012144736842105265,
      "loss": 15.156,
      "step": 1294
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00012138157894736843,
      "loss": 13.2656,
      "step": 1295
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00012131578947368422,
      "loss": 11.1194,
      "step": 1296
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00012124999999999999,
      "loss": 16.9834,
      "step": 1297
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00012118421052631579,
      "loss": 16.6913,
      "step": 1298
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00012111842105263158,
      "loss": 15.608,
      "step": 1299
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00012105263157894738,
      "loss": 17.2573,
      "step": 1300
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00012098684210526316,
      "loss": 16.8726,
      "step": 1301
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00012092105263157896,
      "loss": 16.9416,
      "step": 1302
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00012085526315789475,
      "loss": 16.2472,
      "step": 1303
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00012078947368421055,
      "loss": 14.4017,
      "step": 1304
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001207236842105263,
      "loss": 14.4519,
      "step": 1305
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001206578947368421,
      "loss": 10.8093,
      "step": 1306
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00012059210526315789,
      "loss": 13.1203,
      "step": 1307
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00012052631578947369,
      "loss": 11.0292,
      "step": 1308
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00012046052631578948,
      "loss": 7.4431,
      "step": 1309
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00012039473684210528,
      "loss": 11.3499,
      "step": 1310
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00012032894736842106,
      "loss": 11.755,
      "step": 1311
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00012026315789473686,
      "loss": 8.3959,
      "step": 1312
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00012019736842105265,
      "loss": 8.8043,
      "step": 1313
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00012013157894736842,
      "loss": 10.5069,
      "step": 1314
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0001200657894736842,
      "loss": 9.2879,
      "step": 1315
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00012,
      "loss": 8.4154,
      "step": 1316
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00011993421052631579,
      "loss": 6.2094,
      "step": 1317
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00011986842105263159,
      "loss": 9.1532,
      "step": 1318
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00011980263157894737,
      "loss": 7.7656,
      "step": 1319
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00011973684210526317,
      "loss": 8.0228,
      "step": 1320
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00011967105263157896,
      "loss": 5.9477,
      "step": 1321
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00011960526315789476,
      "loss": 8.153,
      "step": 1322
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00011953947368421052,
      "loss": 6.162,
      "step": 1323
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00011947368421052632,
      "loss": 8.5493,
      "step": 1324
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.0001194078947368421,
      "loss": 7.9093,
      "step": 1325
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.0001193421052631579,
      "loss": 4.8784,
      "step": 1326
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00011927631578947369,
      "loss": 3.7244,
      "step": 1327
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00011921052631578949,
      "loss": 5.305,
      "step": 1328
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00011914473684210527,
      "loss": 7.4394,
      "step": 1329
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00011907894736842107,
      "loss": 4.7773,
      "step": 1330
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00011901315789473684,
      "loss": 5.226,
      "step": 1331
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00011894736842105263,
      "loss": 7.4617,
      "step": 1332
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00011888157894736843,
      "loss": 7.1861,
      "step": 1333
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00011881578947368421,
      "loss": 6.5813,
      "step": 1334
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00011875,
      "loss": 8.2642,
      "step": 1335
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0001186842105263158,
      "loss": 7.1234,
      "step": 1336
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00011861842105263158,
      "loss": 6.2685,
      "step": 1337
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00011855263157894738,
      "loss": 5.6831,
      "step": 1338
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00011848684210526317,
      "loss": 6.7174,
      "step": 1339
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00011842105263157894,
      "loss": 5.7898,
      "step": 1340
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00011835526315789474,
      "loss": 6.3277,
      "step": 1341
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00011828947368421053,
      "loss": 7.7379,
      "step": 1342
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00011822368421052633,
      "loss": 6.9156,
      "step": 1343
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00011815789473684211,
      "loss": 6.107,
      "step": 1344
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0001180921052631579,
      "loss": 6.2928,
      "step": 1345
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.0001180263157894737,
      "loss": 5.7724,
      "step": 1346
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00011796052631578948,
      "loss": 5.7083,
      "step": 1347
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00011789473684210525,
      "loss": 4.7606,
      "step": 1348
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00011782894736842105,
      "loss": 5.0852,
      "step": 1349
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00011776315789473684,
      "loss": 6.3299,
      "step": 1350
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00011769736842105264,
      "loss": 7.839,
      "step": 1351
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00011763157894736843,
      "loss": 5.3394,
      "step": 1352
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00011756578947368422,
      "loss": 6.3331,
      "step": 1353
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00011750000000000001,
      "loss": 5.8917,
      "step": 1354
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0001174342105263158,
      "loss": 5.6271,
      "step": 1355
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0001173684210526316,
      "loss": 5.9388,
      "step": 1356
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00011730263157894737,
      "loss": 5.505,
      "step": 1357
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00011723684210526315,
      "loss": 6.188,
      "step": 1358
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00011717105263157895,
      "loss": 5.9924,
      "step": 1359
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00011710526315789474,
      "loss": 8.0868,
      "step": 1360
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00011703947368421054,
      "loss": 6.4155,
      "step": 1361
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00011697368421052632,
      "loss": 3.4322,
      "step": 1362
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00011690789473684212,
      "loss": 6.9891,
      "step": 1363
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00011684210526315791,
      "loss": 4.6833,
      "step": 1364
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.0001167763157894737,
      "loss": 6.2846,
      "step": 1365
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00011671052631578947,
      "loss": 6.9284,
      "step": 1366
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00011664473684210527,
      "loss": 5.695,
      "step": 1367
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00011657894736842105,
      "loss": 5.588,
      "step": 1368
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00011651315789473685,
      "loss": 5.6761,
      "step": 1369
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00011644736842105264,
      "loss": 3.3686,
      "step": 1370
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00011638157894736844,
      "loss": 6.163,
      "step": 1371
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00011631578947368422,
      "loss": 4.6532,
      "step": 1372
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00011625000000000002,
      "loss": 6.3282,
      "step": 1373
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011618421052631578,
      "loss": 6.0955,
      "step": 1374
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011611842105263158,
      "loss": 6.4099,
      "step": 1375
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011605263157894736,
      "loss": 3.679,
      "step": 1376
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011598684210526316,
      "loss": 5.8441,
      "step": 1377
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011592105263157895,
      "loss": 6.9615,
      "step": 1378
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011585526315789475,
      "loss": 4.978,
      "step": 1379
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011578947368421053,
      "loss": 7.3652,
      "step": 1380
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00011572368421052633,
      "loss": 4.805,
      "step": 1381
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00011565789473684212,
      "loss": 5.2052,
      "step": 1382
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00011559210526315789,
      "loss": 5.6248,
      "step": 1383
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00011552631578947368,
      "loss": 6.9187,
      "step": 1384
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00011546052631578948,
      "loss": 5.0727,
      "step": 1385
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00011539473684210526,
      "loss": 4.757,
      "step": 1386
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00011532894736842106,
      "loss": 5.5775,
      "step": 1387
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00011526315789473685,
      "loss": 6.6521,
      "step": 1388
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00011519736842105265,
      "loss": 6.5772,
      "step": 1389
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00011513157894736843,
      "loss": 6.5292,
      "step": 1390
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00011506578947368423,
      "loss": 7.5852,
      "step": 1391
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00011499999999999999,
      "loss": 8.2151,
      "step": 1392
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00011493421052631579,
      "loss": 7.8298,
      "step": 1393
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00011486842105263157,
      "loss": 7.9327,
      "step": 1394
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00011480263157894737,
      "loss": 6.8025,
      "step": 1395
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00011473684210526316,
      "loss": 4.204,
      "step": 1396
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00011467105263157896,
      "loss": 5.5074,
      "step": 1397
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00011460526315789474,
      "loss": 7.5986,
      "step": 1398
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00011453947368421054,
      "loss": 5.8616,
      "step": 1399
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00011447368421052632,
      "loss": 6.3158,
      "step": 1400
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0001144078947368421,
      "loss": 6.6711,
      "step": 1401
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0001143421052631579,
      "loss": 5.248,
      "step": 1402
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00011427631578947369,
      "loss": 5.233,
      "step": 1403
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00011421052631578947,
      "loss": 6.2722,
      "step": 1404
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00011414473684210527,
      "loss": 5.0468,
      "step": 1405
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00011407894736842106,
      "loss": 4.918,
      "step": 1406
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00011401315789473686,
      "loss": 6.2917,
      "step": 1407
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00011394736842105264,
      "loss": 4.06,
      "step": 1408
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00011388157894736842,
      "loss": 4.8167,
      "step": 1409
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00011381578947368421,
      "loss": 7.419,
      "step": 1410
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00011375,
      "loss": 6.4373,
      "step": 1411
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0001136842105263158,
      "loss": 5.637,
      "step": 1412
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00011361842105263159,
      "loss": 6.643,
      "step": 1413
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00011355263157894737,
      "loss": 4.4443,
      "step": 1414
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00011348684210526317,
      "loss": 6.5213,
      "step": 1415
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00011342105263157896,
      "loss": 6.089,
      "step": 1416
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00011335526315789476,
      "loss": 5.0886,
      "step": 1417
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00011328947368421053,
      "loss": 8.3828,
      "step": 1418
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00011322368421052631,
      "loss": 6.5103,
      "step": 1419
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00011315789473684211,
      "loss": 7.9293,
      "step": 1420
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.0001130921052631579,
      "loss": 4.3015,
      "step": 1421
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.0001130263157894737,
      "loss": 4.7987,
      "step": 1422
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00011296052631578948,
      "loss": 7.2527,
      "step": 1423
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00011289473684210527,
      "loss": 6.2948,
      "step": 1424
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00011282894736842107,
      "loss": 6.0685,
      "step": 1425
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00011276315789473684,
      "loss": 5.4928,
      "step": 1426
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00011269736842105263,
      "loss": 5.5092,
      "step": 1427
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00011263157894736843,
      "loss": 6.6734,
      "step": 1428
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00011256578947368421,
      "loss": 8.3915,
      "step": 1429
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00011250000000000001,
      "loss": 7.1912,
      "step": 1430
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0001124342105263158,
      "loss": 6.8032,
      "step": 1431
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0001123684210526316,
      "loss": 7.0009,
      "step": 1432
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00011230263157894738,
      "loss": 4.7581,
      "step": 1433
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00011223684210526317,
      "loss": 6.9013,
      "step": 1434
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00011217105263157894,
      "loss": 6.9028,
      "step": 1435
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00011210526315789474,
      "loss": 5.6607,
      "step": 1436
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00011203947368421052,
      "loss": 6.4174,
      "step": 1437
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00011197368421052632,
      "loss": 10.0934,
      "step": 1438
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00011190789473684211,
      "loss": 9.229,
      "step": 1439
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00011184210526315791,
      "loss": 11.3599,
      "step": 1440
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0001117763157894737,
      "loss": 6.9149,
      "step": 1441
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0001117105263157895,
      "loss": 10.5888,
      "step": 1442
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00011164473684210525,
      "loss": 11.4777,
      "step": 1443
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00011157894736842105,
      "loss": 6.0569,
      "step": 1444
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00011151315789473684,
      "loss": 5.9454,
      "step": 1445
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00011144736842105264,
      "loss": 14.669,
      "step": 1446
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00011138157894736842,
      "loss": 12.9323,
      "step": 1447
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00011131578947368422,
      "loss": 14.3827,
      "step": 1448
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00011125000000000001,
      "loss": 12.9781,
      "step": 1449
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.0001111842105263158,
      "loss": 14.494,
      "step": 1450
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00011111842105263159,
      "loss": 10.9971,
      "step": 1451
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00011105263157894736,
      "loss": 15.0616,
      "step": 1452
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00011098684210526315,
      "loss": 16.4626,
      "step": 1453
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00011092105263157895,
      "loss": 15.7089,
      "step": 1454
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00011085526315789474,
      "loss": 17.5637,
      "step": 1455
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00011078947368421053,
      "loss": 19.2269,
      "step": 1456
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00011072368421052632,
      "loss": 16.1616,
      "step": 1457
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00011065789473684212,
      "loss": 16.5079,
      "step": 1458
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001105921052631579,
      "loss": 14.6348,
      "step": 1459
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001105263157894737,
      "loss": 17.5806,
      "step": 1460
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00011046052631578946,
      "loss": 19.8806,
      "step": 1461
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00011039473684210526,
      "loss": 18.3651,
      "step": 1462
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00011032894736842105,
      "loss": 20.3054,
      "step": 1463
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00011026315789473685,
      "loss": 20.1312,
      "step": 1464
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00011019736842105263,
      "loss": 17.619,
      "step": 1465
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00011013157894736843,
      "loss": 16.4244,
      "step": 1466
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00011006578947368422,
      "loss": 17.9756,
      "step": 1467
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00011000000000000002,
      "loss": 17.3482,
      "step": 1468
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00010993421052631579,
      "loss": 16.8191,
      "step": 1469
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00010986842105263158,
      "loss": 13.3016,
      "step": 1470
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00010980263157894737,
      "loss": 14.2382,
      "step": 1471
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00010973684210526316,
      "loss": 16.6384,
      "step": 1472
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00010967105263157895,
      "loss": 18.0397,
      "step": 1473
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00010960526315789475,
      "loss": 17.6383,
      "step": 1474
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00010953947368421053,
      "loss": 19.3178,
      "step": 1475
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00010947368421052633,
      "loss": 18.5328,
      "step": 1476
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00010940789473684212,
      "loss": 21.3651,
      "step": 1477
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00010934210526315789,
      "loss": 23.3223,
      "step": 1478
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00010927631578947369,
      "loss": 23.5577,
      "step": 1479
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00010921052631578947,
      "loss": 22.1825,
      "step": 1480
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00010914473684210527,
      "loss": 22.545,
      "step": 1481
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00010907894736842106,
      "loss": 23.041,
      "step": 1482
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00010901315789473684,
      "loss": 22.4417,
      "step": 1483
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00010894736842105264,
      "loss": 21.5462,
      "step": 1484
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00010888157894736843,
      "loss": 21.8418,
      "step": 1485
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00010881578947368423,
      "loss": 20.977,
      "step": 1486
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00010875,
      "loss": 21.9883,
      "step": 1487
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00010868421052631579,
      "loss": 21.3726,
      "step": 1488
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00010861842105263159,
      "loss": 22.8734,
      "step": 1489
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010855263157894737,
      "loss": 21.8741,
      "step": 1490
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010848684210526317,
      "loss": 25.1974,
      "step": 1491
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010842105263157896,
      "loss": 21.3071,
      "step": 1492
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010835526315789474,
      "loss": 21.2277,
      "step": 1493
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00010828947368421054,
      "loss": 24.2244,
      "step": 1494
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00010822368421052631,
      "loss": 24.4046,
      "step": 1495
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0001081578947368421,
      "loss": 23.562,
      "step": 1496
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.0001080921052631579,
      "loss": 24.7008,
      "step": 1497
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00010802631578947368,
      "loss": 22.296,
      "step": 1498
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00010796052631578948,
      "loss": 23.5902,
      "step": 1499
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00010789473684210527,
      "loss": 23.0843,
      "step": 1500
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00010782894736842107,
      "loss": 22.7471,
      "step": 1501
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00010776315789473685,
      "loss": 24.1311,
      "step": 1502
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00010769736842105264,
      "loss": 25.2477,
      "step": 1503
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00010763157894736841,
      "loss": 25.036,
      "step": 1504
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00010756578947368421,
      "loss": 24.7891,
      "step": 1505
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.0001075,
      "loss": 24.8432,
      "step": 1506
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.0001074342105263158,
      "loss": 24.0535,
      "step": 1507
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00010736842105263158,
      "loss": 25.7922,
      "step": 1508
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00010730263157894738,
      "loss": 25.3887,
      "step": 1509
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00010723684210526317,
      "loss": 23.7426,
      "step": 1510
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00010717105263157897,
      "loss": 26.0004,
      "step": 1511
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00010710526315789475,
      "loss": 22.4444,
      "step": 1512
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00010703947368421052,
      "loss": 25.7902,
      "step": 1513
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00010697368421052631,
      "loss": 25.2761,
      "step": 1514
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00010690789473684211,
      "loss": 23.2305,
      "step": 1515
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.0001068421052631579,
      "loss": 22.2404,
      "step": 1516
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.0001067763157894737,
      "loss": 21.6204,
      "step": 1517
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00010671052631578948,
      "loss": 22.4786,
      "step": 1518
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00010664473684210528,
      "loss": 21.7515,
      "step": 1519
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00010657894736842107,
      "loss": 20.3009,
      "step": 1520
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00010651315789473684,
      "loss": 24.3203,
      "step": 1521
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00010644736842105262,
      "loss": 25.0533,
      "step": 1522
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00010638157894736842,
      "loss": 27.2622,
      "step": 1523
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00010631578947368421,
      "loss": 24.974,
      "step": 1524
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00010625000000000001,
      "loss": 23.6781,
      "step": 1525
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.0001061842105263158,
      "loss": 22.9827,
      "step": 1526
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00010611842105263159,
      "loss": 23.7565,
      "step": 1527
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00010605263157894738,
      "loss": 23.8448,
      "step": 1528
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00010598684210526318,
      "loss": 21.5277,
      "step": 1529
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00010592105263157895,
      "loss": 21.9098,
      "step": 1530
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00010585526315789474,
      "loss": 22.0764,
      "step": 1531
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00010578947368421052,
      "loss": 22.0173,
      "step": 1532
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00010572368421052632,
      "loss": 23.9741,
      "step": 1533
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0001056578947368421,
      "loss": 20.7378,
      "step": 1534
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0001055921052631579,
      "loss": 22.847,
      "step": 1535
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00010552631578947369,
      "loss": 21.8261,
      "step": 1536
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00010546052631578949,
      "loss": 22.1817,
      "step": 1537
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00010539473684210526,
      "loss": 23.4632,
      "step": 1538
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00010532894736842105,
      "loss": 23.3335,
      "step": 1539
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00010526315789473685,
      "loss": 25.0013,
      "step": 1540
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00010519736842105263,
      "loss": 24.6497,
      "step": 1541
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00010513157894736842,
      "loss": 24.7203,
      "step": 1542
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00010506578947368422,
      "loss": 24.7931,
      "step": 1543
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.000105,
      "loss": 25.5059,
      "step": 1544
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.0001049342105263158,
      "loss": 25.4375,
      "step": 1545
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00010486842105263159,
      "loss": 25.476,
      "step": 1546
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00010480263157894736,
      "loss": 24.4456,
      "step": 1547
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00010473684210526316,
      "loss": 24.263,
      "step": 1548
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00010467105263157895,
      "loss": 23.9068,
      "step": 1549
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00010460526315789475,
      "loss": 24.8986,
      "step": 1550
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00010453947368421053,
      "loss": 26.2521,
      "step": 1551
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00010447368421052632,
      "loss": 27.3827,
      "step": 1552
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00010440789473684212,
      "loss": 29.4648,
      "step": 1553
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.0001043421052631579,
      "loss": 27.189,
      "step": 1554
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.0001042763157894737,
      "loss": 26.3041,
      "step": 1555
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010421052631578947,
      "loss": 27.0037,
      "step": 1556
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010414473684210526,
      "loss": 27.1357,
      "step": 1557
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010407894736842106,
      "loss": 27.1562,
      "step": 1558
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010401315789473684,
      "loss": 24.8104,
      "step": 1559
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00010394736842105264,
      "loss": 26.1245,
      "step": 1560
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00010388157894736843,
      "loss": 24.5098,
      "step": 1561
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00010381578947368422,
      "loss": 25.3928,
      "step": 1562
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00010375000000000001,
      "loss": 26.369,
      "step": 1563
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00010368421052631579,
      "loss": 25.6886,
      "step": 1564
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00010361842105263157,
      "loss": 24.5927,
      "step": 1565
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00010355263157894737,
      "loss": 24.6313,
      "step": 1566
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00010348684210526316,
      "loss": 23.7247,
      "step": 1567
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00010342105263157896,
      "loss": 23.6604,
      "step": 1568
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00010335526315789474,
      "loss": 24.4065,
      "step": 1569
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00010328947368421054,
      "loss": 24.5426,
      "step": 1570
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00010322368421052633,
      "loss": 26.4346,
      "step": 1571
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00010315789473684211,
      "loss": 25.7802,
      "step": 1572
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00010309210526315789,
      "loss": 28.7308,
      "step": 1573
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00010302631578947368,
      "loss": 25.1907,
      "step": 1574
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00010296052631578947,
      "loss": 27.8914,
      "step": 1575
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00010289473684210527,
      "loss": 27.1074,
      "step": 1576
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00010282894736842106,
      "loss": 25.3054,
      "step": 1577
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00010276315789473685,
      "loss": 23.158,
      "step": 1578
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00010269736842105264,
      "loss": 23.1807,
      "step": 1579
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00010263157894736844,
      "loss": 21.1167,
      "step": 1580
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00010256578947368423,
      "loss": 24.5738,
      "step": 1581
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.0001025,
      "loss": 24.6774,
      "step": 1582
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00010243421052631578,
      "loss": 25.5088,
      "step": 1583
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00010236842105263158,
      "loss": 25.3919,
      "step": 1584
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00010230263157894737,
      "loss": 25.1387,
      "step": 1585
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00010223684210526317,
      "loss": 25.3174,
      "step": 1586
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00010217105263157895,
      "loss": 25.9228,
      "step": 1587
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00010210526315789475,
      "loss": 26.7775,
      "step": 1588
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00010203947368421054,
      "loss": 23.0555,
      "step": 1589
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00010197368421052631,
      "loss": 22.4057,
      "step": 1590
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.0001019078947368421,
      "loss": 21.7556,
      "step": 1591
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.0001018421052631579,
      "loss": 22.5668,
      "step": 1592
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00010177631578947368,
      "loss": 23.4232,
      "step": 1593
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00010171052631578948,
      "loss": 23.055,
      "step": 1594
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00010164473684210527,
      "loss": 25.1425,
      "step": 1595
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00010157894736842107,
      "loss": 25.6051,
      "step": 1596
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00010151315789473685,
      "loss": 26.8412,
      "step": 1597
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00010144736842105265,
      "loss": 25.7852,
      "step": 1598
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00010138157894736842,
      "loss": 24.4555,
      "step": 1599
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00010131578947368421,
      "loss": 24.9019,
      "step": 1600
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00010125,
      "loss": 24.8535,
      "step": 1601
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.0001011842105263158,
      "loss": 23.5866,
      "step": 1602
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00010111842105263158,
      "loss": 22.9431,
      "step": 1603
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00010105263157894738,
      "loss": 24.6881,
      "step": 1604
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00010098684210526316,
      "loss": 25.1323,
      "step": 1605
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00010092105263157896,
      "loss": 27.0895,
      "step": 1606
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00010085526315789475,
      "loss": 24.9436,
      "step": 1607
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00010078947368421052,
      "loss": 26.1442,
      "step": 1608
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00010072368421052632,
      "loss": 23.6624,
      "step": 1609
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00010065789473684211,
      "loss": 24.3362,
      "step": 1610
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00010059210526315789,
      "loss": 24.1866,
      "step": 1611
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00010052631578947369,
      "loss": 23.2117,
      "step": 1612
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00010046052631578948,
      "loss": 24.7515,
      "step": 1613
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00010039473684210528,
      "loss": 25.1844,
      "step": 1614
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00010032894736842106,
      "loss": 25.2592,
      "step": 1615
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00010026315789473683,
      "loss": 25.2637,
      "step": 1616
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00010019736842105263,
      "loss": 27.7328,
      "step": 1617
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00010013157894736842,
      "loss": 28.3462,
      "step": 1618
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00010006578947368422,
      "loss": 24.889,
      "step": 1619
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.0001,
      "loss": 26.5858,
      "step": 1620
    },
    {
      "epoch": 5.16,
      "learning_rate": 9.993421052631579e-05,
      "loss": 25.9326,
      "step": 1621
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.986842105263159e-05,
      "loss": 25.8653,
      "step": 1622
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.980263157894738e-05,
      "loss": 24.754,
      "step": 1623
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.973684210526316e-05,
      "loss": 28.3479,
      "step": 1624
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.967105263157896e-05,
      "loss": 26.3124,
      "step": 1625
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.960526315789475e-05,
      "loss": 25.3256,
      "step": 1626
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.953947368421053e-05,
      "loss": 25.4277,
      "step": 1627
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.947368421052632e-05,
      "loss": 23.3667,
      "step": 1628
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.940789473684212e-05,
      "loss": 25.1658,
      "step": 1629
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.93421052631579e-05,
      "loss": 23.5838,
      "step": 1630
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.927631578947369e-05,
      "loss": 21.5183,
      "step": 1631
    },
    {
      "epoch": 5.2,
      "learning_rate": 9.921052631578947e-05,
      "loss": 21.4903,
      "step": 1632
    },
    {
      "epoch": 5.2,
      "learning_rate": 9.914473684210527e-05,
      "loss": 21.7091,
      "step": 1633
    },
    {
      "epoch": 5.2,
      "learning_rate": 9.907894736842106e-05,
      "loss": 23.0744,
      "step": 1634
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.901315789473686e-05,
      "loss": 25.216,
      "step": 1635
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.894736842105263e-05,
      "loss": 22.5248,
      "step": 1636
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.888157894736843e-05,
      "loss": 24.7491,
      "step": 1637
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.881578947368422e-05,
      "loss": 23.8674,
      "step": 1638
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.875000000000002e-05,
      "loss": 26.5164,
      "step": 1639
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.868421052631579e-05,
      "loss": 26.3795,
      "step": 1640
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.861842105263159e-05,
      "loss": 24.9807,
      "step": 1641
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.855263157894737e-05,
      "loss": 26.3877,
      "step": 1642
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.848684210526317e-05,
      "loss": 23.9639,
      "step": 1643
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.842105263157894e-05,
      "loss": 23.6103,
      "step": 1644
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.835526315789474e-05,
      "loss": 24.9613,
      "step": 1645
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.828947368421053e-05,
      "loss": 24.3066,
      "step": 1646
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.822368421052633e-05,
      "loss": 23.3464,
      "step": 1647
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.815789473684211e-05,
      "loss": 24.5794,
      "step": 1648
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.80921052631579e-05,
      "loss": 23.565,
      "step": 1649
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.802631578947369e-05,
      "loss": 21.5571,
      "step": 1650
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.796052631578948e-05,
      "loss": 23.8835,
      "step": 1651
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.789473684210527e-05,
      "loss": 24.1702,
      "step": 1652
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.782894736842106e-05,
      "loss": 24.1523,
      "step": 1653
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.776315789473684e-05,
      "loss": 23.4319,
      "step": 1654
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.769736842105264e-05,
      "loss": 24.6798,
      "step": 1655
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.763157894736843e-05,
      "loss": 23.6259,
      "step": 1656
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.756578947368421e-05,
      "loss": 21.7805,
      "step": 1657
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.75e-05,
      "loss": 26.2187,
      "step": 1658
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.74342105263158e-05,
      "loss": 24.2609,
      "step": 1659
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.736842105263158e-05,
      "loss": 23.1124,
      "step": 1660
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.730263157894738e-05,
      "loss": 23.1553,
      "step": 1661
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.723684210526315e-05,
      "loss": 21.1779,
      "step": 1662
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.717105263157895e-05,
      "loss": 19.8945,
      "step": 1663
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.710526315789474e-05,
      "loss": 19.5757,
      "step": 1664
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.703947368421054e-05,
      "loss": 19.0881,
      "step": 1665
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.697368421052631e-05,
      "loss": 18.4073,
      "step": 1666
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.690789473684211e-05,
      "loss": 17.8338,
      "step": 1667
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.68421052631579e-05,
      "loss": 16.8914,
      "step": 1668
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.67763157894737e-05,
      "loss": 17.9824,
      "step": 1669
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.671052631578947e-05,
      "loss": 17.4167,
      "step": 1670
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.664473684210527e-05,
      "loss": 15.4984,
      "step": 1671
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.657894736842105e-05,
      "loss": 16.9752,
      "step": 1672
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.651315789473685e-05,
      "loss": 15.8739,
      "step": 1673
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.644736842105262e-05,
      "loss": 17.6699,
      "step": 1674
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.638157894736842e-05,
      "loss": 19.2802,
      "step": 1675
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.631578947368421e-05,
      "loss": 22.0732,
      "step": 1676
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.625000000000001e-05,
      "loss": 23.2029,
      "step": 1677
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.61842105263158e-05,
      "loss": 20.732,
      "step": 1678
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.611842105263158e-05,
      "loss": 22.2493,
      "step": 1679
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.605263157894737e-05,
      "loss": 21.2586,
      "step": 1680
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.598684210526317e-05,
      "loss": 22.2704,
      "step": 1681
    },
    {
      "epoch": 5.36,
      "learning_rate": 9.592105263157895e-05,
      "loss": 24.0792,
      "step": 1682
    },
    {
      "epoch": 5.36,
      "learning_rate": 9.585526315789474e-05,
      "loss": 24.5665,
      "step": 1683
    },
    {
      "epoch": 5.36,
      "learning_rate": 9.578947368421052e-05,
      "loss": 22.6758,
      "step": 1684
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.572368421052632e-05,
      "loss": 23.9476,
      "step": 1685
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.565789473684211e-05,
      "loss": 24.9746,
      "step": 1686
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.559210526315789e-05,
      "loss": 23.3451,
      "step": 1687
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.552631578947369e-05,
      "loss": 25.3908,
      "step": 1688
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.546052631578948e-05,
      "loss": 22.9999,
      "step": 1689
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.539473684210526e-05,
      "loss": 23.6384,
      "step": 1690
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.532894736842106e-05,
      "loss": 24.51,
      "step": 1691
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.526315789473685e-05,
      "loss": 24.2188,
      "step": 1692
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.519736842105263e-05,
      "loss": 19.9232,
      "step": 1693
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.513157894736843e-05,
      "loss": 22.4409,
      "step": 1694
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.506578947368422e-05,
      "loss": 21.7278,
      "step": 1695
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.5e-05,
      "loss": 16.6122,
      "step": 1696
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.493421052631579e-05,
      "loss": 23.1217,
      "step": 1697
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.486842105263159e-05,
      "loss": 22.2806,
      "step": 1698
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.480263157894738e-05,
      "loss": 22.6096,
      "step": 1699
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.473684210526316e-05,
      "loss": 26.7345,
      "step": 1700
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.467105263157895e-05,
      "loss": 23.9415,
      "step": 1701
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.460526315789475e-05,
      "loss": 23.2327,
      "step": 1702
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.453947368421053e-05,
      "loss": 23.8789,
      "step": 1703
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.447368421052633e-05,
      "loss": 22.7378,
      "step": 1704
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.44078947368421e-05,
      "loss": 22.915,
      "step": 1705
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.43421052631579e-05,
      "loss": 21.8966,
      "step": 1706
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.427631578947369e-05,
      "loss": 21.196,
      "step": 1707
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.421052631578949e-05,
      "loss": 24.6984,
      "step": 1708
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.414473684210526e-05,
      "loss": 21.9963,
      "step": 1709
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.407894736842106e-05,
      "loss": 23.6392,
      "step": 1710
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.401315789473685e-05,
      "loss": 23.2614,
      "step": 1711
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.394736842105264e-05,
      "loss": 23.7754,
      "step": 1712
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.388157894736842e-05,
      "loss": 22.5488,
      "step": 1713
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.381578947368422e-05,
      "loss": 20.7645,
      "step": 1714
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.375e-05,
      "loss": 20.5958,
      "step": 1715
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.36842105263158e-05,
      "loss": 20.7155,
      "step": 1716
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.361842105263159e-05,
      "loss": 20.4452,
      "step": 1717
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.355263157894737e-05,
      "loss": 20.6143,
      "step": 1718
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.348684210526316e-05,
      "loss": 19.8358,
      "step": 1719
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.342105263157896e-05,
      "loss": 20.6714,
      "step": 1720
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.335526315789474e-05,
      "loss": 23.0763,
      "step": 1721
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.328947368421053e-05,
      "loss": 20.6001,
      "step": 1722
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.322368421052631e-05,
      "loss": 21.1855,
      "step": 1723
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.315789473684211e-05,
      "loss": 22.4084,
      "step": 1724
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.30921052631579e-05,
      "loss": 22.6665,
      "step": 1725
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.302631578947369e-05,
      "loss": 23.4671,
      "step": 1726
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.296052631578947e-05,
      "loss": 22.0879,
      "step": 1727
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.289473684210527e-05,
      "loss": 24.3406,
      "step": 1728
    },
    {
      "epoch": 5.51,
      "learning_rate": 9.282894736842106e-05,
      "loss": 24.7217,
      "step": 1729
    },
    {
      "epoch": 5.51,
      "learning_rate": 9.276315789473686e-05,
      "loss": 24.1156,
      "step": 1730
    },
    {
      "epoch": 5.51,
      "learning_rate": 9.269736842105263e-05,
      "loss": 24.7376,
      "step": 1731
    },
    {
      "epoch": 5.52,
      "learning_rate": 9.263157894736843e-05,
      "loss": 25.2629,
      "step": 1732
    },
    {
      "epoch": 5.52,
      "learning_rate": 9.256578947368421e-05,
      "loss": 24.1684,
      "step": 1733
    },
    {
      "epoch": 5.52,
      "learning_rate": 9.250000000000001e-05,
      "loss": 23.1605,
      "step": 1734
    },
    {
      "epoch": 5.53,
      "learning_rate": 9.243421052631578e-05,
      "loss": 22.683,
      "step": 1735
    },
    {
      "epoch": 5.53,
      "learning_rate": 9.236842105263158e-05,
      "loss": 23.0845,
      "step": 1736
    },
    {
      "epoch": 5.53,
      "learning_rate": 9.230263157894737e-05,
      "loss": 25.8998,
      "step": 1737
    },
    {
      "epoch": 5.54,
      "learning_rate": 9.223684210526317e-05,
      "loss": 21.8743,
      "step": 1738
    },
    {
      "epoch": 5.54,
      "learning_rate": 9.217105263157894e-05,
      "loss": 22.0506,
      "step": 1739
    },
    {
      "epoch": 5.54,
      "learning_rate": 9.210526315789474e-05,
      "loss": 22.7638,
      "step": 1740
    },
    {
      "epoch": 5.54,
      "learning_rate": 9.203947368421053e-05,
      "loss": 21.065,
      "step": 1741
    },
    {
      "epoch": 5.55,
      "learning_rate": 9.197368421052633e-05,
      "loss": 22.7924,
      "step": 1742
    },
    {
      "epoch": 5.55,
      "learning_rate": 9.190789473684211e-05,
      "loss": 22.8799,
      "step": 1743
    },
    {
      "epoch": 5.55,
      "learning_rate": 9.18421052631579e-05,
      "loss": 23.9783,
      "step": 1744
    },
    {
      "epoch": 5.56,
      "learning_rate": 9.177631578947368e-05,
      "loss": 25.1552,
      "step": 1745
    },
    {
      "epoch": 5.56,
      "learning_rate": 9.171052631578948e-05,
      "loss": 25.297,
      "step": 1746
    },
    {
      "epoch": 5.56,
      "learning_rate": 9.164473684210527e-05,
      "loss": 24.241,
      "step": 1747
    },
    {
      "epoch": 5.57,
      "learning_rate": 9.157894736842105e-05,
      "loss": 23.7894,
      "step": 1748
    },
    {
      "epoch": 5.57,
      "learning_rate": 9.151315789473684e-05,
      "loss": 23.6403,
      "step": 1749
    },
    {
      "epoch": 5.57,
      "learning_rate": 9.144736842105264e-05,
      "loss": 24.1813,
      "step": 1750
    },
    {
      "epoch": 5.58,
      "learning_rate": 9.138157894736842e-05,
      "loss": 21.3046,
      "step": 1751
    },
    {
      "epoch": 5.58,
      "learning_rate": 9.131578947368421e-05,
      "loss": 21.7979,
      "step": 1752
    },
    {
      "epoch": 5.58,
      "learning_rate": 9.125e-05,
      "loss": 19.9505,
      "step": 1753
    },
    {
      "epoch": 5.59,
      "learning_rate": 9.11842105263158e-05,
      "loss": 20.6171,
      "step": 1754
    },
    {
      "epoch": 5.59,
      "learning_rate": 9.111842105263158e-05,
      "loss": 20.6239,
      "step": 1755
    },
    {
      "epoch": 5.59,
      "learning_rate": 9.105263157894738e-05,
      "loss": 21.7172,
      "step": 1756
    },
    {
      "epoch": 5.6,
      "learning_rate": 9.098684210526317e-05,
      "loss": 22.1819,
      "step": 1757
    },
    {
      "epoch": 5.6,
      "learning_rate": 9.092105263157895e-05,
      "loss": 20.882,
      "step": 1758
    },
    {
      "epoch": 5.6,
      "learning_rate": 9.085526315789474e-05,
      "loss": 19.1393,
      "step": 1759
    },
    {
      "epoch": 5.61,
      "learning_rate": 9.078947368421054e-05,
      "loss": 19.2952,
      "step": 1760
    },
    {
      "epoch": 5.61,
      "learning_rate": 9.072368421052632e-05,
      "loss": 19.6501,
      "step": 1761
    },
    {
      "epoch": 5.61,
      "learning_rate": 9.065789473684211e-05,
      "loss": 20.1183,
      "step": 1762
    },
    {
      "epoch": 5.61,
      "learning_rate": 9.059210526315791e-05,
      "loss": 18.9731,
      "step": 1763
    },
    {
      "epoch": 5.62,
      "learning_rate": 9.052631578947369e-05,
      "loss": 17.6757,
      "step": 1764
    },
    {
      "epoch": 5.62,
      "learning_rate": 9.046052631578948e-05,
      "loss": 18.4346,
      "step": 1765
    },
    {
      "epoch": 5.62,
      "learning_rate": 9.039473684210526e-05,
      "loss": 19.0218,
      "step": 1766
    },
    {
      "epoch": 5.63,
      "learning_rate": 9.032894736842106e-05,
      "loss": 17.1224,
      "step": 1767
    },
    {
      "epoch": 5.63,
      "learning_rate": 9.026315789473685e-05,
      "loss": 16.6839,
      "step": 1768
    },
    {
      "epoch": 5.63,
      "learning_rate": 9.019736842105263e-05,
      "loss": 16.6251,
      "step": 1769
    },
    {
      "epoch": 5.64,
      "learning_rate": 9.013157894736842e-05,
      "loss": 16.9086,
      "step": 1770
    },
    {
      "epoch": 5.64,
      "learning_rate": 9.006578947368422e-05,
      "loss": 16.2806,
      "step": 1771
    },
    {
      "epoch": 5.64,
      "learning_rate": 9e-05,
      "loss": 19.7388,
      "step": 1772
    },
    {
      "epoch": 5.65,
      "learning_rate": 8.99342105263158e-05,
      "loss": 18.9429,
      "step": 1773
    },
    {
      "epoch": 5.65,
      "learning_rate": 8.986842105263158e-05,
      "loss": 24.2313,
      "step": 1774
    },
    {
      "epoch": 5.65,
      "learning_rate": 8.980263157894738e-05,
      "loss": 22.285,
      "step": 1775
    },
    {
      "epoch": 5.66,
      "learning_rate": 8.973684210526316e-05,
      "loss": 23.4301,
      "step": 1776
    },
    {
      "epoch": 5.66,
      "learning_rate": 8.967105263157896e-05,
      "loss": 23.4782,
      "step": 1777
    },
    {
      "epoch": 5.66,
      "learning_rate": 8.960526315789473e-05,
      "loss": 23.4513,
      "step": 1778
    },
    {
      "epoch": 5.67,
      "learning_rate": 8.953947368421053e-05,
      "loss": 24.3096,
      "step": 1779
    },
    {
      "epoch": 5.67,
      "learning_rate": 8.947368421052632e-05,
      "loss": 23.9374,
      "step": 1780
    },
    {
      "epoch": 5.67,
      "learning_rate": 8.940789473684212e-05,
      "loss": 24.1015,
      "step": 1781
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.934210526315789e-05,
      "loss": 22.9492,
      "step": 1782
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.927631578947369e-05,
      "loss": 23.0682,
      "step": 1783
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.921052631578948e-05,
      "loss": 24.7041,
      "step": 1784
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.914473684210527e-05,
      "loss": 23.9961,
      "step": 1785
    },
    {
      "epoch": 5.69,
      "learning_rate": 8.907894736842106e-05,
      "loss": 23.6333,
      "step": 1786
    },
    {
      "epoch": 5.69,
      "learning_rate": 8.901315789473685e-05,
      "loss": 25.7928,
      "step": 1787
    },
    {
      "epoch": 5.69,
      "learning_rate": 8.894736842105263e-05,
      "loss": 23.8932,
      "step": 1788
    },
    {
      "epoch": 5.7,
      "learning_rate": 8.888157894736843e-05,
      "loss": 22.8554,
      "step": 1789
    },
    {
      "epoch": 5.7,
      "learning_rate": 8.881578947368422e-05,
      "loss": 22.674,
      "step": 1790
    },
    {
      "epoch": 5.7,
      "learning_rate": 8.875e-05,
      "loss": 22.2634,
      "step": 1791
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.868421052631579e-05,
      "loss": 24.5201,
      "step": 1792
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.861842105263159e-05,
      "loss": 22.3941,
      "step": 1793
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.855263157894737e-05,
      "loss": 21.9876,
      "step": 1794
    },
    {
      "epoch": 5.72,
      "learning_rate": 8.848684210526316e-05,
      "loss": 23.9612,
      "step": 1795
    },
    {
      "epoch": 5.72,
      "learning_rate": 8.842105263157894e-05,
      "loss": 20.426,
      "step": 1796
    },
    {
      "epoch": 5.72,
      "learning_rate": 8.835526315789474e-05,
      "loss": 19.3985,
      "step": 1797
    },
    {
      "epoch": 5.73,
      "learning_rate": 8.828947368421053e-05,
      "loss": 18.9434,
      "step": 1798
    },
    {
      "epoch": 5.73,
      "learning_rate": 8.822368421052633e-05,
      "loss": 20.7396,
      "step": 1799
    },
    {
      "epoch": 5.73,
      "learning_rate": 8.81578947368421e-05,
      "loss": 20.2044,
      "step": 1800
    },
    {
      "epoch": 5.74,
      "learning_rate": 8.80921052631579e-05,
      "loss": 20.1521,
      "step": 1801
    },
    {
      "epoch": 5.74,
      "learning_rate": 8.802631578947369e-05,
      "loss": 18.2255,
      "step": 1802
    },
    {
      "epoch": 5.74,
      "learning_rate": 8.796052631578949e-05,
      "loss": 18.2799,
      "step": 1803
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.789473684210526e-05,
      "loss": 17.5204,
      "step": 1804
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.782894736842106e-05,
      "loss": 17.1565,
      "step": 1805
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.776315789473684e-05,
      "loss": 17.7857,
      "step": 1806
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.769736842105264e-05,
      "loss": 17.8008,
      "step": 1807
    },
    {
      "epoch": 5.76,
      "learning_rate": 8.763157894736841e-05,
      "loss": 18.9741,
      "step": 1808
    },
    {
      "epoch": 5.76,
      "learning_rate": 8.756578947368421e-05,
      "loss": 20.7727,
      "step": 1809
    },
    {
      "epoch": 5.76,
      "learning_rate": 8.75e-05,
      "loss": 24.3512,
      "step": 1810
    },
    {
      "epoch": 5.77,
      "learning_rate": 8.74342105263158e-05,
      "loss": 20.6496,
      "step": 1811
    },
    {
      "epoch": 5.77,
      "learning_rate": 8.736842105263158e-05,
      "loss": 22.2343,
      "step": 1812
    },
    {
      "epoch": 5.77,
      "learning_rate": 8.730263157894737e-05,
      "loss": 25.3416,
      "step": 1813
    },
    {
      "epoch": 5.78,
      "learning_rate": 8.723684210526316e-05,
      "loss": 24.4073,
      "step": 1814
    },
    {
      "epoch": 5.78,
      "learning_rate": 8.717105263157895e-05,
      "loss": 24.6387,
      "step": 1815
    },
    {
      "epoch": 5.78,
      "learning_rate": 8.710526315789474e-05,
      "loss": 25.4717,
      "step": 1816
    },
    {
      "epoch": 5.79,
      "learning_rate": 8.703947368421053e-05,
      "loss": 24.5464,
      "step": 1817
    },
    {
      "epoch": 5.79,
      "learning_rate": 8.697368421052631e-05,
      "loss": 25.5149,
      "step": 1818
    },
    {
      "epoch": 5.79,
      "learning_rate": 8.690789473684211e-05,
      "loss": 23.2173,
      "step": 1819
    },
    {
      "epoch": 5.8,
      "learning_rate": 8.68421052631579e-05,
      "loss": 22.6734,
      "step": 1820
    },
    {
      "epoch": 5.8,
      "learning_rate": 8.677631578947368e-05,
      "loss": 20.8115,
      "step": 1821
    },
    {
      "epoch": 5.8,
      "learning_rate": 8.671052631578948e-05,
      "loss": 22.081,
      "step": 1822
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.664473684210527e-05,
      "loss": 23.108,
      "step": 1823
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.657894736842105e-05,
      "loss": 16.9092,
      "step": 1824
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.651315789473685e-05,
      "loss": 21.9404,
      "step": 1825
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.644736842105264e-05,
      "loss": 20.2166,
      "step": 1826
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.638157894736842e-05,
      "loss": 18.7718,
      "step": 1827
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.631578947368421e-05,
      "loss": 19.356,
      "step": 1828
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.625000000000001e-05,
      "loss": 20.0571,
      "step": 1829
    },
    {
      "epoch": 5.83,
      "learning_rate": 8.61842105263158e-05,
      "loss": 20.7377,
      "step": 1830
    },
    {
      "epoch": 5.83,
      "learning_rate": 8.611842105263158e-05,
      "loss": 20.9816,
      "step": 1831
    },
    {
      "epoch": 5.83,
      "learning_rate": 8.605263157894738e-05,
      "loss": 24.421,
      "step": 1832
    },
    {
      "epoch": 5.84,
      "learning_rate": 8.598684210526317e-05,
      "loss": 23.4269,
      "step": 1833
    },
    {
      "epoch": 5.84,
      "learning_rate": 8.592105263157895e-05,
      "loss": 20.0621,
      "step": 1834
    },
    {
      "epoch": 5.84,
      "learning_rate": 8.585526315789474e-05,
      "loss": 18.0872,
      "step": 1835
    },
    {
      "epoch": 5.85,
      "learning_rate": 8.578947368421054e-05,
      "loss": 19.2719,
      "step": 1836
    },
    {
      "epoch": 5.85,
      "learning_rate": 8.572368421052632e-05,
      "loss": 20.2829,
      "step": 1837
    },
    {
      "epoch": 5.85,
      "learning_rate": 8.565789473684211e-05,
      "loss": 19.2458,
      "step": 1838
    },
    {
      "epoch": 5.86,
      "learning_rate": 8.55921052631579e-05,
      "loss": 19.2822,
      "step": 1839
    },
    {
      "epoch": 5.86,
      "learning_rate": 8.552631578947369e-05,
      "loss": 17.1976,
      "step": 1840
    },
    {
      "epoch": 5.86,
      "learning_rate": 8.546052631578948e-05,
      "loss": 17.6458,
      "step": 1841
    },
    {
      "epoch": 5.87,
      "learning_rate": 8.539473684210528e-05,
      "loss": 18.1822,
      "step": 1842
    },
    {
      "epoch": 5.87,
      "learning_rate": 8.532894736842105e-05,
      "loss": 19.768,
      "step": 1843
    },
    {
      "epoch": 5.87,
      "learning_rate": 8.526315789473685e-05,
      "loss": 21.1498,
      "step": 1844
    },
    {
      "epoch": 5.88,
      "learning_rate": 8.519736842105264e-05,
      "loss": 18.2589,
      "step": 1845
    },
    {
      "epoch": 5.88,
      "learning_rate": 8.513157894736843e-05,
      "loss": 18.3771,
      "step": 1846
    },
    {
      "epoch": 5.88,
      "learning_rate": 8.506578947368421e-05,
      "loss": 21.7067,
      "step": 1847
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.5e-05,
      "loss": 20.9664,
      "step": 1848
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.493421052631579e-05,
      "loss": 18.9584,
      "step": 1849
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.486842105263159e-05,
      "loss": 17.8186,
      "step": 1850
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.480263157894738e-05,
      "loss": 14.7299,
      "step": 1851
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.473684210526316e-05,
      "loss": 19.2619,
      "step": 1852
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.467105263157895e-05,
      "loss": 19.8057,
      "step": 1853
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.460526315789475e-05,
      "loss": 19.5485,
      "step": 1854
    },
    {
      "epoch": 5.91,
      "learning_rate": 8.453947368421053e-05,
      "loss": 18.8299,
      "step": 1855
    },
    {
      "epoch": 5.91,
      "learning_rate": 8.447368421052632e-05,
      "loss": 18.6288,
      "step": 1856
    },
    {
      "epoch": 5.91,
      "learning_rate": 8.44078947368421e-05,
      "loss": 18.7361,
      "step": 1857
    },
    {
      "epoch": 5.92,
      "learning_rate": 8.43421052631579e-05,
      "loss": 18.9413,
      "step": 1858
    },
    {
      "epoch": 5.92,
      "learning_rate": 8.427631578947369e-05,
      "loss": 19.0733,
      "step": 1859
    },
    {
      "epoch": 5.92,
      "learning_rate": 8.421052631578948e-05,
      "loss": 22.9539,
      "step": 1860
    },
    {
      "epoch": 5.93,
      "learning_rate": 8.414473684210526e-05,
      "loss": 21.2423,
      "step": 1861
    },
    {
      "epoch": 5.93,
      "learning_rate": 8.407894736842106e-05,
      "loss": 22.2022,
      "step": 1862
    },
    {
      "epoch": 5.93,
      "learning_rate": 8.401315789473685e-05,
      "loss": 21.9677,
      "step": 1863
    },
    {
      "epoch": 5.94,
      "learning_rate": 8.394736842105263e-05,
      "loss": 24.0776,
      "step": 1864
    },
    {
      "epoch": 5.94,
      "learning_rate": 8.388157894736842e-05,
      "loss": 24.6534,
      "step": 1865
    },
    {
      "epoch": 5.94,
      "learning_rate": 8.381578947368422e-05,
      "loss": 26.2389,
      "step": 1866
    },
    {
      "epoch": 5.95,
      "learning_rate": 8.375e-05,
      "loss": 25.8426,
      "step": 1867
    },
    {
      "epoch": 5.95,
      "learning_rate": 8.36842105263158e-05,
      "loss": 25.3354,
      "step": 1868
    },
    {
      "epoch": 5.95,
      "learning_rate": 8.361842105263157e-05,
      "loss": 22.7444,
      "step": 1869
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.355263157894737e-05,
      "loss": 24.5956,
      "step": 1870
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.348684210526316e-05,
      "loss": 23.8538,
      "step": 1871
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.342105263157896e-05,
      "loss": 23.7669,
      "step": 1872
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.335526315789473e-05,
      "loss": 22.5828,
      "step": 1873
    },
    {
      "epoch": 5.97,
      "learning_rate": 8.328947368421053e-05,
      "loss": 21.0722,
      "step": 1874
    },
    {
      "epoch": 5.97,
      "learning_rate": 8.322368421052632e-05,
      "loss": 19.1397,
      "step": 1875
    },
    {
      "epoch": 5.97,
      "learning_rate": 8.315789473684212e-05,
      "loss": 21.1395,
      "step": 1876
    },
    {
      "epoch": 5.98,
      "learning_rate": 8.309210526315789e-05,
      "loss": 19.7555,
      "step": 1877
    },
    {
      "epoch": 5.98,
      "learning_rate": 8.302631578947369e-05,
      "loss": 21.0523,
      "step": 1878
    },
    {
      "epoch": 5.98,
      "learning_rate": 8.296052631578947e-05,
      "loss": 22.2082,
      "step": 1879
    },
    {
      "epoch": 5.99,
      "learning_rate": 8.289473684210527e-05,
      "loss": 19.3546,
      "step": 1880
    },
    {
      "epoch": 5.99,
      "learning_rate": 8.282894736842106e-05,
      "loss": 20.7965,
      "step": 1881
    },
    {
      "epoch": 5.99,
      "learning_rate": 8.276315789473684e-05,
      "loss": 22.5153,
      "step": 1882
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.269736842105263e-05,
      "loss": 21.124,
      "step": 1883
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.263157894736843e-05,
      "loss": 21.5445,
      "step": 1884
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.256578947368421e-05,
      "loss": 22.7982,
      "step": 1885
    },
    {
      "epoch": 6.01,
      "learning_rate": 8.25e-05,
      "loss": 23.3407,
      "step": 1886
    },
    {
      "epoch": 6.01,
      "learning_rate": 8.243421052631579e-05,
      "loss": 17.4325,
      "step": 1887
    },
    {
      "epoch": 6.01,
      "learning_rate": 8.236842105263158e-05,
      "loss": 21.4446,
      "step": 1888
    },
    {
      "epoch": 6.02,
      "learning_rate": 8.230263157894737e-05,
      "loss": 23.5361,
      "step": 1889
    },
    {
      "epoch": 6.02,
      "learning_rate": 8.223684210526316e-05,
      "loss": 20.0278,
      "step": 1890
    },
    {
      "epoch": 6.02,
      "learning_rate": 8.217105263157896e-05,
      "loss": 21.964,
      "step": 1891
    },
    {
      "epoch": 6.03,
      "learning_rate": 8.210526315789474e-05,
      "loss": 21.6901,
      "step": 1892
    },
    {
      "epoch": 6.03,
      "learning_rate": 8.203947368421053e-05,
      "loss": 21.5213,
      "step": 1893
    },
    {
      "epoch": 6.03,
      "learning_rate": 8.197368421052633e-05,
      "loss": 23.4622,
      "step": 1894
    },
    {
      "epoch": 6.04,
      "learning_rate": 8.190789473684211e-05,
      "loss": 19.5999,
      "step": 1895
    },
    {
      "epoch": 6.04,
      "learning_rate": 8.18421052631579e-05,
      "loss": 27.5497,
      "step": 1896
    },
    {
      "epoch": 6.04,
      "learning_rate": 8.177631578947368e-05,
      "loss": 26.2044,
      "step": 1897
    },
    {
      "epoch": 6.04,
      "learning_rate": 8.171052631578948e-05,
      "loss": 23.7832,
      "step": 1898
    },
    {
      "epoch": 6.05,
      "learning_rate": 8.164473684210527e-05,
      "loss": 23.9551,
      "step": 1899
    },
    {
      "epoch": 6.05,
      "learning_rate": 8.157894736842105e-05,
      "loss": 24.1082,
      "step": 1900
    },
    {
      "epoch": 6.05,
      "learning_rate": 8.151315789473685e-05,
      "loss": 23.7205,
      "step": 1901
    },
    {
      "epoch": 6.06,
      "learning_rate": 8.144736842105264e-05,
      "loss": 24.2514,
      "step": 1902
    },
    {
      "epoch": 6.06,
      "learning_rate": 8.138157894736842e-05,
      "loss": 23.8444,
      "step": 1903
    },
    {
      "epoch": 6.06,
      "learning_rate": 8.131578947368421e-05,
      "loss": 26.4955,
      "step": 1904
    },
    {
      "epoch": 6.07,
      "learning_rate": 8.125000000000001e-05,
      "loss": 25.589,
      "step": 1905
    },
    {
      "epoch": 6.07,
      "learning_rate": 8.11842105263158e-05,
      "loss": 25.6594,
      "step": 1906
    },
    {
      "epoch": 6.07,
      "learning_rate": 8.111842105263158e-05,
      "loss": 25.4001,
      "step": 1907
    },
    {
      "epoch": 6.08,
      "learning_rate": 8.105263157894737e-05,
      "loss": 24.0115,
      "step": 1908
    },
    {
      "epoch": 6.08,
      "learning_rate": 8.098684210526317e-05,
      "loss": 25.374,
      "step": 1909
    },
    {
      "epoch": 6.08,
      "learning_rate": 8.092105263157895e-05,
      "loss": 23.42,
      "step": 1910
    },
    {
      "epoch": 6.09,
      "learning_rate": 8.085526315789475e-05,
      "loss": 19.5536,
      "step": 1911
    },
    {
      "epoch": 6.09,
      "learning_rate": 8.078947368421052e-05,
      "loss": 23.7384,
      "step": 1912
    },
    {
      "epoch": 6.09,
      "learning_rate": 8.072368421052632e-05,
      "loss": 21.6712,
      "step": 1913
    },
    {
      "epoch": 6.1,
      "learning_rate": 8.065789473684211e-05,
      "loss": 22.3636,
      "step": 1914
    },
    {
      "epoch": 6.1,
      "learning_rate": 8.059210526315791e-05,
      "loss": 25.2393,
      "step": 1915
    },
    {
      "epoch": 6.1,
      "learning_rate": 8.052631578947368e-05,
      "loss": 25.6638,
      "step": 1916
    },
    {
      "epoch": 6.11,
      "learning_rate": 8.046052631578948e-05,
      "loss": 23.9414,
      "step": 1917
    },
    {
      "epoch": 6.11,
      "learning_rate": 8.039473684210527e-05,
      "loss": 27.3964,
      "step": 1918
    },
    {
      "epoch": 6.11,
      "learning_rate": 8.032894736842106e-05,
      "loss": 25.0195,
      "step": 1919
    },
    {
      "epoch": 6.11,
      "learning_rate": 8.026315789473685e-05,
      "loss": 24.61,
      "step": 1920
    },
    {
      "epoch": 6.12,
      "learning_rate": 8.019736842105264e-05,
      "loss": 25.0989,
      "step": 1921
    },
    {
      "epoch": 6.12,
      "learning_rate": 8.013157894736842e-05,
      "loss": 24.8563,
      "step": 1922
    },
    {
      "epoch": 6.12,
      "learning_rate": 8.006578947368422e-05,
      "loss": 24.4877,
      "step": 1923
    },
    {
      "epoch": 6.13,
      "learning_rate": 8e-05,
      "loss": 25.4436,
      "step": 1924
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.993421052631579e-05,
      "loss": 26.6081,
      "step": 1925
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.986842105263158e-05,
      "loss": 25.0475,
      "step": 1926
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.980263157894738e-05,
      "loss": 27.8111,
      "step": 1927
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.973684210526316e-05,
      "loss": 26.2459,
      "step": 1928
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.967105263157895e-05,
      "loss": 24.4937,
      "step": 1929
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.960526315789473e-05,
      "loss": 25.3233,
      "step": 1930
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.953947368421053e-05,
      "loss": 22.315,
      "step": 1931
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.947368421052632e-05,
      "loss": 21.2483,
      "step": 1932
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.940789473684212e-05,
      "loss": 24.8764,
      "step": 1933
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.934210526315789e-05,
      "loss": 21.8098,
      "step": 1934
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.927631578947369e-05,
      "loss": 22.2507,
      "step": 1935
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.921052631578948e-05,
      "loss": 25.2972,
      "step": 1936
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.914473684210528e-05,
      "loss": 24.2471,
      "step": 1937
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.907894736842105e-05,
      "loss": 24.602,
      "step": 1938
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.901315789473685e-05,
      "loss": 25.0593,
      "step": 1939
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.894736842105263e-05,
      "loss": 23.4057,
      "step": 1940
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.888157894736843e-05,
      "loss": 24.3556,
      "step": 1941
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.88157894736842e-05,
      "loss": 24.7015,
      "step": 1942
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.875e-05,
      "loss": 25.9062,
      "step": 1943
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.868421052631579e-05,
      "loss": 26.0873,
      "step": 1944
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.861842105263159e-05,
      "loss": 23.578,
      "step": 1945
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.855263157894737e-05,
      "loss": 26.6995,
      "step": 1946
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.848684210526316e-05,
      "loss": 24.6311,
      "step": 1947
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.842105263157895e-05,
      "loss": 24.8705,
      "step": 1948
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.835526315789474e-05,
      "loss": 24.6383,
      "step": 1949
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.828947368421053e-05,
      "loss": 25.5627,
      "step": 1950
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.822368421052632e-05,
      "loss": 26.0925,
      "step": 1951
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.81578947368421e-05,
      "loss": 24.5141,
      "step": 1952
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.80921052631579e-05,
      "loss": 24.5655,
      "step": 1953
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.802631578947369e-05,
      "loss": 25.5231,
      "step": 1954
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.796052631578947e-05,
      "loss": 24.5609,
      "step": 1955
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.789473684210526e-05,
      "loss": 24.8548,
      "step": 1956
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.782894736842106e-05,
      "loss": 24.3801,
      "step": 1957
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.776315789473684e-05,
      "loss": 24.365,
      "step": 1958
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.769736842105263e-05,
      "loss": 23.2118,
      "step": 1959
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.763157894736843e-05,
      "loss": 24.0738,
      "step": 1960
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.756578947368421e-05,
      "loss": 23.0969,
      "step": 1961
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.75e-05,
      "loss": 22.1092,
      "step": 1962
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.74342105263158e-05,
      "loss": 22.7654,
      "step": 1963
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.736842105263159e-05,
      "loss": 23.49,
      "step": 1964
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.730263157894737e-05,
      "loss": 25.7742,
      "step": 1965
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.723684210526316e-05,
      "loss": 24.0919,
      "step": 1966
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.717105263157896e-05,
      "loss": 25.1107,
      "step": 1967
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.710526315789474e-05,
      "loss": 26.7499,
      "step": 1968
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.703947368421053e-05,
      "loss": 24.9267,
      "step": 1969
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.697368421052633e-05,
      "loss": 25.869,
      "step": 1970
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.690789473684211e-05,
      "loss": 24.6144,
      "step": 1971
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.68421052631579e-05,
      "loss": 26.6503,
      "step": 1972
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.677631578947368e-05,
      "loss": 26.298,
      "step": 1973
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.671052631578948e-05,
      "loss": 25.4974,
      "step": 1974
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.664473684210527e-05,
      "loss": 24.3255,
      "step": 1975
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.657894736842105e-05,
      "loss": 25.9736,
      "step": 1976
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.651315789473684e-05,
      "loss": 24.0964,
      "step": 1977
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.644736842105264e-05,
      "loss": 25.0893,
      "step": 1978
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.638157894736843e-05,
      "loss": 23.3997,
      "step": 1979
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.631578947368422e-05,
      "loss": 23.5702,
      "step": 1980
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.625e-05,
      "loss": 21.8786,
      "step": 1981
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.61842105263158e-05,
      "loss": 22.4833,
      "step": 1982
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.611842105263158e-05,
      "loss": 22.4571,
      "step": 1983
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.605263157894738e-05,
      "loss": 24.2427,
      "step": 1984
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.598684210526315e-05,
      "loss": 23.7589,
      "step": 1985
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.592105263157895e-05,
      "loss": 23.8263,
      "step": 1986
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.585526315789474e-05,
      "loss": 24.3959,
      "step": 1987
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.578947368421054e-05,
      "loss": 26.5059,
      "step": 1988
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.572368421052632e-05,
      "loss": 27.451,
      "step": 1989
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.565789473684211e-05,
      "loss": 24.6951,
      "step": 1990
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.55921052631579e-05,
      "loss": 25.7133,
      "step": 1991
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.55263157894737e-05,
      "loss": 25.6798,
      "step": 1992
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.546052631578948e-05,
      "loss": 26.6902,
      "step": 1993
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.539473684210527e-05,
      "loss": 25.5818,
      "step": 1994
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.532894736842105e-05,
      "loss": 25.2731,
      "step": 1995
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.526315789473685e-05,
      "loss": 24.2697,
      "step": 1996
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.519736842105264e-05,
      "loss": 24.1315,
      "step": 1997
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.513157894736842e-05,
      "loss": 24.8101,
      "step": 1998
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.506578947368421e-05,
      "loss": 22.9985,
      "step": 1999
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.500000000000001e-05,
      "loss": 25.3778,
      "step": 2000
    }
  ],
  "logging_steps": 1,
  "max_steps": 3140,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 1.453191069696e+16,
  "trial_name": null,
  "trial_params": null
}
