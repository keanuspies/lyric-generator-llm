{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.1847133757961785,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 5.6759,
      "step": 1
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.000000000000001e-06,
      "loss": 9.2278,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 6e-06,
      "loss": 9.4527,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 8.000000000000001e-06,
      "loss": 8.6189,
      "step": 4
    },
    {
      "epoch": 0.02,
      "learning_rate": 1e-05,
      "loss": 9.4267,
      "step": 5
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.2e-05,
      "loss": 8.9336,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 8.5892,
      "step": 7
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 9.3676,
      "step": 8
    },
    {
      "epoch": 0.03,
      "learning_rate": 1.8e-05,
      "loss": 9.5714,
      "step": 9
    },
    {
      "epoch": 0.03,
      "learning_rate": 2e-05,
      "loss": 9.7373,
      "step": 10
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 4.81,
      "step": 11
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.4e-05,
      "loss": 8.827,
      "step": 12
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 9.4198,
      "step": 13
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 8.4715,
      "step": 14
    },
    {
      "epoch": 0.05,
      "learning_rate": 3e-05,
      "loss": 8.1328,
      "step": 15
    },
    {
      "epoch": 0.05,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 9.1683,
      "step": 16
    },
    {
      "epoch": 0.05,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 8.1505,
      "step": 17
    },
    {
      "epoch": 0.06,
      "learning_rate": 3.6e-05,
      "loss": 8.612,
      "step": 18
    },
    {
      "epoch": 0.06,
      "learning_rate": 3.8e-05,
      "loss": 9.6851,
      "step": 19
    },
    {
      "epoch": 0.06,
      "learning_rate": 4e-05,
      "loss": 9.1717,
      "step": 20
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.2e-05,
      "loss": 9.816,
      "step": 21
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 8.4455,
      "step": 22
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.600000000000001e-05,
      "loss": 9.7776,
      "step": 23
    },
    {
      "epoch": 0.08,
      "learning_rate": 4.8e-05,
      "loss": 9.2504,
      "step": 24
    },
    {
      "epoch": 0.08,
      "learning_rate": 5e-05,
      "loss": 8.4986,
      "step": 25
    },
    {
      "epoch": 0.08,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 7.5105,
      "step": 26
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 9.7485,
      "step": 27
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 8.8211,
      "step": 28
    },
    {
      "epoch": 0.09,
      "learning_rate": 5.8e-05,
      "loss": 7.476,
      "step": 29
    },
    {
      "epoch": 0.1,
      "learning_rate": 6e-05,
      "loss": 6.8175,
      "step": 30
    },
    {
      "epoch": 0.1,
      "learning_rate": 6.2e-05,
      "loss": 7.5066,
      "step": 31
    },
    {
      "epoch": 0.1,
      "learning_rate": 6.400000000000001e-05,
      "loss": 9.8417,
      "step": 32
    },
    {
      "epoch": 0.11,
      "learning_rate": 6.6e-05,
      "loss": 4.3675,
      "step": 33
    },
    {
      "epoch": 0.11,
      "learning_rate": 6.800000000000001e-05,
      "loss": 9.0861,
      "step": 34
    },
    {
      "epoch": 0.11,
      "learning_rate": 7e-05,
      "loss": 9.5019,
      "step": 35
    },
    {
      "epoch": 0.11,
      "learning_rate": 7.2e-05,
      "loss": 6.9603,
      "step": 36
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.4e-05,
      "loss": 7.9824,
      "step": 37
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.6e-05,
      "loss": 8.6069,
      "step": 38
    },
    {
      "epoch": 0.12,
      "learning_rate": 7.800000000000001e-05,
      "loss": 9.3592,
      "step": 39
    },
    {
      "epoch": 0.13,
      "learning_rate": 8e-05,
      "loss": 8.4133,
      "step": 40
    },
    {
      "epoch": 0.13,
      "learning_rate": 8.2e-05,
      "loss": 8.4301,
      "step": 41
    },
    {
      "epoch": 0.13,
      "learning_rate": 8.4e-05,
      "loss": 8.6983,
      "step": 42
    },
    {
      "epoch": 0.14,
      "learning_rate": 8.6e-05,
      "loss": 7.871,
      "step": 43
    },
    {
      "epoch": 0.14,
      "learning_rate": 8.800000000000001e-05,
      "loss": 6.625,
      "step": 44
    },
    {
      "epoch": 0.14,
      "learning_rate": 9e-05,
      "loss": 9.6215,
      "step": 45
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.200000000000001e-05,
      "loss": 6.1227,
      "step": 46
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.4e-05,
      "loss": 6.2597,
      "step": 47
    },
    {
      "epoch": 0.15,
      "learning_rate": 9.6e-05,
      "loss": 7.4782,
      "step": 48
    },
    {
      "epoch": 0.16,
      "learning_rate": 9.8e-05,
      "loss": 7.3345,
      "step": 49
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0001,
      "loss": 7.3749,
      "step": 50
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00010200000000000001,
      "loss": 7.5089,
      "step": 51
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010400000000000001,
      "loss": 8.4622,
      "step": 52
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010600000000000002,
      "loss": 7.596,
      "step": 53
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00010800000000000001,
      "loss": 7.5764,
      "step": 54
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011000000000000002,
      "loss": 7.4765,
      "step": 55
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011200000000000001,
      "loss": 6.9692,
      "step": 56
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00011399999999999999,
      "loss": 4.5377,
      "step": 57
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.000116,
      "loss": 6.4749,
      "step": 58
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.000118,
      "loss": 6.0114,
      "step": 59
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00012,
      "loss": 6.0493,
      "step": 60
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.000122,
      "loss": 7.3822,
      "step": 61
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000124,
      "loss": 7.3809,
      "step": 62
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000126,
      "loss": 6.5897,
      "step": 63
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00012800000000000002,
      "loss": 7.1372,
      "step": 64
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00013000000000000002,
      "loss": 6.3058,
      "step": 65
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000132,
      "loss": 8.5667,
      "step": 66
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000134,
      "loss": 7.3077,
      "step": 67
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00013600000000000003,
      "loss": 4.1507,
      "step": 68
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000138,
      "loss": 4.304,
      "step": 69
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00014,
      "loss": 7.6085,
      "step": 70
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000142,
      "loss": 7.8729,
      "step": 71
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000144,
      "loss": 5.9862,
      "step": 72
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000146,
      "loss": 4.8585,
      "step": 73
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000148,
      "loss": 5.9539,
      "step": 74
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00015000000000000001,
      "loss": 7.5589,
      "step": 75
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.000152,
      "loss": 4.2443,
      "step": 76
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.000154,
      "loss": 6.1773,
      "step": 77
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00015600000000000002,
      "loss": 7.4156,
      "step": 78
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00015800000000000002,
      "loss": 7.0191,
      "step": 79
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00016,
      "loss": 6.8154,
      "step": 80
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000162,
      "loss": 6.8502,
      "step": 81
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000164,
      "loss": 3.7133,
      "step": 82
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000166,
      "loss": 4.3581,
      "step": 83
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000168,
      "loss": 7.735,
      "step": 84
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00017,
      "loss": 6.7878,
      "step": 85
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.000172,
      "loss": 7.9771,
      "step": 86
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000174,
      "loss": 8.8283,
      "step": 87
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00017600000000000002,
      "loss": 7.6323,
      "step": 88
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00017800000000000002,
      "loss": 9.2068,
      "step": 89
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00018,
      "loss": 10.2254,
      "step": 90
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000182,
      "loss": 10.2572,
      "step": 91
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00018400000000000003,
      "loss": 12.3211,
      "step": 92
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00018600000000000002,
      "loss": 15.0841,
      "step": 93
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000188,
      "loss": 15.8401,
      "step": 94
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019,
      "loss": 11.6177,
      "step": 95
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000192,
      "loss": 14.7587,
      "step": 96
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000194,
      "loss": 14.2408,
      "step": 97
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000196,
      "loss": 16.1382,
      "step": 98
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019800000000000002,
      "loss": 13.3746,
      "step": 99
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0002,
      "loss": 12.5751,
      "step": 100
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0001999342105263158,
      "loss": 15.0125,
      "step": 101
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019986842105263158,
      "loss": 14.2702,
      "step": 102
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019980263157894738,
      "loss": 17.4569,
      "step": 103
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019973684210526318,
      "loss": 18.9482,
      "step": 104
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019967105263157895,
      "loss": 17.2836,
      "step": 105
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019960526315789475,
      "loss": 18.7006,
      "step": 106
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019953947368421052,
      "loss": 14.9285,
      "step": 107
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019947368421052632,
      "loss": 21.1089,
      "step": 108
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019940789473684212,
      "loss": 23.3173,
      "step": 109
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019934210526315792,
      "loss": 21.0636,
      "step": 110
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0001992763157894737,
      "loss": 21.6619,
      "step": 111
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001992105263157895,
      "loss": 19.745,
      "step": 112
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019914473684210526,
      "loss": 20.1038,
      "step": 113
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019907894736842106,
      "loss": 19.316,
      "step": 114
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019901315789473684,
      "loss": 14.8836,
      "step": 115
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019894736842105264,
      "loss": 16.9176,
      "step": 116
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019888157894736843,
      "loss": 17.8174,
      "step": 117
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019881578947368423,
      "loss": 17.3609,
      "step": 118
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019875,
      "loss": 26.439,
      "step": 119
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0001986842105263158,
      "loss": 25.0461,
      "step": 120
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0001986184210526316,
      "loss": 25.2197,
      "step": 121
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019855263157894738,
      "loss": 24.4505,
      "step": 122
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019848684210526315,
      "loss": 23.6123,
      "step": 123
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019842105263157895,
      "loss": 22.9074,
      "step": 124
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019835526315789475,
      "loss": 22.7362,
      "step": 125
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019828947368421055,
      "loss": 21.6091,
      "step": 126
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019822368421052632,
      "loss": 19.4497,
      "step": 127
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019815789473684212,
      "loss": 19.4096,
      "step": 128
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019809210526315792,
      "loss": 18.7741,
      "step": 129
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019802631578947372,
      "loss": 20.7739,
      "step": 130
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019796052631578946,
      "loss": 20.3023,
      "step": 131
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019789473684210526,
      "loss": 21.2262,
      "step": 132
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019782894736842106,
      "loss": 20.9764,
      "step": 133
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019776315789473686,
      "loss": 22.2753,
      "step": 134
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019769736842105263,
      "loss": 22.8083,
      "step": 135
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019763157894736843,
      "loss": 20.9484,
      "step": 136
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019756578947368423,
      "loss": 20.5682,
      "step": 137
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019750000000000003,
      "loss": 20.5759,
      "step": 138
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019743421052631578,
      "loss": 20.1925,
      "step": 139
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019736842105263157,
      "loss": 20.512,
      "step": 140
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019730263157894737,
      "loss": 21.4372,
      "step": 141
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019723684210526317,
      "loss": 22.2215,
      "step": 142
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019717105263157895,
      "loss": 21.6497,
      "step": 143
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019710526315789474,
      "loss": 26.202,
      "step": 144
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019703947368421054,
      "loss": 21.6811,
      "step": 145
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019697368421052634,
      "loss": 26.7222,
      "step": 146
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019690789473684212,
      "loss": 25.9274,
      "step": 147
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001968421052631579,
      "loss": 26.9116,
      "step": 148
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001967763157894737,
      "loss": 24.3339,
      "step": 149
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019671052631578949,
      "loss": 21.4098,
      "step": 150
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019664473684210526,
      "loss": 20.1031,
      "step": 151
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019657894736842106,
      "loss": 19.152,
      "step": 152
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019651315789473686,
      "loss": 16.4297,
      "step": 153
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019644736842105266,
      "loss": 15.4417,
      "step": 154
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019638157894736843,
      "loss": 14.7011,
      "step": 155
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019631578947368423,
      "loss": 14.088,
      "step": 156
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019625,
      "loss": 12.7674,
      "step": 157
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001961842105263158,
      "loss": 12.9194,
      "step": 158
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019611842105263157,
      "loss": 13.8197,
      "step": 159
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019605263157894737,
      "loss": 14.4543,
      "step": 160
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00019598684210526317,
      "loss": 13.4982,
      "step": 161
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019592105263157897,
      "loss": 14.1973,
      "step": 162
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019585526315789474,
      "loss": 14.267,
      "step": 163
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00019578947368421054,
      "loss": 14.1564,
      "step": 164
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001957236842105263,
      "loss": 15.358,
      "step": 165
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001956578947368421,
      "loss": 16.713,
      "step": 166
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001955921052631579,
      "loss": 13.721,
      "step": 167
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019552631578947368,
      "loss": 15.4837,
      "step": 168
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019546052631578948,
      "loss": 14.3886,
      "step": 169
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019539473684210528,
      "loss": 15.0899,
      "step": 170
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00019532894736842105,
      "loss": 13.3579,
      "step": 171
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019526315789473685,
      "loss": 10.1595,
      "step": 172
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019519736842105265,
      "loss": 15.9625,
      "step": 173
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00019513157894736843,
      "loss": 15.9005,
      "step": 174
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00019506578947368422,
      "loss": 16.9157,
      "step": 175
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000195,
      "loss": 12.9977,
      "step": 176
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0001949342105263158,
      "loss": 15.3704,
      "step": 177
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0001948684210526316,
      "loss": 14.6059,
      "step": 178
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0001948026315789474,
      "loss": 14.3655,
      "step": 179
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00019473684210526317,
      "loss": 13.2713,
      "step": 180
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019467105263157897,
      "loss": 11.8176,
      "step": 181
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019460526315789477,
      "loss": 8.8979,
      "step": 182
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00019453947368421054,
      "loss": 9.9099,
      "step": 183
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001944736842105263,
      "loss": 9.3891,
      "step": 184
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001944078947368421,
      "loss": 11.6557,
      "step": 185
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001943421052631579,
      "loss": 12.4879,
      "step": 186
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0001942763157894737,
      "loss": 11.0896,
      "step": 187
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019421052631578948,
      "loss": 11.038,
      "step": 188
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00019414473684210528,
      "loss": 12.7242,
      "step": 189
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019407894736842108,
      "loss": 12.0118,
      "step": 190
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019401315789473685,
      "loss": 10.5594,
      "step": 191
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019394736842105262,
      "loss": 10.2826,
      "step": 192
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00019388157894736842,
      "loss": 12.2551,
      "step": 193
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019381578947368422,
      "loss": 10.3004,
      "step": 194
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00019375000000000002,
      "loss": 10.8729,
      "step": 195
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0001936842105263158,
      "loss": 11.7561,
      "step": 196
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001936184210526316,
      "loss": 9.4648,
      "step": 197
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001935526315789474,
      "loss": 10.7901,
      "step": 198
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001934868421052632,
      "loss": 10.9619,
      "step": 199
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019342105263157894,
      "loss": 11.6921,
      "step": 200
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019335526315789473,
      "loss": 9.3315,
      "step": 201
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00019328947368421053,
      "loss": 8.2806,
      "step": 202
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00019322368421052633,
      "loss": 6.7133,
      "step": 203
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001931578947368421,
      "loss": 8.271,
      "step": 204
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001930921052631579,
      "loss": 8.1684,
      "step": 205
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001930263157894737,
      "loss": 6.7519,
      "step": 206
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001929605263157895,
      "loss": 8.0853,
      "step": 207
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00019289473684210525,
      "loss": 7.4471,
      "step": 208
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019282894736842105,
      "loss": 7.2211,
      "step": 209
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019276315789473685,
      "loss": 8.7592,
      "step": 210
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00019269736842105265,
      "loss": 8.8813,
      "step": 211
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019263157894736842,
      "loss": 9.274,
      "step": 212
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019256578947368422,
      "loss": 7.5105,
      "step": 213
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019250000000000002,
      "loss": 7.1429,
      "step": 214
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00019243421052631582,
      "loss": 9.2634,
      "step": 215
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0001923684210526316,
      "loss": 6.715,
      "step": 216
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019230263157894736,
      "loss": 10.9345,
      "step": 217
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00019223684210526316,
      "loss": 7.6129,
      "step": 218
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019217105263157896,
      "loss": 12.159,
      "step": 219
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019210526315789473,
      "loss": 9.8723,
      "step": 220
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00019203947368421053,
      "loss": 8.8281,
      "step": 221
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019197368421052633,
      "loss": 8.7621,
      "step": 222
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00019190789473684213,
      "loss": 10.7565,
      "step": 223
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0001918421052631579,
      "loss": 9.7459,
      "step": 224
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0001917763157894737,
      "loss": 9.4441,
      "step": 225
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019171052631578947,
      "loss": 8.9404,
      "step": 226
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00019164473684210527,
      "loss": 8.0429,
      "step": 227
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019157894736842104,
      "loss": 7.2789,
      "step": 228
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019151315789473684,
      "loss": 8.0291,
      "step": 229
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00019144736842105264,
      "loss": 8.3912,
      "step": 230
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019138157894736844,
      "loss": 8.727,
      "step": 231
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019131578947368421,
      "loss": 7.2409,
      "step": 232
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00019125000000000001,
      "loss": 9.7089,
      "step": 233
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019118421052631579,
      "loss": 10.3189,
      "step": 234
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019111842105263159,
      "loss": 8.1965,
      "step": 235
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019105263157894738,
      "loss": 8.7254,
      "step": 236
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00019098684210526316,
      "loss": 9.6717,
      "step": 237
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019092105263157896,
      "loss": 5.7683,
      "step": 238
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019085526315789476,
      "loss": 6.8171,
      "step": 239
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00019078947368421053,
      "loss": 7.7083,
      "step": 240
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00019072368421052633,
      "loss": 7.6909,
      "step": 241
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00019065789473684213,
      "loss": 7.2135,
      "step": 242
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0001905921052631579,
      "loss": 8.3113,
      "step": 243
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0001905263157894737,
      "loss": 8.024,
      "step": 244
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019046052631578947,
      "loss": 8.7761,
      "step": 245
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00019039473684210527,
      "loss": 7.7232,
      "step": 246
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019032894736842107,
      "loss": 10.4809,
      "step": 247
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019026315789473687,
      "loss": 9.9043,
      "step": 248
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00019019736842105264,
      "loss": 6.0337,
      "step": 249
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019013157894736844,
      "loss": 11.841,
      "step": 250
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019006578947368424,
      "loss": 11.4816,
      "step": 251
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00019,
      "loss": 11.2749,
      "step": 252
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018993421052631578,
      "loss": 8.9063,
      "step": 253
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018986842105263158,
      "loss": 10.5343,
      "step": 254
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018980263157894738,
      "loss": 10.3194,
      "step": 255
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018973684210526318,
      "loss": 9.7584,
      "step": 256
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018967105263157895,
      "loss": 14.4965,
      "step": 257
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018960526315789475,
      "loss": 16.4215,
      "step": 258
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018953947368421055,
      "loss": 19.8624,
      "step": 259
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00018947368421052632,
      "loss": 17.3915,
      "step": 260
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0001894078947368421,
      "loss": 16.7317,
      "step": 261
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0001893421052631579,
      "loss": 18.0015,
      "step": 262
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0001892763157894737,
      "loss": 16.0877,
      "step": 263
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0001892105263157895,
      "loss": 13.1755,
      "step": 264
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00018914473684210527,
      "loss": 14.4097,
      "step": 265
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018907894736842106,
      "loss": 13.2824,
      "step": 266
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018901315789473686,
      "loss": 13.7581,
      "step": 267
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018894736842105266,
      "loss": 16.5712,
      "step": 268
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001888815789473684,
      "loss": 13.5035,
      "step": 269
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0001888157894736842,
      "loss": 11.8915,
      "step": 270
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00018875,
      "loss": 14.5707,
      "step": 271
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001886842105263158,
      "loss": 15.5897,
      "step": 272
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00018861842105263158,
      "loss": 14.7081,
      "step": 273
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00018855263157894738,
      "loss": 15.2912,
      "step": 274
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018848684210526318,
      "loss": 18.1013,
      "step": 275
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018842105263157898,
      "loss": 20.8701,
      "step": 276
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018835526315789475,
      "loss": 21.7741,
      "step": 277
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018828947368421052,
      "loss": 21.4064,
      "step": 278
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018822368421052632,
      "loss": 18.6123,
      "step": 279
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018815789473684212,
      "loss": 15.0317,
      "step": 280
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001880921052631579,
      "loss": 15.7044,
      "step": 281
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001880263157894737,
      "loss": 14.9149,
      "step": 282
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001879605263157895,
      "loss": 13.1727,
      "step": 283
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001878947368421053,
      "loss": 14.759,
      "step": 284
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018782894736842106,
      "loss": 15.3887,
      "step": 285
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018776315789473683,
      "loss": 13.0587,
      "step": 286
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018769736842105263,
      "loss": 12.1497,
      "step": 287
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00018763157894736843,
      "loss": 11.5455,
      "step": 288
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0001875657894736842,
      "loss": 14.0392,
      "step": 289
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0001875,
      "loss": 14.5723,
      "step": 290
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001874342105263158,
      "loss": 11.7874,
      "step": 291
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001873684210526316,
      "loss": 12.3434,
      "step": 292
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00018730263157894737,
      "loss": 12.4035,
      "step": 293
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018723684210526317,
      "loss": 11.6886,
      "step": 294
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018717105263157895,
      "loss": 9.0142,
      "step": 295
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018710526315789475,
      "loss": 11.394,
      "step": 296
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018703947368421052,
      "loss": 9.7303,
      "step": 297
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018697368421052632,
      "loss": 8.1218,
      "step": 298
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018690789473684212,
      "loss": 7.3644,
      "step": 299
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018684210526315792,
      "loss": 8.3423,
      "step": 300
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001867763157894737,
      "loss": 5.6038,
      "step": 301
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0001867105263157895,
      "loss": 7.4735,
      "step": 302
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018664473684210526,
      "loss": 6.4936,
      "step": 303
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018657894736842106,
      "loss": 11.1872,
      "step": 304
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018651315789473686,
      "loss": 7.7247,
      "step": 305
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018644736842105263,
      "loss": 7.2046,
      "step": 306
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018638157894736843,
      "loss": 8.2687,
      "step": 307
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018631578947368423,
      "loss": 7.922,
      "step": 308
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018625,
      "loss": 7.9956,
      "step": 309
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001861842105263158,
      "loss": 6.3759,
      "step": 310
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001861184210526316,
      "loss": 7.5518,
      "step": 311
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00018605263157894737,
      "loss": 8.8418,
      "step": 312
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018598684210526317,
      "loss": 7.6948,
      "step": 313
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018592105263157894,
      "loss": 6.7944,
      "step": 314
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018585526315789474,
      "loss": 6.6822,
      "step": 315
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00018578947368421054,
      "loss": 5.7927,
      "step": 316
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00018572368421052634,
      "loss": 7.7049,
      "step": 317
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0001856578947368421,
      "loss": 9.1632,
      "step": 318
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001855921052631579,
      "loss": 7.6945,
      "step": 319
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001855263157894737,
      "loss": 6.2945,
      "step": 320
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00018546052631578948,
      "loss": 5.1819,
      "step": 321
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018539473684210526,
      "loss": 6.5901,
      "step": 322
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018532894736842106,
      "loss": 7.983,
      "step": 323
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00018526315789473685,
      "loss": 9.2046,
      "step": 324
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018519736842105265,
      "loss": 6.5659,
      "step": 325
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018513157894736843,
      "loss": 6.6954,
      "step": 326
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018506578947368423,
      "loss": 6.4781,
      "step": 327
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00018500000000000002,
      "loss": 6.9963,
      "step": 328
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001849342105263158,
      "loss": 6.6482,
      "step": 329
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00018486842105263157,
      "loss": 6.9935,
      "step": 330
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00018480263157894737,
      "loss": 7.8637,
      "step": 331
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018473684210526317,
      "loss": 7.0802,
      "step": 332
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018467105263157897,
      "loss": 7.8831,
      "step": 333
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00018460526315789474,
      "loss": 6.8677,
      "step": 334
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018453947368421054,
      "loss": 9.8019,
      "step": 335
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018447368421052634,
      "loss": 6.0277,
      "step": 336
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00018440789473684214,
      "loss": 10.1787,
      "step": 337
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018434210526315788,
      "loss": 8.1094,
      "step": 338
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018427631578947368,
      "loss": 9.9001,
      "step": 339
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00018421052631578948,
      "loss": 9.9737,
      "step": 340
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018414473684210528,
      "loss": 7.9358,
      "step": 341
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018407894736842105,
      "loss": 9.7837,
      "step": 342
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00018401315789473685,
      "loss": 8.2897,
      "step": 343
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018394736842105265,
      "loss": 9.2263,
      "step": 344
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018388157894736845,
      "loss": 9.9906,
      "step": 345
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00018381578947368422,
      "loss": 8.6699,
      "step": 346
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00018375,
      "loss": 8.8681,
      "step": 347
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0001836842105263158,
      "loss": 9.8318,
      "step": 348
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0001836184210526316,
      "loss": 8.1051,
      "step": 349
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00018355263157894736,
      "loss": 11.4609,
      "step": 350
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018348684210526316,
      "loss": 11.2862,
      "step": 351
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018342105263157896,
      "loss": 12.2515,
      "step": 352
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00018335526315789476,
      "loss": 11.3103,
      "step": 353
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00018328947368421053,
      "loss": 8.2848,
      "step": 354
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001832236842105263,
      "loss": 9.6668,
      "step": 355
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001831578947368421,
      "loss": 11.3855,
      "step": 356
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0001830921052631579,
      "loss": 10.8505,
      "step": 357
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00018302631578947368,
      "loss": 11.7766,
      "step": 358
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00018296052631578948,
      "loss": 10.8459,
      "step": 359
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018289473684210528,
      "loss": 11.4489,
      "step": 360
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018282894736842108,
      "loss": 11.3321,
      "step": 361
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018276315789473685,
      "loss": 12.6805,
      "step": 362
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018269736842105265,
      "loss": 11.6585,
      "step": 363
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018263157894736842,
      "loss": 9.2467,
      "step": 364
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00018256578947368422,
      "loss": 10.3239,
      "step": 365
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001825,
      "loss": 9.0767,
      "step": 366
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001824342105263158,
      "loss": 8.9068,
      "step": 367
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001823684210526316,
      "loss": 9.4668,
      "step": 368
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0001823026315789474,
      "loss": 9.7107,
      "step": 369
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018223684210526316,
      "loss": 5.056,
      "step": 370
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018217105263157896,
      "loss": 9.0235,
      "step": 371
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018210526315789476,
      "loss": 7.2697,
      "step": 372
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00018203947368421053,
      "loss": 8.1155,
      "step": 373
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00018197368421052633,
      "loss": 9.6886,
      "step": 374
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0001819078947368421,
      "loss": 8.714,
      "step": 375
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0001818421052631579,
      "loss": 7.6017,
      "step": 376
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0001817763157894737,
      "loss": 8.3032,
      "step": 377
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00018171052631578947,
      "loss": 9.767,
      "step": 378
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018164473684210527,
      "loss": 6.8952,
      "step": 379
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018157894736842107,
      "loss": 7.7691,
      "step": 380
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018151315789473684,
      "loss": 7.4938,
      "step": 381
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018144736842105264,
      "loss": 7.8102,
      "step": 382
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018138157894736842,
      "loss": 8.4985,
      "step": 383
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018131578947368422,
      "loss": 7.6459,
      "step": 384
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018125000000000001,
      "loss": 8.5635,
      "step": 385
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018118421052631581,
      "loss": 5.0362,
      "step": 386
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00018111842105263159,
      "loss": 5.7943,
      "step": 387
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018105263157894739,
      "loss": 6.2967,
      "step": 388
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018098684210526318,
      "loss": 9.3257,
      "step": 389
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00018092105263157896,
      "loss": 6.6711,
      "step": 390
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018085526315789473,
      "loss": 7.1532,
      "step": 391
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018078947368421053,
      "loss": 7.2052,
      "step": 392
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018072368421052633,
      "loss": 8.6348,
      "step": 393
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00018065789473684213,
      "loss": 7.0797,
      "step": 394
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001805921052631579,
      "loss": 6.7545,
      "step": 395
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001805263157894737,
      "loss": 5.9885,
      "step": 396
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0001804605263157895,
      "loss": 6.6452,
      "step": 397
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018039473684210527,
      "loss": 7.8825,
      "step": 398
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018032894736842104,
      "loss": 6.7477,
      "step": 399
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00018026315789473684,
      "loss": 7.6022,
      "step": 400
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00018019736842105264,
      "loss": 5.2887,
      "step": 401
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00018013157894736844,
      "loss": 7.0855,
      "step": 402
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0001800657894736842,
      "loss": 7.6928,
      "step": 403
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00018,
      "loss": 7.0171,
      "step": 404
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0001799342105263158,
      "loss": 9.5572,
      "step": 405
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0001798684210526316,
      "loss": 8.4234,
      "step": 406
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017980263157894735,
      "loss": 9.627,
      "step": 407
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017973684210526315,
      "loss": 8.5001,
      "step": 408
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017967105263157895,
      "loss": 8.0787,
      "step": 409
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017960526315789475,
      "loss": 6.5977,
      "step": 410
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017953947368421053,
      "loss": 5.0208,
      "step": 411
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017947368421052632,
      "loss": 6.9425,
      "step": 412
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017940789473684212,
      "loss": 7.6974,
      "step": 413
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017934210526315792,
      "loss": 5.2986,
      "step": 414
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0001792763157894737,
      "loss": 8.2266,
      "step": 415
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017921052631578947,
      "loss": 8.156,
      "step": 416
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017914473684210527,
      "loss": 7.4764,
      "step": 417
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017907894736842107,
      "loss": 8.3185,
      "step": 418
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017901315789473684,
      "loss": 7.6152,
      "step": 419
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017894736842105264,
      "loss": 6.6326,
      "step": 420
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017888157894736844,
      "loss": 8.4163,
      "step": 421
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017881578947368424,
      "loss": 6.695,
      "step": 422
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017875,
      "loss": 8.7324,
      "step": 423
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017868421052631578,
      "loss": 6.9342,
      "step": 424
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017861842105263158,
      "loss": 11.035,
      "step": 425
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017855263157894738,
      "loss": 11.0419,
      "step": 426
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017848684210526315,
      "loss": 9.4253,
      "step": 427
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017842105263157895,
      "loss": 12.7597,
      "step": 428
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017835526315789475,
      "loss": 6.5763,
      "step": 429
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017828947368421055,
      "loss": 10.4711,
      "step": 430
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017822368421052632,
      "loss": 9.7972,
      "step": 431
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00017815789473684212,
      "loss": 6.1812,
      "step": 432
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001780921052631579,
      "loss": 11.0408,
      "step": 433
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001780263157894737,
      "loss": 11.1766,
      "step": 434
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0001779605263157895,
      "loss": 10.0879,
      "step": 435
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017789473684210526,
      "loss": 9.0864,
      "step": 436
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017782894736842106,
      "loss": 7.6043,
      "step": 437
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017776315789473686,
      "loss": 9.8173,
      "step": 438
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017769736842105263,
      "loss": 9.3867,
      "step": 439
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017763157894736843,
      "loss": 8.2974,
      "step": 440
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017756578947368423,
      "loss": 9.8381,
      "step": 441
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001775,
      "loss": 7.1877,
      "step": 442
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001774342105263158,
      "loss": 7.7126,
      "step": 443
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00017736842105263158,
      "loss": 6.5377,
      "step": 444
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017730263157894738,
      "loss": 9.8501,
      "step": 445
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017723684210526317,
      "loss": 8.0838,
      "step": 446
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017717105263157895,
      "loss": 4.8709,
      "step": 447
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017710526315789475,
      "loss": 7.4893,
      "step": 448
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017703947368421055,
      "loss": 8.3785,
      "step": 449
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017697368421052632,
      "loss": 8.3244,
      "step": 450
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00017690789473684212,
      "loss": 9.8595,
      "step": 451
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001768421052631579,
      "loss": 9.4643,
      "step": 452
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001767763157894737,
      "loss": 4.4912,
      "step": 453
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0001767105263157895,
      "loss": 8.6767,
      "step": 454
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0001766447368421053,
      "loss": 8.941,
      "step": 455
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00017657894736842106,
      "loss": 6.4551,
      "step": 456
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017651315789473686,
      "loss": 10.098,
      "step": 457
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017644736842105266,
      "loss": 7.2525,
      "step": 458
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017638157894736843,
      "loss": 9.5392,
      "step": 459
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0001763157894736842,
      "loss": 7.7694,
      "step": 460
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00017625,
      "loss": 10.5878,
      "step": 461
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001761842105263158,
      "loss": 8.6952,
      "step": 462
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001761184210526316,
      "loss": 8.1309,
      "step": 463
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017605263157894737,
      "loss": 8.6866,
      "step": 464
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017598684210526317,
      "loss": 9.2521,
      "step": 465
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017592105263157897,
      "loss": 6.3651,
      "step": 466
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017585526315789474,
      "loss": 6.9983,
      "step": 467
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017578947368421052,
      "loss": 8.9906,
      "step": 468
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017572368421052631,
      "loss": 7.0841,
      "step": 469
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017565789473684211,
      "loss": 7.6972,
      "step": 470
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0001755921052631579,
      "loss": 7.7349,
      "step": 471
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017552631578947369,
      "loss": 6.2193,
      "step": 472
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017546052631578948,
      "loss": 6.4108,
      "step": 473
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017539473684210528,
      "loss": 8.5691,
      "step": 474
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00017532894736842108,
      "loss": 8.0335,
      "step": 475
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017526315789473683,
      "loss": 7.9568,
      "step": 476
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017519736842105263,
      "loss": 7.407,
      "step": 477
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00017513157894736843,
      "loss": 6.7954,
      "step": 478
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00017506578947368423,
      "loss": 7.835,
      "step": 479
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000175,
      "loss": 6.0811,
      "step": 480
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0001749342105263158,
      "loss": 9.3357,
      "step": 481
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001748684210526316,
      "loss": 7.903,
      "step": 482
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001748026315789474,
      "loss": 7.2982,
      "step": 483
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00017473684210526317,
      "loss": 9.1905,
      "step": 484
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00017467105263157894,
      "loss": 8.2641,
      "step": 485
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00017460526315789474,
      "loss": 8.5395,
      "step": 486
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00017453947368421054,
      "loss": 8.9992,
      "step": 487
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0001744736842105263,
      "loss": 7.5806,
      "step": 488
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001744078947368421,
      "loss": 6.2173,
      "step": 489
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001743421052631579,
      "loss": 6.139,
      "step": 490
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0001742763157894737,
      "loss": 8.873,
      "step": 491
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017421052631578948,
      "loss": 6.3816,
      "step": 492
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017414473684210525,
      "loss": 8.0174,
      "step": 493
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00017407894736842105,
      "loss": 7.3974,
      "step": 494
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017401315789473685,
      "loss": 7.5018,
      "step": 495
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017394736842105262,
      "loss": 8.9115,
      "step": 496
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00017388157894736842,
      "loss": 5.7531,
      "step": 497
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00017381578947368422,
      "loss": 8.8558,
      "step": 498
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00017375000000000002,
      "loss": 5.3447,
      "step": 499
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001736842105263158,
      "loss": 5.8546,
      "step": 500
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001736184210526316,
      "loss": 5.2057,
      "step": 501
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00017355263157894737,
      "loss": 7.0328,
      "step": 502
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00017348684210526316,
      "loss": 7.5172,
      "step": 503
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017342105263157896,
      "loss": 9.4729,
      "step": 504
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017335526315789474,
      "loss": 6.3143,
      "step": 505
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017328947368421054,
      "loss": 6.094,
      "step": 506
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00017322368421052634,
      "loss": 6.535,
      "step": 507
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001731578947368421,
      "loss": 6.1028,
      "step": 508
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001730921052631579,
      "loss": 7.2121,
      "step": 509
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001730263157894737,
      "loss": 5.3467,
      "step": 510
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017296052631578948,
      "loss": 7.8162,
      "step": 511
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017289473684210528,
      "loss": 5.9826,
      "step": 512
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00017282894736842105,
      "loss": 4.9153,
      "step": 513
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017276315789473685,
      "loss": 5.1952,
      "step": 514
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017269736842105265,
      "loss": 9.6705,
      "step": 515
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00017263157894736842,
      "loss": 4.0367,
      "step": 516
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00017256578947368422,
      "loss": 7.9563,
      "step": 517
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00017250000000000002,
      "loss": 7.6047,
      "step": 518
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001724342105263158,
      "loss": 7.3881,
      "step": 519
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001723684210526316,
      "loss": 5.9305,
      "step": 520
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00017230263157894736,
      "loss": 7.739,
      "step": 521
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00017223684210526316,
      "loss": 6.4404,
      "step": 522
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017217105263157896,
      "loss": 6.6856,
      "step": 523
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017210526315789476,
      "loss": 6.4346,
      "step": 524
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00017203947368421053,
      "loss": 7.4347,
      "step": 525
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017197368421052633,
      "loss": 7.0139,
      "step": 526
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017190789473684213,
      "loss": 6.917,
      "step": 527
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0001718421052631579,
      "loss": 8.8123,
      "step": 528
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00017177631578947368,
      "loss": 8.1804,
      "step": 529
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017171052631578947,
      "loss": 8.0765,
      "step": 530
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017164473684210527,
      "loss": 7.6481,
      "step": 531
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00017157894736842107,
      "loss": 7.5002,
      "step": 532
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017151315789473685,
      "loss": 5.4967,
      "step": 533
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017144736842105264,
      "loss": 5.7779,
      "step": 534
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00017138157894736844,
      "loss": 7.4914,
      "step": 535
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00017131578947368422,
      "loss": 6.8433,
      "step": 536
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00017125,
      "loss": 7.821,
      "step": 537
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0001711842105263158,
      "loss": 7.6259,
      "step": 538
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0001711184210526316,
      "loss": 5.8863,
      "step": 539
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00017105263157894739,
      "loss": 4.9646,
      "step": 540
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00017098684210526316,
      "loss": 9.1112,
      "step": 541
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017092105263157896,
      "loss": 8.009,
      "step": 542
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017085526315789476,
      "loss": 6.8101,
      "step": 543
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00017078947368421056,
      "loss": 7.6545,
      "step": 544
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001707236842105263,
      "loss": 6.2157,
      "step": 545
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001706578947368421,
      "loss": 7.5117,
      "step": 546
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001705921052631579,
      "loss": 6.2438,
      "step": 547
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0001705263157894737,
      "loss": 6.6676,
      "step": 548
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017046052631578947,
      "loss": 6.6791,
      "step": 549
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017039473684210527,
      "loss": 6.9335,
      "step": 550
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00017032894736842107,
      "loss": 9.5455,
      "step": 551
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017026315789473687,
      "loss": 6.1273,
      "step": 552
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017019736842105264,
      "loss": 7.6874,
      "step": 553
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00017013157894736841,
      "loss": 6.0116,
      "step": 554
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0001700657894736842,
      "loss": 7.4642,
      "step": 555
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00017,
      "loss": 8.0394,
      "step": 556
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00016993421052631578,
      "loss": 8.3467,
      "step": 557
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016986842105263158,
      "loss": 7.148,
      "step": 558
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016980263157894738,
      "loss": 7.0483,
      "step": 559
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00016973684210526318,
      "loss": 9.3816,
      "step": 560
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016967105263157895,
      "loss": 4.5338,
      "step": 561
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016960526315789475,
      "loss": 8.1417,
      "step": 562
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016953947368421053,
      "loss": 6.4424,
      "step": 563
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.00016947368421052633,
      "loss": 5.439,
      "step": 564
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001694078947368421,
      "loss": 7.7598,
      "step": 565
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001693421052631579,
      "loss": 6.0347,
      "step": 566
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001692763157894737,
      "loss": 8.3304,
      "step": 567
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001692105263157895,
      "loss": 4.7275,
      "step": 568
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00016914473684210527,
      "loss": 6.6496,
      "step": 569
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016907894736842107,
      "loss": 5.6252,
      "step": 570
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016901315789473684,
      "loss": 7.7278,
      "step": 571
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016894736842105264,
      "loss": 5.3837,
      "step": 572
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016888157894736844,
      "loss": 7.6139,
      "step": 573
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0001688157894736842,
      "loss": 7.3205,
      "step": 574
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00016875,
      "loss": 5.8176,
      "step": 575
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0001686842105263158,
      "loss": 6.082,
      "step": 576
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016861842105263158,
      "loss": 7.3743,
      "step": 577
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016855263157894738,
      "loss": 5.2722,
      "step": 578
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016848684210526318,
      "loss": 8.1518,
      "step": 579
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016842105263157895,
      "loss": 7.4338,
      "step": 580
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016835526315789475,
      "loss": 5.2382,
      "step": 581
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016828947368421052,
      "loss": 6.7977,
      "step": 582
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016822368421052632,
      "loss": 6.5813,
      "step": 583
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016815789473684212,
      "loss": 5.9156,
      "step": 584
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0001680921052631579,
      "loss": 6.4112,
      "step": 585
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0001680263157894737,
      "loss": 5.3477,
      "step": 586
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0001679605263157895,
      "loss": 3.4396,
      "step": 587
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00016789473684210526,
      "loss": 6.8688,
      "step": 588
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016782894736842106,
      "loss": 6.5531,
      "step": 589
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016776315789473684,
      "loss": 8.3735,
      "step": 590
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016769736842105263,
      "loss": 7.5751,
      "step": 591
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016763157894736843,
      "loss": 8.2157,
      "step": 592
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016756578947368423,
      "loss": 6.4087,
      "step": 593
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0001675,
      "loss": 6.1903,
      "step": 594
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0001674342105263158,
      "loss": 5.2205,
      "step": 595
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0001673684210526316,
      "loss": 7.0044,
      "step": 596
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016730263157894738,
      "loss": 4.5823,
      "step": 597
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016723684210526315,
      "loss": 5.9253,
      "step": 598
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016717105263157895,
      "loss": 4.3104,
      "step": 599
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016710526315789475,
      "loss": 4.5051,
      "step": 600
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016703947368421055,
      "loss": 4.3634,
      "step": 601
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016697368421052632,
      "loss": 6.381,
      "step": 602
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016690789473684212,
      "loss": 6.5078,
      "step": 603
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016684210526315792,
      "loss": 6.8479,
      "step": 604
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0001667763157894737,
      "loss": 6.9782,
      "step": 605
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016671052631578946,
      "loss": 7.0489,
      "step": 606
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016664473684210526,
      "loss": 7.218,
      "step": 607
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016657894736842106,
      "loss": 6.8946,
      "step": 608
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016651315789473686,
      "loss": 5.0504,
      "step": 609
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016644736842105263,
      "loss": 6.9306,
      "step": 610
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016638157894736843,
      "loss": 5.0708,
      "step": 611
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016631578947368423,
      "loss": 8.3567,
      "step": 612
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016625000000000003,
      "loss": 5.7654,
      "step": 613
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016618421052631577,
      "loss": 7.5326,
      "step": 614
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016611842105263157,
      "loss": 7.3344,
      "step": 615
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016605263157894737,
      "loss": 7.5294,
      "step": 616
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016598684210526317,
      "loss": 6.3524,
      "step": 617
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016592105263157894,
      "loss": 7.1576,
      "step": 618
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016585526315789474,
      "loss": 6.4871,
      "step": 619
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016578947368421054,
      "loss": 6.1212,
      "step": 620
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016572368421052634,
      "loss": 6.6827,
      "step": 621
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016565789473684211,
      "loss": 7.6906,
      "step": 622
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0001655921052631579,
      "loss": 7.9251,
      "step": 623
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016552631578947369,
      "loss": 7.0462,
      "step": 624
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016546052631578949,
      "loss": 5.8511,
      "step": 625
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016539473684210526,
      "loss": 8.9401,
      "step": 626
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016532894736842106,
      "loss": 6.6981,
      "step": 627
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016526315789473686,
      "loss": 5.2718,
      "step": 628
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016519736842105266,
      "loss": 5.9845,
      "step": 629
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00016513157894736843,
      "loss": 6.7545,
      "step": 630
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00016506578947368423,
      "loss": 3.6693,
      "step": 631
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.000165,
      "loss": 7.8874,
      "step": 632
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0001649342105263158,
      "loss": 3.6892,
      "step": 633
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00016486842105263157,
      "loss": 4.8252,
      "step": 634
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00016480263157894737,
      "loss": 5.7972,
      "step": 635
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016473684210526317,
      "loss": 6.2797,
      "step": 636
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016467105263157897,
      "loss": 8.9891,
      "step": 637
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00016460526315789474,
      "loss": 7.0017,
      "step": 638
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00016453947368421054,
      "loss": 8.5476,
      "step": 639
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001644736842105263,
      "loss": 5.6032,
      "step": 640
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001644078947368421,
      "loss": 4.7811,
      "step": 641
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001643421052631579,
      "loss": 6.067,
      "step": 642
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016427631578947368,
      "loss": 5.8464,
      "step": 643
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016421052631578948,
      "loss": 6.6472,
      "step": 644
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00016414473684210528,
      "loss": 6.6265,
      "step": 645
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016407894736842105,
      "loss": 4.6543,
      "step": 646
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016401315789473685,
      "loss": 6.0185,
      "step": 647
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00016394736842105265,
      "loss": 6.3654,
      "step": 648
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016388157894736842,
      "loss": 4.041,
      "step": 649
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016381578947368422,
      "loss": 6.3336,
      "step": 650
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00016375,
      "loss": 8.414,
      "step": 651
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0001636842105263158,
      "loss": 7.434,
      "step": 652
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0001636184210526316,
      "loss": 3.7716,
      "step": 653
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00016355263157894737,
      "loss": 8.3403,
      "step": 654
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016348684210526317,
      "loss": 6.2682,
      "step": 655
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016342105263157897,
      "loss": 6.2844,
      "step": 656
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00016335526315789476,
      "loss": 7.4151,
      "step": 657
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00016328947368421054,
      "loss": 6.6818,
      "step": 658
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001632236842105263,
      "loss": 8.6314,
      "step": 659
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001631578947368421,
      "loss": 6.9084,
      "step": 660
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0001630921052631579,
      "loss": 6.694,
      "step": 661
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0001630263157894737,
      "loss": 6.9694,
      "step": 662
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00016296052631578948,
      "loss": 6.711,
      "step": 663
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00016289473684210528,
      "loss": 8.012,
      "step": 664
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016282894736842108,
      "loss": 5.7472,
      "step": 665
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016276315789473685,
      "loss": 5.6348,
      "step": 666
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00016269736842105262,
      "loss": 6.6843,
      "step": 667
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016263157894736842,
      "loss": 9.1781,
      "step": 668
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016256578947368422,
      "loss": 6.2448,
      "step": 669
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016250000000000002,
      "loss": 7.1374,
      "step": 670
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001624342105263158,
      "loss": 8.9919,
      "step": 671
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001623684210526316,
      "loss": 5.0703,
      "step": 672
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001623026315789474,
      "loss": 6.9487,
      "step": 673
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016223684210526316,
      "loss": 6.9791,
      "step": 674
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016217105263157893,
      "loss": 6.9609,
      "step": 675
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00016210526315789473,
      "loss": 6.511,
      "step": 676
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00016203947368421053,
      "loss": 5.0456,
      "step": 677
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00016197368421052633,
      "loss": 4.7139,
      "step": 678
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0001619078947368421,
      "loss": 7.2923,
      "step": 679
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001618421052631579,
      "loss": 4.6535,
      "step": 680
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001617763157894737,
      "loss": 6.5314,
      "step": 681
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001617105263157895,
      "loss": 8.8248,
      "step": 682
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016164473684210525,
      "loss": 5.6368,
      "step": 683
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016157894736842105,
      "loss": 5.3128,
      "step": 684
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016151315789473685,
      "loss": 6.858,
      "step": 685
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00016144736842105265,
      "loss": 8.1294,
      "step": 686
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016138157894736842,
      "loss": 3.6248,
      "step": 687
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016131578947368422,
      "loss": 5.5736,
      "step": 688
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00016125000000000002,
      "loss": 7.8241,
      "step": 689
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00016118421052631582,
      "loss": 5.7889,
      "step": 690
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0001611184210526316,
      "loss": 7.7371,
      "step": 691
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00016105263157894736,
      "loss": 5.0423,
      "step": 692
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016098684210526316,
      "loss": 8.0954,
      "step": 693
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016092105263157896,
      "loss": 8.5545,
      "step": 694
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00016085526315789473,
      "loss": 6.9751,
      "step": 695
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016078947368421053,
      "loss": 5.7838,
      "step": 696
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016072368421052633,
      "loss": 7.0672,
      "step": 697
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00016065789473684213,
      "loss": 7.3838,
      "step": 698
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0001605921052631579,
      "loss": 5.1222,
      "step": 699
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0001605263157894737,
      "loss": 7.9851,
      "step": 700
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00016046052631578947,
      "loss": 6.7359,
      "step": 701
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016039473684210527,
      "loss": 6.4469,
      "step": 702
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016032894736842104,
      "loss": 9.1707,
      "step": 703
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00016026315789473684,
      "loss": 7.643,
      "step": 704
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016019736842105264,
      "loss": 5.6455,
      "step": 705
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016013157894736844,
      "loss": 6.7616,
      "step": 706
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016006578947368421,
      "loss": 7.8844,
      "step": 707
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00016,
      "loss": 7.1474,
      "step": 708
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015993421052631579,
      "loss": 6.6469,
      "step": 709
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015986842105263158,
      "loss": 7.9354,
      "step": 710
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015980263157894738,
      "loss": 5.6746,
      "step": 711
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015973684210526316,
      "loss": 7.4044,
      "step": 712
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015967105263157896,
      "loss": 5.5899,
      "step": 713
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015960526315789475,
      "loss": 6.221,
      "step": 714
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015953947368421053,
      "loss": 6.7536,
      "step": 715
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015947368421052633,
      "loss": 6.4945,
      "step": 716
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015940789473684213,
      "loss": 6.7731,
      "step": 717
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001593421052631579,
      "loss": 7.3555,
      "step": 718
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001592763157894737,
      "loss": 6.4165,
      "step": 719
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00015921052631578947,
      "loss": 7.2108,
      "step": 720
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015914473684210527,
      "loss": 5.5116,
      "step": 721
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015907894736842107,
      "loss": 5.2434,
      "step": 722
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015901315789473684,
      "loss": 6.2195,
      "step": 723
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015894736842105264,
      "loss": 6.9556,
      "step": 724
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015888157894736844,
      "loss": 6.5432,
      "step": 725
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00015881578947368424,
      "loss": 5.8987,
      "step": 726
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015875,
      "loss": 6.538,
      "step": 727
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015868421052631578,
      "loss": 8.3281,
      "step": 728
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015861842105263158,
      "loss": 5.519,
      "step": 729
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015855263157894738,
      "loss": 7.948,
      "step": 730
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015848684210526318,
      "loss": 7.2478,
      "step": 731
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015842105263157895,
      "loss": 6.8984,
      "step": 732
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015835526315789475,
      "loss": 4.3433,
      "step": 733
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00015828947368421055,
      "loss": 7.5655,
      "step": 734
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00015822368421052632,
      "loss": 6.3821,
      "step": 735
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0001581578947368421,
      "loss": 6.0639,
      "step": 736
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001580921052631579,
      "loss": 7.3338,
      "step": 737
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001580263157894737,
      "loss": 7.3776,
      "step": 738
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001579605263157895,
      "loss": 6.675,
      "step": 739
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015789473684210527,
      "loss": 7.3202,
      "step": 740
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015782894736842106,
      "loss": 5.4583,
      "step": 741
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015776315789473686,
      "loss": 5.0976,
      "step": 742
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00015769736842105264,
      "loss": 5.0371,
      "step": 743
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0001576315789473684,
      "loss": 5.8948,
      "step": 744
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0001575657894736842,
      "loss": 6.8185,
      "step": 745
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0001575,
      "loss": 7.741,
      "step": 746
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0001574342105263158,
      "loss": 6.6126,
      "step": 747
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00015736842105263158,
      "loss": 5.6508,
      "step": 748
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015730263157894738,
      "loss": 5.7831,
      "step": 749
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015723684210526318,
      "loss": 7.2376,
      "step": 750
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015717105263157898,
      "loss": 7.1645,
      "step": 751
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015710526315789475,
      "loss": 7.2393,
      "step": 752
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015703947368421052,
      "loss": 8.1738,
      "step": 753
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015697368421052632,
      "loss": 6.4703,
      "step": 754
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015690789473684212,
      "loss": 7.816,
      "step": 755
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001568421052631579,
      "loss": 7.2473,
      "step": 756
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001567763157894737,
      "loss": 4.9348,
      "step": 757
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001567105263157895,
      "loss": 7.0899,
      "step": 758
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0001566447368421053,
      "loss": 7.0002,
      "step": 759
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00015657894736842106,
      "loss": 6.6266,
      "step": 760
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00015651315789473683,
      "loss": 4.9791,
      "step": 761
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00015644736842105263,
      "loss": 6.0215,
      "step": 762
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00015638157894736843,
      "loss": 6.4615,
      "step": 763
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0001563157894736842,
      "loss": 7.1153,
      "step": 764
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00015625,
      "loss": 7.9944,
      "step": 765
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0001561842105263158,
      "loss": 6.3988,
      "step": 766
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0001561184210526316,
      "loss": 5.3613,
      "step": 767
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015605263157894737,
      "loss": 5.2903,
      "step": 768
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015598684210526317,
      "loss": 4.8942,
      "step": 769
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015592105263157895,
      "loss": 3.4212,
      "step": 770
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015585526315789474,
      "loss": 5.8533,
      "step": 771
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015578947368421052,
      "loss": 7.2413,
      "step": 772
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015572368421052632,
      "loss": 6.6859,
      "step": 773
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015565789473684212,
      "loss": 6.0702,
      "step": 774
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00015559210526315791,
      "loss": 6.2573,
      "step": 775
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0001555263157894737,
      "loss": 7.8818,
      "step": 776
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00015546052631578949,
      "loss": 5.7124,
      "step": 777
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015539473684210526,
      "loss": 6.9013,
      "step": 778
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015532894736842106,
      "loss": 7.0208,
      "step": 779
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015526315789473686,
      "loss": 6.6827,
      "step": 780
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015519736842105263,
      "loss": 5.9441,
      "step": 781
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015513157894736843,
      "loss": 7.1122,
      "step": 782
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015506578947368423,
      "loss": 6.728,
      "step": 783
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.000155,
      "loss": 5.0752,
      "step": 784
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001549342105263158,
      "loss": 5.9231,
      "step": 785
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001548684210526316,
      "loss": 6.5907,
      "step": 786
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015480263157894737,
      "loss": 8.2295,
      "step": 787
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015473684210526317,
      "loss": 7.4967,
      "step": 788
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00015467105263157894,
      "loss": 6.9904,
      "step": 789
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00015460526315789474,
      "loss": 4.3657,
      "step": 790
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00015453947368421054,
      "loss": 7.6279,
      "step": 791
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0001544736842105263,
      "loss": 5.5869,
      "step": 792
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001544078947368421,
      "loss": 5.9186,
      "step": 793
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001543421052631579,
      "loss": 7.4644,
      "step": 794
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001542763157894737,
      "loss": 6.3364,
      "step": 795
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015421052631578948,
      "loss": 6.8816,
      "step": 796
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015414473684210526,
      "loss": 8.3012,
      "step": 797
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015407894736842105,
      "loss": 5.454,
      "step": 798
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015401315789473685,
      "loss": 6.4431,
      "step": 799
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015394736842105265,
      "loss": 7.0492,
      "step": 800
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015388157894736843,
      "loss": 5.8384,
      "step": 801
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015381578947368422,
      "loss": 5.6661,
      "step": 802
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00015375000000000002,
      "loss": 5.2635,
      "step": 803
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0001536842105263158,
      "loss": 3.7131,
      "step": 804
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00015361842105263157,
      "loss": 6.6371,
      "step": 805
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015355263157894737,
      "loss": 6.4124,
      "step": 806
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015348684210526317,
      "loss": 5.9355,
      "step": 807
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00015342105263157897,
      "loss": 5.1462,
      "step": 808
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015335526315789474,
      "loss": 5.3767,
      "step": 809
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015328947368421054,
      "loss": 6.8195,
      "step": 810
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00015322368421052634,
      "loss": 4.4444,
      "step": 811
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0001531578947368421,
      "loss": 3.6598,
      "step": 812
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00015309210526315788,
      "loss": 4.9692,
      "step": 813
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00015302631578947368,
      "loss": 6.9108,
      "step": 814
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015296052631578948,
      "loss": 8.1998,
      "step": 815
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015289473684210528,
      "loss": 6.8161,
      "step": 816
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00015282894736842105,
      "loss": 5.8481,
      "step": 817
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015276315789473685,
      "loss": 5.9156,
      "step": 818
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015269736842105265,
      "loss": 5.5674,
      "step": 819
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015263157894736845,
      "loss": 5.3137,
      "step": 820
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00015256578947368422,
      "loss": 6.1893,
      "step": 821
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001525,
      "loss": 6.4184,
      "step": 822
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001524342105263158,
      "loss": 5.6095,
      "step": 823
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001523684210526316,
      "loss": 7.8894,
      "step": 824
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015230263157894736,
      "loss": 6.6889,
      "step": 825
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015223684210526316,
      "loss": 6.5747,
      "step": 826
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00015217105263157896,
      "loss": 6.1156,
      "step": 827
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00015210526315789476,
      "loss": 5.8202,
      "step": 828
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00015203947368421053,
      "loss": 5.5123,
      "step": 829
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0001519736842105263,
      "loss": 5.2674,
      "step": 830
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0001519078947368421,
      "loss": 5.4908,
      "step": 831
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0001518421052631579,
      "loss": 6.4388,
      "step": 832
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00015177631578947368,
      "loss": 5.0561,
      "step": 833
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015171052631578948,
      "loss": 8.7734,
      "step": 834
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015164473684210528,
      "loss": 5.1529,
      "step": 835
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00015157894736842108,
      "loss": 5.5235,
      "step": 836
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015151315789473685,
      "loss": 6.8769,
      "step": 837
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015144736842105265,
      "loss": 5.435,
      "step": 838
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00015138157894736842,
      "loss": 3.8633,
      "step": 839
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00015131578947368422,
      "loss": 6.4536,
      "step": 840
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00015125,
      "loss": 6.767,
      "step": 841
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001511842105263158,
      "loss": 5.6768,
      "step": 842
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001511184210526316,
      "loss": 7.9853,
      "step": 843
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0001510526315789474,
      "loss": 6.7176,
      "step": 844
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00015098684210526316,
      "loss": 6.1393,
      "step": 845
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00015092105263157896,
      "loss": 3.9655,
      "step": 846
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015085526315789476,
      "loss": 6.1113,
      "step": 847
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015078947368421053,
      "loss": 5.4648,
      "step": 848
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00015072368421052633,
      "loss": 5.6201,
      "step": 849
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001506578947368421,
      "loss": 5.8592,
      "step": 850
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001505921052631579,
      "loss": 4.605,
      "step": 851
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001505263157894737,
      "loss": 6.5752,
      "step": 852
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015046052631578947,
      "loss": 5.8605,
      "step": 853
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015039473684210527,
      "loss": 4.6916,
      "step": 854
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00015032894736842107,
      "loss": 4.5582,
      "step": 855
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015026315789473684,
      "loss": 7.8363,
      "step": 856
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015019736842105264,
      "loss": 5.9937,
      "step": 857
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00015013157894736842,
      "loss": 5.5856,
      "step": 858
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00015006578947368421,
      "loss": 6.2379,
      "step": 859
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00015000000000000001,
      "loss": 8.5126,
      "step": 860
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00014993421052631579,
      "loss": 6.6379,
      "step": 861
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014986842105263159,
      "loss": 5.2698,
      "step": 862
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014980263157894738,
      "loss": 6.1544,
      "step": 863
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014973684210526318,
      "loss": 5.5434,
      "step": 864
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014967105263157896,
      "loss": 6.7835,
      "step": 865
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014960526315789473,
      "loss": 5.8804,
      "step": 866
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014953947368421053,
      "loss": 6.6801,
      "step": 867
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014947368421052633,
      "loss": 6.0688,
      "step": 868
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.00014940789473684213,
      "loss": 5.6664,
      "step": 869
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001493421052631579,
      "loss": 7.1206,
      "step": 870
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001492763157894737,
      "loss": 5.9399,
      "step": 871
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0001492105263157895,
      "loss": 7.3804,
      "step": 872
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014914473684210527,
      "loss": 6.2835,
      "step": 873
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014907894736842104,
      "loss": 4.9061,
      "step": 874
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014901315789473684,
      "loss": 8.5323,
      "step": 875
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014894736842105264,
      "loss": 5.9518,
      "step": 876
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00014888157894736844,
      "loss": 6.9103,
      "step": 877
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0001488157894736842,
      "loss": 6.898,
      "step": 878
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00014875,
      "loss": 7.8909,
      "step": 879
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0001486842105263158,
      "loss": 5.5964,
      "step": 880
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014861842105263158,
      "loss": 5.9566,
      "step": 881
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014855263157894735,
      "loss": 5.163,
      "step": 882
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014848684210526315,
      "loss": 6.4404,
      "step": 883
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014842105263157895,
      "loss": 7.5725,
      "step": 884
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014835526315789475,
      "loss": 7.9372,
      "step": 885
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014828947368421052,
      "loss": 5.1593,
      "step": 886
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014822368421052632,
      "loss": 8.9093,
      "step": 887
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00014815789473684212,
      "loss": 5.4914,
      "step": 888
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00014809210526315792,
      "loss": 7.5177,
      "step": 889
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0001480263157894737,
      "loss": 7.0449,
      "step": 890
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014796052631578947,
      "loss": 5.1561,
      "step": 891
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014789473684210527,
      "loss": 7.4049,
      "step": 892
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014782894736842107,
      "loss": 4.1205,
      "step": 893
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014776315789473684,
      "loss": 7.1785,
      "step": 894
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014769736842105264,
      "loss": 6.9466,
      "step": 895
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014763157894736844,
      "loss": 6.9065,
      "step": 896
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014756578947368424,
      "loss": 5.4256,
      "step": 897
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0001475,
      "loss": 8.3424,
      "step": 898
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014743421052631578,
      "loss": 6.2506,
      "step": 899
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014736842105263158,
      "loss": 7.4237,
      "step": 900
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014730263157894738,
      "loss": 7.4323,
      "step": 901
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014723684210526315,
      "loss": 9.0303,
      "step": 902
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014717105263157895,
      "loss": 6.5592,
      "step": 903
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014710526315789475,
      "loss": 6.274,
      "step": 904
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014703947368421055,
      "loss": 6.0262,
      "step": 905
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014697368421052632,
      "loss": 7.488,
      "step": 906
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014690789473684212,
      "loss": 8.8619,
      "step": 907
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0001468421052631579,
      "loss": 8.5165,
      "step": 908
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0001467763157894737,
      "loss": 9.5897,
      "step": 909
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014671052631578946,
      "loss": 8.614,
      "step": 910
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014664473684210526,
      "loss": 9.4893,
      "step": 911
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014657894736842106,
      "loss": 6.4858,
      "step": 912
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014651315789473686,
      "loss": 7.7731,
      "step": 913
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014644736842105263,
      "loss": 7.5183,
      "step": 914
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014638157894736843,
      "loss": 8.8299,
      "step": 915
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014631578947368423,
      "loss": 5.7484,
      "step": 916
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014625,
      "loss": 8.0063,
      "step": 917
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0001461842105263158,
      "loss": 6.3484,
      "step": 918
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014611842105263158,
      "loss": 6.3667,
      "step": 919
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014605263157894737,
      "loss": 6.832,
      "step": 920
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014598684210526317,
      "loss": 8.278,
      "step": 921
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014592105263157895,
      "loss": 5.4919,
      "step": 922
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014585526315789475,
      "loss": 5.1994,
      "step": 923
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014578947368421054,
      "loss": 5.5534,
      "step": 924
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014572368421052632,
      "loss": 8.0369,
      "step": 925
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014565789473684212,
      "loss": 5.998,
      "step": 926
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0001455921052631579,
      "loss": 5.6849,
      "step": 927
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0001455263157894737,
      "loss": 7.4017,
      "step": 928
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0001454605263157895,
      "loss": 3.7376,
      "step": 929
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00014539473684210526,
      "loss": 5.4368,
      "step": 930
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00014532894736842106,
      "loss": 8.5874,
      "step": 931
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014526315789473686,
      "loss": 7.3056,
      "step": 932
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014519736842105266,
      "loss": 3.6664,
      "step": 933
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014513157894736843,
      "loss": 6.5079,
      "step": 934
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0001450657894736842,
      "loss": 7.4123,
      "step": 935
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.000145,
      "loss": 6.8467,
      "step": 936
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0001449342105263158,
      "loss": 6.1826,
      "step": 937
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0001448684210526316,
      "loss": 6.8444,
      "step": 938
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00014480263157894737,
      "loss": 7.093,
      "step": 939
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00014473684210526317,
      "loss": 6.429,
      "step": 940
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014467105263157897,
      "loss": 6.985,
      "step": 941
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014460526315789474,
      "loss": 5.307,
      "step": 942
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014453947368421051,
      "loss": 5.1588,
      "step": 943
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00014447368421052631,
      "loss": 6.9922,
      "step": 944
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001444078947368421,
      "loss": 6.3198,
      "step": 945
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001443421052631579,
      "loss": 6.8799,
      "step": 946
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014427631578947368,
      "loss": 7.0528,
      "step": 947
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014421052631578948,
      "loss": 5.9014,
      "step": 948
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00014414473684210528,
      "loss": 4.0878,
      "step": 949
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014407894736842106,
      "loss": 6.7893,
      "step": 950
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014401315789473683,
      "loss": 7.6755,
      "step": 951
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00014394736842105263,
      "loss": 7.5226,
      "step": 952
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014388157894736843,
      "loss": 4.6329,
      "step": 953
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014381578947368423,
      "loss": 5.133,
      "step": 954
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00014375,
      "loss": 5.2047,
      "step": 955
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0001436842105263158,
      "loss": 5.8394,
      "step": 956
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0001436184210526316,
      "loss": 8.3843,
      "step": 957
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0001435526315789474,
      "loss": 5.5916,
      "step": 958
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00014348684210526317,
      "loss": 3.6753,
      "step": 959
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014342105263157894,
      "loss": 6.4266,
      "step": 960
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014335526315789474,
      "loss": 7.1392,
      "step": 961
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00014328947368421054,
      "loss": 3.6707,
      "step": 962
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001432236842105263,
      "loss": 6.0328,
      "step": 963
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001431578947368421,
      "loss": 4.4438,
      "step": 964
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001430921052631579,
      "loss": 4.3366,
      "step": 965
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0001430263157894737,
      "loss": 4.903,
      "step": 966
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00014296052631578948,
      "loss": 5.3537,
      "step": 967
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00014289473684210525,
      "loss": 5.2791,
      "step": 968
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014282894736842105,
      "loss": 5.9134,
      "step": 969
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014276315789473685,
      "loss": 7.1794,
      "step": 970
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00014269736842105262,
      "loss": 6.5826,
      "step": 971
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014263157894736842,
      "loss": 4.7426,
      "step": 972
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014256578947368422,
      "loss": 6.8157,
      "step": 973
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00014250000000000002,
      "loss": 7.2243,
      "step": 974
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0001424342105263158,
      "loss": 6.571,
      "step": 975
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0001423684210526316,
      "loss": 5.9073,
      "step": 976
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00014230263157894737,
      "loss": 5.8397,
      "step": 977
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00014223684210526316,
      "loss": 5.1685,
      "step": 978
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014217105263157894,
      "loss": 6.3394,
      "step": 979
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014210526315789474,
      "loss": 6.8359,
      "step": 980
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00014203947368421054,
      "loss": 5.6035,
      "step": 981
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00014197368421052633,
      "loss": 7.2915,
      "step": 982
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0001419078947368421,
      "loss": 8.1051,
      "step": 983
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0001418421052631579,
      "loss": 5.1753,
      "step": 984
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0001417763157894737,
      "loss": 4.3142,
      "step": 985
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00014171052631578948,
      "loss": 7.9292,
      "step": 986
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00014164473684210528,
      "loss": 6.2082,
      "step": 987
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014157894736842105,
      "loss": 7.9789,
      "step": 988
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014151315789473685,
      "loss": 4.3829,
      "step": 989
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00014144736842105265,
      "loss": 6.9979,
      "step": 990
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014138157894736842,
      "loss": 6.68,
      "step": 991
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014131578947368422,
      "loss": 6.6833,
      "step": 992
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00014125000000000002,
      "loss": 5.6486,
      "step": 993
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0001411842105263158,
      "loss": 5.5527,
      "step": 994
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0001411184210526316,
      "loss": 5.5147,
      "step": 995
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00014105263157894736,
      "loss": 5.9635,
      "step": 996
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014098684210526316,
      "loss": 7.7153,
      "step": 997
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014092105263157896,
      "loss": 7.5182,
      "step": 998
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014085526315789473,
      "loss": 5.5395,
      "step": 999
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00014078947368421053,
      "loss": 6.89,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 3140,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 7265955348480000.0,
  "trial_name": null,
  "trial_params": null
}
